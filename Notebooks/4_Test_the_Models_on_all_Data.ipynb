{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "4. TEST the Models on all Data.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EwECcSZvLLCB"
      },
      "source": [
        "## Final Tests and Scores\n",
        "This Notebook is a part of the Thesis Project: Learning Multilingual Document Representations. (Marc Lenz, 2021)\n",
        "\n",
        "-------------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ce5qKfxEEE9E"
      },
      "source": [
        "**General Information**\n",
        "- Inside this Notebook, different methods to create multilingual document representations are tested and evaluated. \n",
        "\n",
        "- Which methods, parameter-settings and languages are used for the evaluation can be adjusted by changing the variables in the Cell below. \n",
        "\n",
        "- This Notebook was run in Google Colab. \n",
        "\n",
        "**About the Methods and Datasets**\n",
        "\n",
        "Datasets: \n",
        " - JRC-Arquis (sample of 5000 Documents)\n",
        " - EU-Bookshop (sample of ~9000 Documents, first 5000 are selected)\n",
        "\n",
        "Methods:\n",
        "\n",
        "- Methods which are based on creating mappings between monolingual corpora.\n",
        "Those methods are: Linear Concept Approximation (LCA), Linear Concept Compression(LCC) and the Neural Network versions of those: NNCA and NNCC. \n",
        "For them, first the monolingual representation have to be created, then the mapping can be applied. Algorithms which are applied here to derive monolingual representations are: Latent Semantic indexing and Doc2Vec (Mikolov et al.)\n",
        "\n",
        "- Methods which derive multilingual representations directly. Those are: Cross-Lingual Latent Semantic Indexing (CL-LSI) and the improved version of it, which is also described within the theoretical section of the Thesis. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hshTz7z4DH1y"
      },
      "source": [
        "\"\"\"\n",
        "----\n",
        "Languages Preprocessed for JRC_Arquis: en, hu, fr, de, nl, pt, cz, pl\n",
        "Languages Preprocessed for EU-Bookshop: en, es, fr\n",
        "\n",
        "\"\"\"\n",
        "#Choose either \"JRC_Arquis\" \"EU-Bookshop\"\n",
        "dataset =\"EU-Bookshop\"\n",
        "\n",
        "#Determines which methods are tested\n",
        "# True -> Method is evaluated\n",
        "# False -> Method is ignored\n",
        "test_LCA = False\n",
        "test_LCC = False\n",
        "test_CLLSI = False\n",
        "test_neural_networks = True\n",
        "\n",
        "#Set languages, dimensions and kind of monolingual embedding\n",
        "#The monolingual embedding method influences the results of \n",
        "# LCA, LCC, NNCA, and NNCC\n",
        "languages = [\"en\", \"es\", \"fr\"] #[\"en\", \"hu\", \"fr\", \"de\", \"nl\", \"pt\", \"cs\", \"pl\"]\n",
        "embedding_method = \"LSI\"\n",
        "\n",
        "\n",
        "#BEST PARAMETERS/PARAMETERS TO BE TESTED\n",
        "lca_dimension = [500]\n",
        "lcao_dimension =[500]\n",
        "lcc_dimension = [500]\n",
        "cllsi_dimension = [500]\n",
        "settings_nncc = [     \n",
        "             ]\n",
        "\n",
        "settings_nnca = [  \n",
        "            {\"dimension\" : 500,\n",
        "             \"neurons\" : [500], \n",
        "             \"activation_function\" : None,\n",
        "             \"dropout\" : 0.0,\n",
        "             \"optimizer\" : \"adam\",\n",
        "             \"loss_function\" : \"cosine_sim\"},\n",
        "             ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CbdMEV93vg7D"
      },
      "source": [
        "all_dimensions = lca_dimension + lcao_dimension + lcc_dimension\n",
        "dimensions = list(dict.fromkeys(all_dimensions))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "It0niRYTn2Y1"
      },
      "source": [
        "##  Load Dataset\n",
        "- First of all, clone the git repository which contains most of the functions and models for this Notebook"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DnPUdnM5n4_H",
        "outputId": "593ef7f1-0e31-41bf-9293-6b3072a4bccb"
      },
      "source": [
        "!git clone https://github.com/marc-lenz/thesis_code.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'thesis_code' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OK3ve7knzwr5"
      },
      "source": [
        "- then load the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "elxdSt42S5Yt",
        "outputId": "4a8b7a11-4c02-4c7e-a396-19568955dc67"
      },
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd \n",
        "import numpy as np\n",
        "import pickle\n",
        "\n",
        "drive.mount(\"/content/gdrive\")\n",
        "\n",
        "if dataset == \"JRC_Arquis\" :\n",
        "  main_dir = \"/content/gdrive/My Drive/Thesis/JRC_Arquis_files/\"\n",
        "  sample_df = pd.read_pickle(main_dir+\"sample_df_preprocessed.pkl\")\n",
        "  train_df = sample_df[:3000]\n",
        "  val_df = sample_df[3000:4000]\n",
        "  test_df = sample_df[4000:5000]\n",
        "  \n",
        "elif dataset == \"EU-Bookshop\": \n",
        "  main_dir = \"/content/gdrive/My Drive/Thesis/EU-BookShop Files/\"\n",
        "  #define\n",
        "\n",
        "  def get_eub_dataframe(main_dir):\n",
        "    def load(filepath):\n",
        "      with open(filepath,\"rb\") as f:\n",
        "          obj = pickle.load(f)\n",
        "      return obj\n",
        "    tokenized_en = load(main_dir+\"/tokenized_en.list\")\n",
        "    tokenized_fr = load(main_dir+\"/tokenized_fr.list\")\n",
        "    tokenized_es = load(main_dir+\"/tokenized_es.list\")\n",
        "    sample_df = pd.DataFrame()\n",
        "    sample_df[\"body_pre_en\"] = tokenized_en\n",
        "    sample_df[\"body_pre_fr\"] = tokenized_fr\n",
        "    sample_df[\"body_pre_es\"] = tokenized_es\n",
        "    #erase empty lists\n",
        "    for key in sample_df.keys():\n",
        "      sample_df = sample_df[sample_df.astype(str)[key] != '[]']\n",
        "    return sample_df\n",
        "\n",
        "  sample_df = get_eub_dataframe(main_dir)[:5000]\n",
        "  train_df = sample_df[:3000]\n",
        "  val_df = sample_df[3000:4000]\n",
        "  test_df = sample_df[4000:5000]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ev7mVFQMvFly"
      },
      "source": [
        "## Train Monolingual Representations which will be aligned\n",
        "- > Define the languages and dimensions which should be tested here"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6lpKqf-yIUG"
      },
      "source": [
        "from thesis_code.Utils import read_docs, Vector_Lsi_Model\n",
        "from gensim.test.utils import common_texts\n",
        "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
        "from tqdm import tqdm \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "max_dim = max(dimensions)\n",
        "matrices = dict()\n",
        "\n",
        "\n",
        "if embedding_method == \"LSI\":\n",
        "  lsi_models = dict()\n",
        "  for t in languages:\n",
        "    key = \"body_pre_{}\".format(t)\n",
        "    lsi_models[t] = Vector_Lsi_Model(sample_df[key], dimension=max_dim)\n",
        "    matrices[\"{}_train_vecs\".format(t)] = np.asarray(lsi_models[t].create_embeddings(train_df[key]))\n",
        "    matrices[\"{}_val_vecs\".format(t)] = np.asarray(lsi_models[t].create_embeddings(val_df[key]))\n",
        "    matrices[\"{}_test_vecs\".format(t)] = np.asarray(lsi_models[t].create_embeddings(test_df[key]))\n",
        "\n",
        "elif embedding_method ==\"Doc2Vec\":\n",
        "  for dimension in dimensions:\n",
        "    matrices[dimension] = dict()\n",
        "    for t in tqdm(languages):\n",
        "      key = \"body_pre_{}\".format(t)\n",
        "      #create tagged docs first\n",
        "      documents = []\n",
        "      for ind in sample_df.index:\n",
        "        doc = sample_df[key][ind]\n",
        "        tagged_doc = TaggedDocument(doc, [ind])\n",
        "        documents.append(tagged_doc)\n",
        "      #Train Doc2Vec Model\n",
        "      model = Doc2Vec(documents, vector_size=dimension, window=3, min_count=10, workers=4, epochs=100, dm=0)\n",
        "      training_docs = [model[i] for i in train_df.index]\n",
        "      validation_docs = [model[i] for i in val_df.index]\n",
        "      test_docs = [model[i] for i in test_df.index]\n",
        "      #set matrices\n",
        "      matrices[dimension][\"{}_train_vecs\".format(t)] = np.asarray(training_docs)\n",
        "      matrices[dimension][\"{}_val_vecs\".format(t)] = np.asarray(validation_docs)\n",
        "      matrices[dimension][\"{}_test_vecs\".format(t)] = np.asarray(test_docs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JStFUUbz4fsB"
      },
      "source": [
        "from itertools import permutations\n",
        "pairs = permutations(languages, 2)\n",
        "pair_list = [p for p in pairs]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DyFVUKrE0n_U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5e750da-59a0-4413-b00f-8d9f543a37ee"
      },
      "source": [
        "pair_list"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('en', 'es'),\n",
              " ('en', 'fr'),\n",
              " ('es', 'en'),\n",
              " ('es', 'fr'),\n",
              " ('fr', 'en'),\n",
              " ('fr', 'es')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zH5sFQtlxYvN"
      },
      "source": [
        "## Linear Concept Approximation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1TMIuR52vG6y"
      },
      "source": [
        "from thesis_code.evaluation_functions import mate_retrieval, reciprocal_rank, comp_scores"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pwjR3Va-QAU2"
      },
      "source": [
        "from thesis_code.evaluation_functions import evaluate_baseline_lca_model, evaluate_baseline_lca_model_ort\n",
        "#from thesis_code.evaluation_functions import mate_retrieval, reciprocal_rank, comp_scores\n",
        "from tqdm import tqdm\n",
        "\n",
        "if test_LCA == True:\n",
        "  lca_scores = dict()\n",
        "\n",
        "  for pair in pair_list:\n",
        "    l1 = pair[0]\n",
        "    l2 = pair[1]\n",
        "    if embedding_method == \"LSI\":\n",
        "      l1_train, l1_test = matrices[\"{}_train_vecs\".format(l1)], matrices[\"{}_test_vecs\".format(l1)]\n",
        "      l2_train, l2_test = matrices[\"{}_train_vecs\".format(l2)], matrices[\"{}_test_vecs\".format(l2)]\n",
        "      score_lca = evaluate_baseline_lca_model(l1_train, l1_test, l2_train, l2_test, lca_dimension, comp_scores)\n",
        "      score_lcao = evaluate_baseline_lca_model_ort(l1_train, l1_test, l2_train, l2_test, lcao_dimension, comp_scores)\n",
        "    if embedding_method ==\"Doc2Vec\":\n",
        "      score_lca = []\n",
        "      score_lcao = []\n",
        "      for dimension in lca_dimension: \n",
        "        l1_train, l1_test = matrices[dimension][\"{}_train_vecs\".format(l1)], matrices[dimension][\"{}_test_vecs\".format(l1)]\n",
        "        l2_train, l2_test = matrices[dimension][\"{}_train_vecs\".format(l2)], matrices[dimension][\"{}_test_vecs\".format(l2)]\n",
        "        score_lca.append(evaluate_baseline_lca_model(l1_train, l1_test, l2_train, l2_test, [dimension], comp_scores)[0])\n",
        "      for dimension in lcao_dimension: \n",
        "        l1_train, l1_test = matrices[dimension][\"{}_train_vecs\".format(l1)], matrices[dimension][\"{}_test_vecs\".format(l1)]\n",
        "        l2_train, l2_test = matrices[dimension][\"{}_train_vecs\".format(l2)], matrices[dimension][\"{}_test_vecs\".format(l2)]\n",
        "        score_lcao.append(evaluate_baseline_lca_model_ort(l1_train, l1_test, l2_train, l2_test, [dimension], comp_scores)[0])\n",
        "\n",
        "    lca_scores[\"{}-> {}\".format(l1,l2)] = {\"lca_{}\".format(embedding_method): score_lca, \n",
        "                         \"lcao_{}\".format(embedding_method): score_lcao}\n",
        "    #Save Results\n",
        "    target_dir = main_dir+\"lca_scores_{}_{}\".format(embedding_method, dataset)\n",
        "    with open(target_dir, 'wb') as handle:\n",
        "        pickle.dump(lca_scores, handle, protocol=pickle.HIGHEST_PROTOCOL)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pXfoquzk6edg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pXVcVDelQFbk"
      },
      "source": [
        "##LCC Scores"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0uGBgYEOLsGE"
      },
      "source": [
        "from thesis_code.evaluation_functions import evaluate_lcc_model\n",
        "\n",
        "if test_LCC == True:\n",
        "  lcc_scores = dict()\n",
        "\n",
        "  for pair in pair_list:\n",
        "    l1 = pair[0]\n",
        "    l2 = pair[1]\n",
        "    if embedding_method ==\"LSI\":\n",
        "      l1_train, l1_test = matrices[\"{}_train_vecs\".format(l1)], matrices[\"{}_test_vecs\".format(l1)]\n",
        "      l2_train, l2_test = matrices[\"{}_train_vecs\".format(l2)], matrices[\"{}_test_vecs\".format(l2)]\n",
        "      score_lcc = evaluate_lcc_model(l1_train, l1_test, l2_train, l2_test, lcc_dimension, evaluation_function = comp_scores)\n",
        "    if embedding_method ==\"Doc2Vec\":\n",
        "      score_lcc = []\n",
        "      for dimension in lcc_dimension: \n",
        "        l1_train, l1_test = matrices[dimension][\"{}_train_vecs\".format(l1)], matrices[dimension][\"{}_test_vecs\".format(l1)]\n",
        "        l2_train, l2_test = matrices[dimension][\"{}_train_vecs\".format(l2)], matrices[dimension][\"{}_test_vecs\".format(l2)]\n",
        "        score_lcc.append(evaluate_lcc_model(l1_train, l1_test, l2_train, l2_test, [dimension], comp_scores)[0])\n",
        "    lcc_scores[\"{}-> {}\".format(l1,l2)] = score_lcc\n",
        "\n",
        "    #Save Results\n",
        "    target_dir = main_dir+\"lcc_scores_{}_{}\".format(embedding_method, dataset)\n",
        "    with open(target_dir, 'wb') as handle:\n",
        "        pickle.dump(lcc_scores, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQwJAi1X_hOK"
      },
      "source": [
        "#Cross-Lingual LSI"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oNFA1i_YcbvM"
      },
      "source": [
        "from thesis_code.evaluation_functions import evaluate_cllsi, evaluate_improved_cllsi\n",
        "from tqdm import tqdm\n",
        "\n",
        "cllsi_scores = dict()\n",
        "if test_CLLSI == True:\n",
        "\n",
        "  for pair in tqdm(pair_list):\n",
        "    l1 = pair[0]\n",
        "    l2 = pair[1]\n",
        "    l1_train, l1_test = list(train_df[\"body_pre_{}\".format(l1)]), list(val_df[\"body_pre_{}\".format(l1)])\n",
        "    l2_train, l2_test = list(train_df[\"body_pre_{}\".format(l2)]), list(val_df[\"body_pre_{}\".format(l2)])\n",
        "    cllsi_score = evaluate_cllsi(l1_train, l1_test, l2_train, l2_test, cllsi_dimension, evaluation_function = comp_scores)\n",
        "    print(\"pair: {}, CL-LSI score: {}\".format(pair, cllsi_score) )\n",
        "    i_cllsi_score = evaluate_improved_cllsi(l1_train, l1_test, l2_train, l2_test, cllsi_dimension, evaluation_function = comp_scores)\n",
        "    print(\"pair: {}, CL-LSI score: {}\".format(pair, i_cllsi_score))\n",
        "\n",
        "    cllsi_scores[\"{}-> {}\".format(l1,l2)] = {\"cllsi_{}\".format(embedding_method): cllsi_score, \n",
        "                         \"icllsi_{}\".format(embedding_method): i_cllsi_score}\n",
        "    #Save Results\n",
        "    target_dir = main_dir+\"cllsi_scores_{}_{}\".format(embedding_method, dataset)\n",
        "    with open(target_dir, 'wb') as handle:\n",
        "        pickle.dump(lca_scores, handle, protocol=pickle.HIGHEST_PROTOCOL)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eNwUIz4H06vu"
      },
      "source": [
        "##Neural Networks "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_QJd1tz-1BdZ"
      },
      "source": [
        "List all settings to be tested here. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ngXuM2TqElO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4bfe1172-6899-406f-8832-0898d87dd0e4"
      },
      "source": [
        "from thesis_code.evaluation_functions import evaluate_nncc, evaluate_nnca\n",
        "\n",
        "if test_neural_networks == True:\n",
        "  nncc_scores = dict()\n",
        "  nnca_scores = dict()\n",
        "  #choose only one, to reduce computational burden\n",
        "  for pair in pair_list:\n",
        "    l1 = pair[0]\n",
        "    l2 = pair[1]\n",
        "    \n",
        "    if embedding_method ==\"LSI\":\n",
        "        for setting in settings_nncc:\n",
        "          dimension = setting[\"dimension\"]\n",
        "          l1_train, l1_test = matrices[\"{}_train_vecs\".format(l1)], matrices[\"{}_test_vecs\".format(l1)]\n",
        "          l2_train, l2_test = matrices[\"{}_train_vecs\".format(l2)], matrices[\"{}_test_vecs\".format(l2)]\n",
        "          score, history = evaluate_nncc(l1_train, l1_test, l2_train, l2_test, \n",
        "                                dimensions = [dimension], \n",
        "                                evaluation_function = comp_scores,\n",
        "                                neurons = setting[\"neurons\"],\n",
        "                                activation_function = setting[\"activation_function\"],\n",
        "                                max_epochs = 200,\n",
        "                                dropout = setting[\"dropout\"],\n",
        "                                optimizer = setting[\"optimizer\"],\n",
        "                                loss = setting[\"loss_function\" ])\n",
        "          nncc_scores[\"{}-> {}\".format(l1,l2)] = score\n",
        "        for setting in settings_nnca:\n",
        "          dimension = setting[\"dimension\"]\n",
        "          l1_train, l1_test = matrices[\"{}_train_vecs\".format(l1)], matrices[\"{}_test_vecs\".format(l1)]\n",
        "          l2_train, l2_test = matrices[\"{}_train_vecs\".format(l2)], matrices[\"{}_test_vecs\".format(l2)]\n",
        "          score, h1, h2 = evaluate_nnca(l1_train, l1_test, l2_train, l2_test, \n",
        "                                dimensions = [dimension], \n",
        "                                evaluation_function = comp_scores,\n",
        "                                neurons = setting[\"neurons\"],\n",
        "                                activation_function = setting[\"activation_function\"],\n",
        "                                max_epochs = 200,\n",
        "                                dropout = setting[\"dropout\"],\n",
        "                                optimizer = setting[\"optimizer\"],\n",
        "                                loss = setting[\"loss_function\" ])\n",
        "          nnca_scores[\"{}-> {}\".format(l1,l2)] = score\n",
        "    if embedding_method ==\"Doc2Vec\":\n",
        "        #Compute score for each nncc Setting:\n",
        "        for setting in settings_nncc:\n",
        "          dimension = setting[\"dimension\"]\n",
        "          l1_train, l1_test = matrices[dimension][\"{}_train_vecs\".format(l1)], matrices[dimension][\"{}_test_vecs\".format(l1)]\n",
        "          l2_train, l2_test = matrices[dimension][\"{}_train_vecs\".format(l2)], matrices[dimension][\"{}_test_vecs\".format(l2)]\n",
        "          score, history = evaluate_nncc(l1_train, l1_test, l2_train, l2_test, \n",
        "                                dimensions = [dimension], \n",
        "                                evaluation_function = comp_scores,\n",
        "                                neurons = setting[\"neurons\"],\n",
        "                                activation_function = setting[\"activation_function\"],\n",
        "                                max_epochs = 200,\n",
        "                                dropout = setting[\"dropout\"],\n",
        "                                optimizer = setting[\"optimizer\"],\n",
        "                                loss = setting[\"loss_function\" ])\n",
        "          nncc_scores[\"{}-> {}\".format(l1,l2)] = score\n",
        "        for setting in settings_nnca:\n",
        "          dimension = setting[\"dimension\"]\n",
        "          l1_train, l1_test = matrices[dimension][\"{}_train_vecs\".format(l1)], matrices[dimension][\"{}_test_vecs\".format(l1)]\n",
        "          l2_train, l2_test = matrices[dimension][\"{}_train_vecs\".format(l2)], matrices[dimension][\"{}_test_vecs\".format(l2)]\n",
        "          score, h1, h2 = evaluate_nnca(l1_train, l1_test, l2_train, l2_test, \n",
        "                                dimensions = [dimension], \n",
        "                                evaluation_function = comp_scores,\n",
        "                                neurons = setting[\"neurons\"],\n",
        "                                activation_function = setting[\"activation_function\"],\n",
        "                                max_epochs = 200,\n",
        "                                dropout = setting[\"dropout\"],\n",
        "                                optimizer = setting[\"optimizer\"],\n",
        "                                loss = setting[\"loss_function\" ])\n",
        "          nnca_scores[\"{}-> {}\".format(l1,l2)] = score\n",
        "\n",
        "    #Save Results\n",
        "    target_dir = main_dir+\"nnca_scores_{}_{}\".format(embedding_method, dataset)\n",
        "    with open(target_dir, 'wb') as handle:\n",
        "        pickle.dump(nnca_scores, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "    #Save Results\n",
        "    target_dir = main_dir+\"nncc_scores_{}_{}\".format(embedding_method, dataset)\n",
        "    with open(target_dir, 'wb') as handle:\n",
        "        pickle.dump(nncc_scores, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "    print(nncc_scores)\n",
        "\n",
        "      #lca_nn_score = evaluate_single_layer_lca_nn(l1_train, l1_test, l2_train, l2_test, evaluation_function = reciprocal_rank)\n",
        "      #lca_nn_scores.append(lca_nn_score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "94/94 [==============================] - 1s 3ms/step - loss: -0.5654 - cosine_similarity: -0.5658 - val_loss: -0.7210 - val_cosine_similarity: -0.7196\n",
            "Epoch 2/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.8131 - cosine_similarity: -0.8132 - val_loss: -0.7902 - val_cosine_similarity: -0.7885\n",
            "Epoch 3/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.8667 - cosine_similarity: -0.8667 - val_loss: -0.8182 - val_cosine_similarity: -0.8165\n",
            "Epoch 4/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.8910 - cosine_similarity: -0.8909 - val_loss: -0.8337 - val_cosine_similarity: -0.8321\n",
            "Epoch 5/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9041 - cosine_similarity: -0.9040 - val_loss: -0.8429 - val_cosine_similarity: -0.8413\n",
            "Epoch 6/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9121 - cosine_similarity: -0.9120 - val_loss: -0.8479 - val_cosine_similarity: -0.8464\n",
            "Epoch 7/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9173 - cosine_similarity: -0.9173 - val_loss: -0.8516 - val_cosine_similarity: -0.8500\n",
            "Epoch 8/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9208 - cosine_similarity: -0.9208 - val_loss: -0.8544 - val_cosine_similarity: -0.8527\n",
            "Epoch 9/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9232 - cosine_similarity: -0.9232 - val_loss: -0.8570 - val_cosine_similarity: -0.8554\n",
            "Epoch 10/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9251 - cosine_similarity: -0.9250 - val_loss: -0.8578 - val_cosine_similarity: -0.8562\n",
            "Epoch 11/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9265 - cosine_similarity: -0.9265 - val_loss: -0.8582 - val_cosine_similarity: -0.8566\n",
            "Epoch 12/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9275 - cosine_similarity: -0.9275 - val_loss: -0.8597 - val_cosine_similarity: -0.8581\n",
            "Epoch 13/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9285 - cosine_similarity: -0.9285 - val_loss: -0.8604 - val_cosine_similarity: -0.8589\n",
            "Epoch 14/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9290 - cosine_similarity: -0.9290 - val_loss: -0.8605 - val_cosine_similarity: -0.8589\n",
            "Epoch 15/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9294 - cosine_similarity: -0.9295 - val_loss: -0.8612 - val_cosine_similarity: -0.8596\n",
            "Epoch 16/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9299 - cosine_similarity: -0.9300 - val_loss: -0.8612 - val_cosine_similarity: -0.8596\n",
            "Epoch 17/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9303 - cosine_similarity: -0.9302 - val_loss: -0.8615 - val_cosine_similarity: -0.8599\n",
            "Epoch 18/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9306 - cosine_similarity: -0.9305 - val_loss: -0.8617 - val_cosine_similarity: -0.8601\n",
            "Epoch 19/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9310 - cosine_similarity: -0.9310 - val_loss: -0.8618 - val_cosine_similarity: -0.8602\n",
            "Epoch 20/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9312 - cosine_similarity: -0.9312 - val_loss: -0.8622 - val_cosine_similarity: -0.8606\n",
            "Epoch 21/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9315 - cosine_similarity: -0.9314 - val_loss: -0.8621 - val_cosine_similarity: -0.8605\n",
            "Epoch 22/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9316 - cosine_similarity: -0.9316 - val_loss: -0.8624 - val_cosine_similarity: -0.8608\n",
            "Epoch 23/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9319 - cosine_similarity: -0.9319 - val_loss: -0.8625 - val_cosine_similarity: -0.8609\n",
            "Epoch 24/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9319 - cosine_similarity: -0.9319 - val_loss: -0.8628 - val_cosine_similarity: -0.8612\n",
            "Epoch 25/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9323 - cosine_similarity: -0.9323 - val_loss: -0.8621 - val_cosine_similarity: -0.8605\n",
            "Epoch 26/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9323 - cosine_similarity: -0.9323 - val_loss: -0.8629 - val_cosine_similarity: -0.8613\n",
            "Epoch 27/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9324 - cosine_similarity: -0.9323 - val_loss: -0.8630 - val_cosine_similarity: -0.8615\n",
            "Epoch 28/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9325 - cosine_similarity: -0.9324 - val_loss: -0.8627 - val_cosine_similarity: -0.8611\n",
            "Epoch 29/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9325 - cosine_similarity: -0.9325 - val_loss: -0.8627 - val_cosine_similarity: -0.8612\n",
            "Epoch 30/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9328 - cosine_similarity: -0.9327 - val_loss: -0.8625 - val_cosine_similarity: -0.8609\n",
            "Epoch 31/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9329 - cosine_similarity: -0.9329 - val_loss: -0.8629 - val_cosine_similarity: -0.8612\n",
            "Epoch 32/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9330 - cosine_similarity: -0.9330 - val_loss: -0.8627 - val_cosine_similarity: -0.8611\n",
            "Epoch 33/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9332 - cosine_similarity: -0.9331 - val_loss: -0.8628 - val_cosine_similarity: -0.8611\n",
            "Epoch 34/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9329 - cosine_similarity: -0.9329 - val_loss: -0.8626 - val_cosine_similarity: -0.8610\n",
            "Epoch 35/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9332 - cosine_similarity: -0.9332 - val_loss: -0.8623 - val_cosine_similarity: -0.8608\n",
            "Epoch 36/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9333 - cosine_similarity: -0.9332 - val_loss: -0.8623 - val_cosine_similarity: -0.8607\n",
            "Epoch 37/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9332 - cosine_similarity: -0.9332 - val_loss: -0.8627 - val_cosine_similarity: -0.8611\n",
            "Epoch 38/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9336 - cosine_similarity: -0.9335 - val_loss: -0.8629 - val_cosine_similarity: -0.8613\n",
            "Epoch 39/200\n",
            "94/94 [==============================] - 0s 3ms/step - loss: -0.9335 - cosine_similarity: -0.9335 - val_loss: -0.8622 - val_cosine_similarity: -0.8606\n",
            "Epoch 40/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9336 - cosine_similarity: -0.9336 - val_loss: -0.8628 - val_cosine_similarity: -0.8612\n",
            "Epoch 41/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9336 - cosine_similarity: -0.9336 - val_loss: -0.8627 - val_cosine_similarity: -0.8611\n",
            "Epoch 42/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9337 - cosine_similarity: -0.9337 - val_loss: -0.8631 - val_cosine_similarity: -0.8615\n",
            "Epoch 43/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9338 - cosine_similarity: -0.9337 - val_loss: -0.8627 - val_cosine_similarity: -0.8610\n",
            "Epoch 44/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9338 - cosine_similarity: -0.9337 - val_loss: -0.8629 - val_cosine_similarity: -0.8612\n",
            "Epoch 45/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9339 - cosine_similarity: -0.9339 - val_loss: -0.8618 - val_cosine_similarity: -0.8602\n",
            "Epoch 46/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9340 - cosine_similarity: -0.9340 - val_loss: -0.8628 - val_cosine_similarity: -0.8612\n",
            "Epoch 47/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9341 - cosine_similarity: -0.9342 - val_loss: -0.8631 - val_cosine_similarity: -0.8615\n",
            "Epoch 48/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9341 - cosine_similarity: -0.9341 - val_loss: -0.8627 - val_cosine_similarity: -0.8611\n",
            "Epoch 49/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9341 - cosine_similarity: -0.9341 - val_loss: -0.8625 - val_cosine_similarity: -0.8609\n",
            "Epoch 50/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9342 - cosine_similarity: -0.9342 - val_loss: -0.8626 - val_cosine_similarity: -0.8609\n",
            "Epoch 51/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9342 - cosine_similarity: -0.9342 - val_loss: -0.8627 - val_cosine_similarity: -0.8611\n",
            "Epoch 52/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9342 - cosine_similarity: -0.9342 - val_loss: -0.8628 - val_cosine_similarity: -0.8612\n",
            "Epoch 53/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9343 - cosine_similarity: -0.9342 - val_loss: -0.8632 - val_cosine_similarity: -0.8615\n",
            "Epoch 54/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9344 - cosine_similarity: -0.9344 - val_loss: -0.8628 - val_cosine_similarity: -0.8611\n",
            "Epoch 55/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9344 - cosine_similarity: -0.9344 - val_loss: -0.8628 - val_cosine_similarity: -0.8612\n",
            "Epoch 56/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9348 - cosine_similarity: -0.9347 - val_loss: -0.8626 - val_cosine_similarity: -0.8609\n",
            "Epoch 57/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9346 - cosine_similarity: -0.9346 - val_loss: -0.8624 - val_cosine_similarity: -0.8607\n",
            "Epoch 58/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9345 - cosine_similarity: -0.9345 - val_loss: -0.8628 - val_cosine_similarity: -0.8612\n",
            "Epoch 59/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9347 - cosine_similarity: -0.9347 - val_loss: -0.8629 - val_cosine_similarity: -0.8612\n",
            "Epoch 60/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9347 - cosine_similarity: -0.9347 - val_loss: -0.8627 - val_cosine_similarity: -0.8611\n",
            "Epoch 61/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9348 - cosine_similarity: -0.9347 - val_loss: -0.8626 - val_cosine_similarity: -0.8610\n",
            "Epoch 62/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9348 - cosine_similarity: -0.9349 - val_loss: -0.8628 - val_cosine_similarity: -0.8612\n",
            "Epoch 63/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9348 - cosine_similarity: -0.9347 - val_loss: -0.8628 - val_cosine_similarity: -0.8612\n",
            "Epoch 64/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9348 - cosine_similarity: -0.9348 - val_loss: -0.8630 - val_cosine_similarity: -0.8614\n",
            "Epoch 65/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9348 - cosine_similarity: -0.9348 - val_loss: -0.8627 - val_cosine_similarity: -0.8610\n",
            "Epoch 66/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9349 - cosine_similarity: -0.9349 - val_loss: -0.8626 - val_cosine_similarity: -0.8610\n",
            "Epoch 67/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9350 - cosine_similarity: -0.9349 - val_loss: -0.8625 - val_cosine_similarity: -0.8609\n",
            "Epoch 68/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9348 - cosine_similarity: -0.9349 - val_loss: -0.8625 - val_cosine_similarity: -0.8610\n",
            "Epoch 69/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9352 - cosine_similarity: -0.9352 - val_loss: -0.8630 - val_cosine_similarity: -0.8615\n",
            "Epoch 70/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9352 - cosine_similarity: -0.9352 - val_loss: -0.8630 - val_cosine_similarity: -0.8613\n",
            "Epoch 71/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9353 - cosine_similarity: -0.9352 - val_loss: -0.8629 - val_cosine_similarity: -0.8613\n",
            "Epoch 72/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9353 - cosine_similarity: -0.9353 - val_loss: -0.8629 - val_cosine_similarity: -0.8613\n",
            "Epoch 73/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9353 - cosine_similarity: -0.9354 - val_loss: -0.8626 - val_cosine_similarity: -0.8611\n",
            "Epoch 74/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9354 - cosine_similarity: -0.9353 - val_loss: -0.8627 - val_cosine_similarity: -0.8611\n",
            "Epoch 75/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9354 - cosine_similarity: -0.9354 - val_loss: -0.8626 - val_cosine_similarity: -0.8609\n",
            "Epoch 76/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9353 - cosine_similarity: -0.9353 - val_loss: -0.8629 - val_cosine_similarity: -0.8613\n",
            "Epoch 77/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9354 - cosine_similarity: -0.9354 - val_loss: -0.8629 - val_cosine_similarity: -0.8613\n",
            "Epoch 78/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9355 - cosine_similarity: -0.9356 - val_loss: -0.8628 - val_cosine_similarity: -0.8613\n",
            "Epoch 79/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9356 - cosine_similarity: -0.9356 - val_loss: -0.8626 - val_cosine_similarity: -0.8610\n",
            "Epoch 80/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9355 - cosine_similarity: -0.9354 - val_loss: -0.8625 - val_cosine_similarity: -0.8609\n",
            "Epoch 81/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9355 - cosine_similarity: -0.9356 - val_loss: -0.8628 - val_cosine_similarity: -0.8612\n",
            "Epoch 82/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9357 - cosine_similarity: -0.9357 - val_loss: -0.8626 - val_cosine_similarity: -0.8610\n",
            "Epoch 83/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9356 - cosine_similarity: -0.9356 - val_loss: -0.8629 - val_cosine_similarity: -0.8612\n",
            "Epoch 84/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9356 - cosine_similarity: -0.9356 - val_loss: -0.8628 - val_cosine_similarity: -0.8612\n",
            "Epoch 85/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9358 - cosine_similarity: -0.9357 - val_loss: -0.8627 - val_cosine_similarity: -0.8611\n",
            "Epoch 86/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9358 - cosine_similarity: -0.9358 - val_loss: -0.8629 - val_cosine_similarity: -0.8613\n",
            "Epoch 87/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9359 - cosine_similarity: -0.9360 - val_loss: -0.8631 - val_cosine_similarity: -0.8615\n",
            "Epoch 88/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9357 - cosine_similarity: -0.9357 - val_loss: -0.8628 - val_cosine_similarity: -0.8612\n",
            "Epoch 89/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9359 - cosine_similarity: -0.9359 - val_loss: -0.8627 - val_cosine_similarity: -0.8611\n",
            "Epoch 90/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9359 - cosine_similarity: -0.9360 - val_loss: -0.8627 - val_cosine_similarity: -0.8611\n",
            "Epoch 91/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9359 - cosine_similarity: -0.9358 - val_loss: -0.8629 - val_cosine_similarity: -0.8612\n",
            "Epoch 92/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9360 - cosine_similarity: -0.9360 - val_loss: -0.8625 - val_cosine_similarity: -0.8609\n",
            "Epoch 93/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9360 - cosine_similarity: -0.9361 - val_loss: -0.8628 - val_cosine_similarity: -0.8612\n",
            "Epoch 94/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9359 - cosine_similarity: -0.9359 - val_loss: -0.8630 - val_cosine_similarity: -0.8614\n",
            "Epoch 95/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9360 - cosine_similarity: -0.9361 - val_loss: -0.8626 - val_cosine_similarity: -0.8610\n",
            "Epoch 96/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9362 - cosine_similarity: -0.9361 - val_loss: -0.8631 - val_cosine_similarity: -0.8615\n",
            "Epoch 97/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9362 - cosine_similarity: -0.9361 - val_loss: -0.8626 - val_cosine_similarity: -0.8610\n",
            "Epoch 98/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9361 - cosine_similarity: -0.9361 - val_loss: -0.8625 - val_cosine_similarity: -0.8609\n",
            "Epoch 99/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9362 - cosine_similarity: -0.9362 - val_loss: -0.8628 - val_cosine_similarity: -0.8612\n",
            "Epoch 100/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9363 - cosine_similarity: -0.9362 - val_loss: -0.8626 - val_cosine_similarity: -0.8610\n",
            "Epoch 101/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9363 - cosine_similarity: -0.9362 - val_loss: -0.8627 - val_cosine_similarity: -0.8611\n",
            "Epoch 102/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9364 - cosine_similarity: -0.9363 - val_loss: -0.8625 - val_cosine_similarity: -0.8609\n",
            "Epoch 103/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9362 - cosine_similarity: -0.9361 - val_loss: -0.8627 - val_cosine_similarity: -0.8611\n",
            "Epoch 104/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9364 - cosine_similarity: -0.9363 - val_loss: -0.8629 - val_cosine_similarity: -0.8613\n",
            "Epoch 105/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9364 - cosine_similarity: -0.9364 - val_loss: -0.8624 - val_cosine_similarity: -0.8608\n",
            "Epoch 106/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9365 - cosine_similarity: -0.9364 - val_loss: -0.8626 - val_cosine_similarity: -0.8610\n",
            "Epoch 107/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9363 - cosine_similarity: -0.9363 - val_loss: -0.8625 - val_cosine_similarity: -0.8609\n",
            "Epoch 108/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9365 - cosine_similarity: -0.9366 - val_loss: -0.8626 - val_cosine_similarity: -0.8610\n",
            "Epoch 109/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9365 - cosine_similarity: -0.9365 - val_loss: -0.8630 - val_cosine_similarity: -0.8614\n",
            "Epoch 110/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9365 - cosine_similarity: -0.9365 - val_loss: -0.8625 - val_cosine_similarity: -0.8609\n",
            "Epoch 111/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9365 - cosine_similarity: -0.9365 - val_loss: -0.8627 - val_cosine_similarity: -0.8611\n",
            "Epoch 112/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9366 - cosine_similarity: -0.9367 - val_loss: -0.8626 - val_cosine_similarity: -0.8610\n",
            "Epoch 113/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9365 - cosine_similarity: -0.9365 - val_loss: -0.8628 - val_cosine_similarity: -0.8612\n",
            "Epoch 114/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9366 - cosine_similarity: -0.9365 - val_loss: -0.8627 - val_cosine_similarity: -0.8610\n",
            "Epoch 115/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9366 - cosine_similarity: -0.9366 - val_loss: -0.8627 - val_cosine_similarity: -0.8611\n",
            "Epoch 116/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9366 - cosine_similarity: -0.9366 - val_loss: -0.8627 - val_cosine_similarity: -0.8610\n",
            "Epoch 117/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9366 - cosine_similarity: -0.9366 - val_loss: -0.8627 - val_cosine_similarity: -0.8611\n",
            "Epoch 1/200\n",
            "94/94 [==============================] - 1s 3ms/step - loss: -0.5827 - cosine_similarity: -0.5828 - val_loss: -0.6268 - val_cosine_similarity: -0.6259\n",
            "Epoch 2/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.7186 - cosine_similarity: -0.7187 - val_loss: -0.7021 - val_cosine_similarity: -0.7005\n",
            "Epoch 3/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.7886 - cosine_similarity: -0.7887 - val_loss: -0.7464 - val_cosine_similarity: -0.7445\n",
            "Epoch 4/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.8310 - cosine_similarity: -0.8312 - val_loss: -0.7748 - val_cosine_similarity: -0.7728\n",
            "Epoch 5/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.8588 - cosine_similarity: -0.8589 - val_loss: -0.7947 - val_cosine_similarity: -0.7925\n",
            "Epoch 6/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.8779 - cosine_similarity: -0.8778 - val_loss: -0.8086 - val_cosine_similarity: -0.8064\n",
            "Epoch 7/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.8917 - cosine_similarity: -0.8917 - val_loss: -0.8193 - val_cosine_similarity: -0.8171\n",
            "Epoch 8/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9016 - cosine_similarity: -0.9016 - val_loss: -0.8273 - val_cosine_similarity: -0.8250\n",
            "Epoch 9/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9093 - cosine_similarity: -0.9092 - val_loss: -0.8337 - val_cosine_similarity: -0.8314\n",
            "Epoch 10/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9150 - cosine_similarity: -0.9149 - val_loss: -0.8388 - val_cosine_similarity: -0.8366\n",
            "Epoch 11/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9194 - cosine_similarity: -0.9194 - val_loss: -0.8426 - val_cosine_similarity: -0.8403\n",
            "Epoch 12/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9228 - cosine_similarity: -0.9227 - val_loss: -0.8465 - val_cosine_similarity: -0.8443\n",
            "Epoch 13/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9254 - cosine_similarity: -0.9254 - val_loss: -0.8490 - val_cosine_similarity: -0.8467\n",
            "Epoch 14/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9275 - cosine_similarity: -0.9275 - val_loss: -0.8509 - val_cosine_similarity: -0.8487\n",
            "Epoch 15/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9292 - cosine_similarity: -0.9292 - val_loss: -0.8529 - val_cosine_similarity: -0.8507\n",
            "Epoch 16/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9305 - cosine_similarity: -0.9305 - val_loss: -0.8546 - val_cosine_similarity: -0.8523\n",
            "Epoch 17/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9316 - cosine_similarity: -0.9316 - val_loss: -0.8556 - val_cosine_similarity: -0.8534\n",
            "Epoch 18/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9325 - cosine_similarity: -0.9325 - val_loss: -0.8566 - val_cosine_similarity: -0.8544\n",
            "Epoch 19/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9333 - cosine_similarity: -0.9332 - val_loss: -0.8575 - val_cosine_similarity: -0.8553\n",
            "Epoch 20/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9338 - cosine_similarity: -0.9338 - val_loss: -0.8584 - val_cosine_similarity: -0.8561\n",
            "Epoch 21/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9342 - cosine_similarity: -0.9342 - val_loss: -0.8587 - val_cosine_similarity: -0.8564\n",
            "Epoch 22/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9346 - cosine_similarity: -0.9346 - val_loss: -0.8596 - val_cosine_similarity: -0.8575\n",
            "Epoch 23/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9352 - cosine_similarity: -0.9352 - val_loss: -0.8600 - val_cosine_similarity: -0.8578\n",
            "Epoch 24/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9352 - cosine_similarity: -0.9352 - val_loss: -0.8605 - val_cosine_similarity: -0.8582\n",
            "Epoch 25/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9357 - cosine_similarity: -0.9357 - val_loss: -0.8606 - val_cosine_similarity: -0.8583\n",
            "Epoch 26/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9358 - cosine_similarity: -0.9357 - val_loss: -0.8607 - val_cosine_similarity: -0.8585\n",
            "Epoch 27/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9361 - cosine_similarity: -0.9362 - val_loss: -0.8609 - val_cosine_similarity: -0.8587\n",
            "Epoch 28/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9363 - cosine_similarity: -0.9363 - val_loss: -0.8613 - val_cosine_similarity: -0.8591\n",
            "Epoch 29/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9364 - cosine_similarity: -0.9363 - val_loss: -0.8616 - val_cosine_similarity: -0.8595\n",
            "Epoch 30/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9365 - cosine_similarity: -0.9365 - val_loss: -0.8617 - val_cosine_similarity: -0.8595\n",
            "Epoch 31/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9366 - cosine_similarity: -0.9365 - val_loss: -0.8621 - val_cosine_similarity: -0.8599\n",
            "Epoch 32/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9368 - cosine_similarity: -0.9367 - val_loss: -0.8618 - val_cosine_similarity: -0.8596\n",
            "Epoch 33/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9369 - cosine_similarity: -0.9368 - val_loss: -0.8623 - val_cosine_similarity: -0.8600\n",
            "Epoch 34/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9370 - cosine_similarity: -0.9369 - val_loss: -0.8621 - val_cosine_similarity: -0.8598\n",
            "Epoch 35/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9372 - cosine_similarity: -0.9372 - val_loss: -0.8623 - val_cosine_similarity: -0.8601\n",
            "Epoch 36/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9372 - cosine_similarity: -0.9372 - val_loss: -0.8625 - val_cosine_similarity: -0.8602\n",
            "Epoch 37/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9372 - cosine_similarity: -0.9372 - val_loss: -0.8626 - val_cosine_similarity: -0.8603\n",
            "Epoch 38/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9374 - cosine_similarity: -0.9373 - val_loss: -0.8622 - val_cosine_similarity: -0.8600\n",
            "Epoch 39/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9374 - cosine_similarity: -0.9374 - val_loss: -0.8627 - val_cosine_similarity: -0.8605\n",
            "Epoch 40/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9375 - cosine_similarity: -0.9374 - val_loss: -0.8627 - val_cosine_similarity: -0.8605\n",
            "Epoch 41/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9376 - cosine_similarity: -0.9375 - val_loss: -0.8624 - val_cosine_similarity: -0.8602\n",
            "Epoch 42/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9377 - cosine_similarity: -0.9376 - val_loss: -0.8627 - val_cosine_similarity: -0.8605\n",
            "Epoch 43/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9376 - cosine_similarity: -0.9376 - val_loss: -0.8630 - val_cosine_similarity: -0.8608\n",
            "Epoch 44/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9374 - cosine_similarity: -0.9374 - val_loss: -0.8628 - val_cosine_similarity: -0.8606\n",
            "Epoch 45/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9378 - cosine_similarity: -0.9378 - val_loss: -0.8627 - val_cosine_similarity: -0.8605\n",
            "Epoch 46/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9379 - cosine_similarity: -0.9378 - val_loss: -0.8632 - val_cosine_similarity: -0.8609\n",
            "Epoch 47/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9378 - cosine_similarity: -0.9378 - val_loss: -0.8630 - val_cosine_similarity: -0.8608\n",
            "Epoch 48/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9379 - cosine_similarity: -0.9378 - val_loss: -0.8630 - val_cosine_similarity: -0.8609\n",
            "Epoch 49/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9378 - cosine_similarity: -0.9378 - val_loss: -0.8630 - val_cosine_similarity: -0.8608\n",
            "Epoch 50/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9381 - cosine_similarity: -0.9381 - val_loss: -0.8630 - val_cosine_similarity: -0.8607\n",
            "Epoch 51/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9381 - cosine_similarity: -0.9380 - val_loss: -0.8629 - val_cosine_similarity: -0.8607\n",
            "Epoch 52/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9379 - cosine_similarity: -0.9379 - val_loss: -0.8632 - val_cosine_similarity: -0.8610\n",
            "Epoch 53/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9381 - cosine_similarity: -0.9380 - val_loss: -0.8632 - val_cosine_similarity: -0.8610\n",
            "Epoch 54/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9382 - cosine_similarity: -0.9382 - val_loss: -0.8630 - val_cosine_similarity: -0.8608\n",
            "Epoch 55/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9381 - cosine_similarity: -0.9380 - val_loss: -0.8631 - val_cosine_similarity: -0.8608\n",
            "Epoch 56/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9381 - cosine_similarity: -0.9382 - val_loss: -0.8631 - val_cosine_similarity: -0.8609\n",
            "Epoch 57/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9383 - cosine_similarity: -0.9383 - val_loss: -0.8628 - val_cosine_similarity: -0.8606\n",
            "Epoch 58/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9382 - cosine_similarity: -0.9382 - val_loss: -0.8633 - val_cosine_similarity: -0.8610\n",
            "Epoch 59/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9384 - cosine_similarity: -0.9385 - val_loss: -0.8629 - val_cosine_similarity: -0.8608\n",
            "Epoch 60/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9383 - cosine_similarity: -0.9383 - val_loss: -0.8632 - val_cosine_similarity: -0.8610\n",
            "Epoch 61/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9383 - cosine_similarity: -0.9382 - val_loss: -0.8632 - val_cosine_similarity: -0.8609\n",
            "Epoch 62/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9383 - cosine_similarity: -0.9383 - val_loss: -0.8630 - val_cosine_similarity: -0.8608\n",
            "Epoch 63/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9385 - cosine_similarity: -0.9385 - val_loss: -0.8634 - val_cosine_similarity: -0.8612\n",
            "Epoch 64/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9386 - cosine_similarity: -0.9385 - val_loss: -0.8631 - val_cosine_similarity: -0.8608\n",
            "Epoch 65/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9385 - cosine_similarity: -0.9384 - val_loss: -0.8631 - val_cosine_similarity: -0.8608\n",
            "Epoch 66/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9385 - cosine_similarity: -0.9385 - val_loss: -0.8629 - val_cosine_similarity: -0.8606\n",
            "Epoch 67/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9385 - cosine_similarity: -0.9385 - val_loss: -0.8633 - val_cosine_similarity: -0.8610\n",
            "Epoch 68/200\n",
            "94/94 [==============================] - 0s 3ms/step - loss: -0.9384 - cosine_similarity: -0.9384 - val_loss: -0.8633 - val_cosine_similarity: -0.8610\n",
            "Epoch 69/200\n",
            "94/94 [==============================] - 0s 3ms/step - loss: -0.9386 - cosine_similarity: -0.9385 - val_loss: -0.8630 - val_cosine_similarity: -0.8608\n",
            "{}\n",
            "Epoch 1/200\n",
            "94/94 [==============================] - 1s 3ms/step - loss: -0.5452 - cosine_similarity: -0.5458 - val_loss: -0.7051 - val_cosine_similarity: -0.7038\n",
            "Epoch 2/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.7972 - cosine_similarity: -0.7973 - val_loss: -0.7736 - val_cosine_similarity: -0.7724\n",
            "Epoch 3/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.8523 - cosine_similarity: -0.8523 - val_loss: -0.8012 - val_cosine_similarity: -0.8001\n",
            "Epoch 4/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.8777 - cosine_similarity: -0.8775 - val_loss: -0.8170 - val_cosine_similarity: -0.8160\n",
            "Epoch 5/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.8912 - cosine_similarity: -0.8911 - val_loss: -0.8260 - val_cosine_similarity: -0.8251\n",
            "Epoch 6/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.8993 - cosine_similarity: -0.8992 - val_loss: -0.8299 - val_cosine_similarity: -0.8291\n",
            "Epoch 7/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9041 - cosine_similarity: -0.9042 - val_loss: -0.8343 - val_cosine_similarity: -0.8335\n",
            "Epoch 8/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9079 - cosine_similarity: -0.9079 - val_loss: -0.8365 - val_cosine_similarity: -0.8357\n",
            "Epoch 9/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9102 - cosine_similarity: -0.9102 - val_loss: -0.8383 - val_cosine_similarity: -0.8375\n",
            "Epoch 10/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9124 - cosine_similarity: -0.9124 - val_loss: -0.8396 - val_cosine_similarity: -0.8389\n",
            "Epoch 11/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9138 - cosine_similarity: -0.9138 - val_loss: -0.8407 - val_cosine_similarity: -0.8399\n",
            "Epoch 12/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9151 - cosine_similarity: -0.9151 - val_loss: -0.8415 - val_cosine_similarity: -0.8406\n",
            "Epoch 13/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9159 - cosine_similarity: -0.9159 - val_loss: -0.8421 - val_cosine_similarity: -0.8413\n",
            "Epoch 14/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9163 - cosine_similarity: -0.9163 - val_loss: -0.8428 - val_cosine_similarity: -0.8420\n",
            "Epoch 15/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9172 - cosine_similarity: -0.9172 - val_loss: -0.8431 - val_cosine_similarity: -0.8424\n",
            "Epoch 16/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9176 - cosine_similarity: -0.9176 - val_loss: -0.8432 - val_cosine_similarity: -0.8424\n",
            "Epoch 17/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9180 - cosine_similarity: -0.9179 - val_loss: -0.8430 - val_cosine_similarity: -0.8423\n",
            "Epoch 18/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9184 - cosine_similarity: -0.9184 - val_loss: -0.8440 - val_cosine_similarity: -0.8432\n",
            "Epoch 19/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9186 - cosine_similarity: -0.9186 - val_loss: -0.8435 - val_cosine_similarity: -0.8427\n",
            "Epoch 20/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9191 - cosine_similarity: -0.9190 - val_loss: -0.8447 - val_cosine_similarity: -0.8439\n",
            "Epoch 21/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9195 - cosine_similarity: -0.9195 - val_loss: -0.8447 - val_cosine_similarity: -0.8440\n",
            "Epoch 22/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9193 - cosine_similarity: -0.9192 - val_loss: -0.8444 - val_cosine_similarity: -0.8437\n",
            "Epoch 23/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9197 - cosine_similarity: -0.9197 - val_loss: -0.8444 - val_cosine_similarity: -0.8437\n",
            "Epoch 24/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9197 - cosine_similarity: -0.9198 - val_loss: -0.8446 - val_cosine_similarity: -0.8439\n",
            "Epoch 25/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9200 - cosine_similarity: -0.9200 - val_loss: -0.8442 - val_cosine_similarity: -0.8435\n",
            "Epoch 26/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9201 - cosine_similarity: -0.9201 - val_loss: -0.8437 - val_cosine_similarity: -0.8430\n",
            "Epoch 27/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9204 - cosine_similarity: -0.9204 - val_loss: -0.8448 - val_cosine_similarity: -0.8440\n",
            "Epoch 28/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9205 - cosine_similarity: -0.9205 - val_loss: -0.8446 - val_cosine_similarity: -0.8439\n",
            "Epoch 29/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9204 - cosine_similarity: -0.9204 - val_loss: -0.8450 - val_cosine_similarity: -0.8443\n",
            "Epoch 30/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9206 - cosine_similarity: -0.9206 - val_loss: -0.8446 - val_cosine_similarity: -0.8439\n",
            "Epoch 31/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9207 - cosine_similarity: -0.9207 - val_loss: -0.8445 - val_cosine_similarity: -0.8438\n",
            "Epoch 32/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9207 - cosine_similarity: -0.9207 - val_loss: -0.8450 - val_cosine_similarity: -0.8442\n",
            "Epoch 33/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9210 - cosine_similarity: -0.9209 - val_loss: -0.8451 - val_cosine_similarity: -0.8444\n",
            "Epoch 34/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9209 - cosine_similarity: -0.9208 - val_loss: -0.8448 - val_cosine_similarity: -0.8441\n",
            "Epoch 35/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9211 - cosine_similarity: -0.9211 - val_loss: -0.8447 - val_cosine_similarity: -0.8440\n",
            "Epoch 36/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9214 - cosine_similarity: -0.9214 - val_loss: -0.8447 - val_cosine_similarity: -0.8440\n",
            "Epoch 37/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9214 - cosine_similarity: -0.9213 - val_loss: -0.8441 - val_cosine_similarity: -0.8434\n",
            "Epoch 38/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9214 - cosine_similarity: -0.9213 - val_loss: -0.8448 - val_cosine_similarity: -0.8441\n",
            "Epoch 39/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9212 - cosine_similarity: -0.9212 - val_loss: -0.8453 - val_cosine_similarity: -0.8446\n",
            "Epoch 40/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9214 - cosine_similarity: -0.9214 - val_loss: -0.8448 - val_cosine_similarity: -0.8441\n",
            "Epoch 41/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9215 - cosine_similarity: -0.9215 - val_loss: -0.8450 - val_cosine_similarity: -0.8443\n",
            "Epoch 42/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9218 - cosine_similarity: -0.9218 - val_loss: -0.8452 - val_cosine_similarity: -0.8445\n",
            "Epoch 43/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9217 - cosine_similarity: -0.9218 - val_loss: -0.8451 - val_cosine_similarity: -0.8444\n",
            "Epoch 44/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9217 - cosine_similarity: -0.9216 - val_loss: -0.8452 - val_cosine_similarity: -0.8444\n",
            "Epoch 45/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9219 - cosine_similarity: -0.9217 - val_loss: -0.8442 - val_cosine_similarity: -0.8435\n",
            "Epoch 46/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9218 - cosine_similarity: -0.9218 - val_loss: -0.8449 - val_cosine_similarity: -0.8441\n",
            "Epoch 47/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9220 - cosine_similarity: -0.9220 - val_loss: -0.8446 - val_cosine_similarity: -0.8439\n",
            "Epoch 48/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9221 - cosine_similarity: -0.9220 - val_loss: -0.8453 - val_cosine_similarity: -0.8446\n",
            "Epoch 49/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9221 - cosine_similarity: -0.9221 - val_loss: -0.8447 - val_cosine_similarity: -0.8440\n",
            "Epoch 50/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9222 - cosine_similarity: -0.9222 - val_loss: -0.8450 - val_cosine_similarity: -0.8443\n",
            "Epoch 51/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9224 - cosine_similarity: -0.9223 - val_loss: -0.8448 - val_cosine_similarity: -0.8440\n",
            "Epoch 52/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9222 - cosine_similarity: -0.9222 - val_loss: -0.8449 - val_cosine_similarity: -0.8441\n",
            "Epoch 53/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9226 - cosine_similarity: -0.9226 - val_loss: -0.8447 - val_cosine_similarity: -0.8440\n",
            "Epoch 54/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9223 - cosine_similarity: -0.9223 - val_loss: -0.8450 - val_cosine_similarity: -0.8443\n",
            "Epoch 55/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9225 - cosine_similarity: -0.9224 - val_loss: -0.8451 - val_cosine_similarity: -0.8444\n",
            "Epoch 56/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9226 - cosine_similarity: -0.9226 - val_loss: -0.8451 - val_cosine_similarity: -0.8444\n",
            "Epoch 57/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9226 - cosine_similarity: -0.9226 - val_loss: -0.8450 - val_cosine_similarity: -0.8443\n",
            "Epoch 58/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9228 - cosine_similarity: -0.9227 - val_loss: -0.8448 - val_cosine_similarity: -0.8441\n",
            "Epoch 59/200\n",
            "94/94 [==============================] - 0s 3ms/step - loss: -0.9227 - cosine_similarity: -0.9227 - val_loss: -0.8449 - val_cosine_similarity: -0.8442\n",
            "Epoch 60/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9228 - cosine_similarity: -0.9228 - val_loss: -0.8450 - val_cosine_similarity: -0.8442\n",
            "Epoch 61/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9229 - cosine_similarity: -0.9229 - val_loss: -0.8452 - val_cosine_similarity: -0.8444\n",
            "Epoch 62/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9229 - cosine_similarity: -0.9230 - val_loss: -0.8450 - val_cosine_similarity: -0.8442\n",
            "Epoch 63/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9229 - cosine_similarity: -0.9228 - val_loss: -0.8449 - val_cosine_similarity: -0.8441\n",
            "Epoch 64/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9230 - cosine_similarity: -0.9230 - val_loss: -0.8450 - val_cosine_similarity: -0.8442\n",
            "Epoch 65/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9230 - cosine_similarity: -0.9231 - val_loss: -0.8448 - val_cosine_similarity: -0.8441\n",
            "Epoch 66/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9233 - cosine_similarity: -0.9233 - val_loss: -0.8445 - val_cosine_similarity: -0.8438\n",
            "Epoch 67/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9230 - cosine_similarity: -0.9229 - val_loss: -0.8450 - val_cosine_similarity: -0.8442\n",
            "Epoch 68/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9231 - cosine_similarity: -0.9230 - val_loss: -0.8448 - val_cosine_similarity: -0.8440\n",
            "Epoch 69/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9231 - cosine_similarity: -0.9231 - val_loss: -0.8442 - val_cosine_similarity: -0.8435\n",
            "Epoch 70/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9232 - cosine_similarity: -0.9231 - val_loss: -0.8451 - val_cosine_similarity: -0.8443\n",
            "Epoch 71/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9234 - cosine_similarity: -0.9233 - val_loss: -0.8449 - val_cosine_similarity: -0.8441\n",
            "Epoch 72/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9235 - cosine_similarity: -0.9235 - val_loss: -0.8448 - val_cosine_similarity: -0.8440\n",
            "Epoch 73/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9235 - cosine_similarity: -0.9235 - val_loss: -0.8452 - val_cosine_similarity: -0.8445\n",
            "Epoch 74/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9234 - cosine_similarity: -0.9235 - val_loss: -0.8449 - val_cosine_similarity: -0.8442\n",
            "Epoch 75/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9235 - cosine_similarity: -0.9235 - val_loss: -0.8448 - val_cosine_similarity: -0.8440\n",
            "Epoch 76/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9234 - cosine_similarity: -0.9234 - val_loss: -0.8445 - val_cosine_similarity: -0.8437\n",
            "Epoch 77/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9235 - cosine_similarity: -0.9236 - val_loss: -0.8446 - val_cosine_similarity: -0.8438\n",
            "Epoch 78/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9235 - cosine_similarity: -0.9236 - val_loss: -0.8447 - val_cosine_similarity: -0.8440\n",
            "Epoch 79/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9236 - cosine_similarity: -0.9236 - val_loss: -0.8449 - val_cosine_similarity: -0.8441\n",
            "Epoch 80/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9238 - cosine_similarity: -0.9238 - val_loss: -0.8451 - val_cosine_similarity: -0.8443\n",
            "Epoch 81/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9237 - cosine_similarity: -0.9237 - val_loss: -0.8446 - val_cosine_similarity: -0.8438\n",
            "Epoch 82/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9238 - cosine_similarity: -0.9238 - val_loss: -0.8450 - val_cosine_similarity: -0.8443\n",
            "Epoch 83/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9238 - cosine_similarity: -0.9237 - val_loss: -0.8452 - val_cosine_similarity: -0.8445\n",
            "Epoch 84/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9238 - cosine_similarity: -0.9239 - val_loss: -0.8446 - val_cosine_similarity: -0.8438\n",
            "Epoch 85/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9240 - cosine_similarity: -0.9239 - val_loss: -0.8446 - val_cosine_similarity: -0.8439\n",
            "Epoch 86/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9240 - cosine_similarity: -0.9240 - val_loss: -0.8443 - val_cosine_similarity: -0.8436\n",
            "Epoch 87/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9239 - cosine_similarity: -0.9239 - val_loss: -0.8451 - val_cosine_similarity: -0.8443\n",
            "Epoch 88/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9242 - cosine_similarity: -0.9241 - val_loss: -0.8445 - val_cosine_similarity: -0.8438\n",
            "Epoch 89/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9240 - cosine_similarity: -0.9240 - val_loss: -0.8443 - val_cosine_similarity: -0.8435\n",
            "Epoch 90/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9242 - cosine_similarity: -0.9242 - val_loss: -0.8444 - val_cosine_similarity: -0.8436\n",
            "Epoch 91/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9241 - cosine_similarity: -0.9241 - val_loss: -0.8444 - val_cosine_similarity: -0.8437\n",
            "Epoch 92/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9242 - cosine_similarity: -0.9242 - val_loss: -0.8448 - val_cosine_similarity: -0.8441\n",
            "Epoch 93/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9242 - cosine_similarity: -0.9242 - val_loss: -0.8448 - val_cosine_similarity: -0.8440\n",
            "Epoch 94/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9242 - cosine_similarity: -0.9241 - val_loss: -0.8444 - val_cosine_similarity: -0.8436\n",
            "Epoch 95/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9242 - cosine_similarity: -0.9241 - val_loss: -0.8446 - val_cosine_similarity: -0.8439\n",
            "Epoch 96/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9243 - cosine_similarity: -0.9242 - val_loss: -0.8449 - val_cosine_similarity: -0.8442\n",
            "Epoch 97/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9243 - cosine_similarity: -0.9244 - val_loss: -0.8447 - val_cosine_similarity: -0.8439\n",
            "Epoch 98/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9243 - cosine_similarity: -0.9243 - val_loss: -0.8442 - val_cosine_similarity: -0.8434\n",
            "Epoch 99/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9244 - cosine_similarity: -0.9244 - val_loss: -0.8445 - val_cosine_similarity: -0.8438\n",
            "Epoch 100/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9245 - cosine_similarity: -0.9245 - val_loss: -0.8446 - val_cosine_similarity: -0.8438\n",
            "Epoch 101/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9245 - cosine_similarity: -0.9245 - val_loss: -0.8445 - val_cosine_similarity: -0.8438\n",
            "Epoch 102/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9245 - cosine_similarity: -0.9245 - val_loss: -0.8449 - val_cosine_similarity: -0.8441\n",
            "Epoch 103/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9244 - cosine_similarity: -0.9243 - val_loss: -0.8446 - val_cosine_similarity: -0.8438\n",
            "Epoch 104/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9244 - cosine_similarity: -0.9244 - val_loss: -0.8441 - val_cosine_similarity: -0.8434\n",
            "Epoch 105/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9246 - cosine_similarity: -0.9246 - val_loss: -0.8447 - val_cosine_similarity: -0.8439\n",
            "Epoch 106/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9247 - cosine_similarity: -0.9247 - val_loss: -0.8447 - val_cosine_similarity: -0.8439\n",
            "Epoch 107/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9248 - cosine_similarity: -0.9248 - val_loss: -0.8448 - val_cosine_similarity: -0.8441\n",
            "Epoch 108/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9246 - cosine_similarity: -0.9246 - val_loss: -0.8445 - val_cosine_similarity: -0.8438\n",
            "Epoch 109/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9246 - cosine_similarity: -0.9247 - val_loss: -0.8440 - val_cosine_similarity: -0.8432\n",
            "Epoch 110/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9247 - cosine_similarity: -0.9246 - val_loss: -0.8444 - val_cosine_similarity: -0.8437\n",
            "Epoch 111/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9247 - cosine_similarity: -0.9246 - val_loss: -0.8446 - val_cosine_similarity: -0.8438\n",
            "Epoch 112/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9248 - cosine_similarity: -0.9247 - val_loss: -0.8445 - val_cosine_similarity: -0.8437\n",
            "Epoch 1/200\n",
            "94/94 [==============================] - 1s 3ms/step - loss: -0.5260 - cosine_similarity: -0.5264 - val_loss: -0.5872 - val_cosine_similarity: -0.5871\n",
            "Epoch 2/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.6828 - cosine_similarity: -0.6830 - val_loss: -0.6770 - val_cosine_similarity: -0.6758\n",
            "Epoch 3/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.7671 - cosine_similarity: -0.7671 - val_loss: -0.7298 - val_cosine_similarity: -0.7281\n",
            "Epoch 4/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.8190 - cosine_similarity: -0.8190 - val_loss: -0.7632 - val_cosine_similarity: -0.7613\n",
            "Epoch 5/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.8517 - cosine_similarity: -0.8518 - val_loss: -0.7850 - val_cosine_similarity: -0.7829\n",
            "Epoch 6/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.8726 - cosine_similarity: -0.8725 - val_loss: -0.7998 - val_cosine_similarity: -0.7978\n",
            "Epoch 7/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.8869 - cosine_similarity: -0.8870 - val_loss: -0.8103 - val_cosine_similarity: -0.8083\n",
            "Epoch 8/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.8973 - cosine_similarity: -0.8974 - val_loss: -0.8188 - val_cosine_similarity: -0.8169\n",
            "Epoch 9/200\n",
            "94/94 [==============================] - 0s 3ms/step - loss: -0.9051 - cosine_similarity: -0.9051 - val_loss: -0.8250 - val_cosine_similarity: -0.8231\n",
            "Epoch 10/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9112 - cosine_similarity: -0.9112 - val_loss: -0.8296 - val_cosine_similarity: -0.8278\n",
            "Epoch 11/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9157 - cosine_similarity: -0.9157 - val_loss: -0.8341 - val_cosine_similarity: -0.8322\n",
            "Epoch 12/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9193 - cosine_similarity: -0.9193 - val_loss: -0.8370 - val_cosine_similarity: -0.8354\n",
            "Epoch 13/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9221 - cosine_similarity: -0.9222 - val_loss: -0.8398 - val_cosine_similarity: -0.8382\n",
            "Epoch 14/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9244 - cosine_similarity: -0.9244 - val_loss: -0.8420 - val_cosine_similarity: -0.8403\n",
            "Epoch 15/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9262 - cosine_similarity: -0.9263 - val_loss: -0.8434 - val_cosine_similarity: -0.8418\n",
            "Epoch 16/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9276 - cosine_similarity: -0.9276 - val_loss: -0.8451 - val_cosine_similarity: -0.8435\n",
            "Epoch 17/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9288 - cosine_similarity: -0.9287 - val_loss: -0.8461 - val_cosine_similarity: -0.8446\n",
            "Epoch 18/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9297 - cosine_similarity: -0.9297 - val_loss: -0.8474 - val_cosine_similarity: -0.8458\n",
            "Epoch 19/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9306 - cosine_similarity: -0.9306 - val_loss: -0.8482 - val_cosine_similarity: -0.8467\n",
            "Epoch 20/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9315 - cosine_similarity: -0.9314 - val_loss: -0.8489 - val_cosine_similarity: -0.8473\n",
            "Epoch 21/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9315 - cosine_similarity: -0.9314 - val_loss: -0.8490 - val_cosine_similarity: -0.8475\n",
            "Epoch 22/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9323 - cosine_similarity: -0.9322 - val_loss: -0.8497 - val_cosine_similarity: -0.8482\n",
            "Epoch 23/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9326 - cosine_similarity: -0.9326 - val_loss: -0.8504 - val_cosine_similarity: -0.8490\n",
            "Epoch 24/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9331 - cosine_similarity: -0.9330 - val_loss: -0.8507 - val_cosine_similarity: -0.8492\n",
            "Epoch 25/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9332 - cosine_similarity: -0.9332 - val_loss: -0.8509 - val_cosine_similarity: -0.8495\n",
            "Epoch 26/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9335 - cosine_similarity: -0.9334 - val_loss: -0.8510 - val_cosine_similarity: -0.8496\n",
            "Epoch 27/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9338 - cosine_similarity: -0.9337 - val_loss: -0.8517 - val_cosine_similarity: -0.8502\n",
            "Epoch 28/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9340 - cosine_similarity: -0.9340 - val_loss: -0.8520 - val_cosine_similarity: -0.8505\n",
            "Epoch 29/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9341 - cosine_similarity: -0.9341 - val_loss: -0.8516 - val_cosine_similarity: -0.8503\n",
            "Epoch 30/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9341 - cosine_similarity: -0.9342 - val_loss: -0.8520 - val_cosine_similarity: -0.8504\n",
            "Epoch 31/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9345 - cosine_similarity: -0.9344 - val_loss: -0.8528 - val_cosine_similarity: -0.8511\n",
            "Epoch 32/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9345 - cosine_similarity: -0.9345 - val_loss: -0.8525 - val_cosine_similarity: -0.8511\n",
            "Epoch 33/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9346 - cosine_similarity: -0.9346 - val_loss: -0.8526 - val_cosine_similarity: -0.8511\n",
            "Epoch 34/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9347 - cosine_similarity: -0.9347 - val_loss: -0.8525 - val_cosine_similarity: -0.8511\n",
            "Epoch 35/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9347 - cosine_similarity: -0.9347 - val_loss: -0.8527 - val_cosine_similarity: -0.8512\n",
            "Epoch 36/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9349 - cosine_similarity: -0.9349 - val_loss: -0.8511 - val_cosine_similarity: -0.8489\n",
            "Epoch 37/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9346 - cosine_similarity: -0.9346 - val_loss: -0.8530 - val_cosine_similarity: -0.8516\n",
            "Epoch 38/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9352 - cosine_similarity: -0.9352 - val_loss: -0.8527 - val_cosine_similarity: -0.8512\n",
            "Epoch 39/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9354 - cosine_similarity: -0.9353 - val_loss: -0.8527 - val_cosine_similarity: -0.8512\n",
            "Epoch 40/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9354 - cosine_similarity: -0.9354 - val_loss: -0.8530 - val_cosine_similarity: -0.8516\n",
            "Epoch 41/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9353 - cosine_similarity: -0.9353 - val_loss: -0.8531 - val_cosine_similarity: -0.8517\n",
            "Epoch 42/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9354 - cosine_similarity: -0.9353 - val_loss: -0.8530 - val_cosine_similarity: -0.8515\n",
            "Epoch 43/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9354 - cosine_similarity: -0.9354 - val_loss: -0.8531 - val_cosine_similarity: -0.8516\n",
            "Epoch 44/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9355 - cosine_similarity: -0.9355 - val_loss: -0.8530 - val_cosine_similarity: -0.8515\n",
            "Epoch 45/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9355 - cosine_similarity: -0.9355 - val_loss: -0.8530 - val_cosine_similarity: -0.8515\n",
            "Epoch 46/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9355 - cosine_similarity: -0.9355 - val_loss: -0.8529 - val_cosine_similarity: -0.8513\n",
            "Epoch 47/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9355 - cosine_similarity: -0.9355 - val_loss: -0.8534 - val_cosine_similarity: -0.8519\n",
            "Epoch 48/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9357 - cosine_similarity: -0.9357 - val_loss: -0.8529 - val_cosine_similarity: -0.8514\n",
            "Epoch 49/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9357 - cosine_similarity: -0.9357 - val_loss: -0.8526 - val_cosine_similarity: -0.8509\n",
            "Epoch 50/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9358 - cosine_similarity: -0.9357 - val_loss: -0.8535 - val_cosine_similarity: -0.8520\n",
            "Epoch 51/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9359 - cosine_similarity: -0.9358 - val_loss: -0.8529 - val_cosine_similarity: -0.8513\n",
            "Epoch 52/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9356 - cosine_similarity: -0.9356 - val_loss: -0.8532 - val_cosine_similarity: -0.8517\n",
            "Epoch 53/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9360 - cosine_similarity: -0.9359 - val_loss: -0.8532 - val_cosine_similarity: -0.8517\n",
            "Epoch 54/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9360 - cosine_similarity: -0.9361 - val_loss: -0.8532 - val_cosine_similarity: -0.8517\n",
            "Epoch 55/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9360 - cosine_similarity: -0.9360 - val_loss: -0.8527 - val_cosine_similarity: -0.8511\n",
            "Epoch 56/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9358 - cosine_similarity: -0.9358 - val_loss: -0.8536 - val_cosine_similarity: -0.8520\n",
            "Epoch 57/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9361 - cosine_similarity: -0.9361 - val_loss: -0.8532 - val_cosine_similarity: -0.8519\n",
            "Epoch 58/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9356 - cosine_similarity: -0.9355 - val_loss: -0.8534 - val_cosine_similarity: -0.8518\n",
            "Epoch 59/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9361 - cosine_similarity: -0.9361 - val_loss: -0.8532 - val_cosine_similarity: -0.8518\n",
            "Epoch 60/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9363 - cosine_similarity: -0.9363 - val_loss: -0.8535 - val_cosine_similarity: -0.8519\n",
            "Epoch 61/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9363 - cosine_similarity: -0.9362 - val_loss: -0.8533 - val_cosine_similarity: -0.8518\n",
            "Epoch 62/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9362 - cosine_similarity: -0.9362 - val_loss: -0.8534 - val_cosine_similarity: -0.8518\n",
            "Epoch 63/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9361 - cosine_similarity: -0.9360 - val_loss: -0.8531 - val_cosine_similarity: -0.8517\n",
            "Epoch 64/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9362 - cosine_similarity: -0.9362 - val_loss: -0.8533 - val_cosine_similarity: -0.8518\n",
            "Epoch 65/200\n",
            "94/94 [==============================] - 0s 3ms/step - loss: -0.9363 - cosine_similarity: -0.9363 - val_loss: -0.8531 - val_cosine_similarity: -0.8517\n",
            "Epoch 66/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9363 - cosine_similarity: -0.9363 - val_loss: -0.8533 - val_cosine_similarity: -0.8518\n",
            "{}\n",
            "Epoch 1/200\n",
            "94/94 [==============================] - 1s 3ms/step - loss: -0.5693 - cosine_similarity: -0.5698 - val_loss: -0.7179 - val_cosine_similarity: -0.7155\n",
            "Epoch 2/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.8118 - cosine_similarity: -0.8119 - val_loss: -0.7883 - val_cosine_similarity: -0.7855\n",
            "Epoch 3/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.8672 - cosine_similarity: -0.8671 - val_loss: -0.8164 - val_cosine_similarity: -0.8136\n",
            "Epoch 4/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.8918 - cosine_similarity: -0.8918 - val_loss: -0.8321 - val_cosine_similarity: -0.8294\n",
            "Epoch 5/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9051 - cosine_similarity: -0.9050 - val_loss: -0.8410 - val_cosine_similarity: -0.8386\n",
            "Epoch 6/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9130 - cosine_similarity: -0.9129 - val_loss: -0.8465 - val_cosine_similarity: -0.8442\n",
            "Epoch 7/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9182 - cosine_similarity: -0.9183 - val_loss: -0.8502 - val_cosine_similarity: -0.8478\n",
            "Epoch 8/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9217 - cosine_similarity: -0.9217 - val_loss: -0.8536 - val_cosine_similarity: -0.8512\n",
            "Epoch 9/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9239 - cosine_similarity: -0.9238 - val_loss: -0.8550 - val_cosine_similarity: -0.8526\n",
            "Epoch 10/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9260 - cosine_similarity: -0.9259 - val_loss: -0.8570 - val_cosine_similarity: -0.8547\n",
            "Epoch 11/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9272 - cosine_similarity: -0.9272 - val_loss: -0.8586 - val_cosine_similarity: -0.8564\n",
            "Epoch 12/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9280 - cosine_similarity: -0.9280 - val_loss: -0.8589 - val_cosine_similarity: -0.8567\n",
            "Epoch 13/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9289 - cosine_similarity: -0.9288 - val_loss: -0.8598 - val_cosine_similarity: -0.8575\n",
            "Epoch 14/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9297 - cosine_similarity: -0.9297 - val_loss: -0.8602 - val_cosine_similarity: -0.8580\n",
            "Epoch 15/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9301 - cosine_similarity: -0.9300 - val_loss: -0.8605 - val_cosine_similarity: -0.8584\n",
            "Epoch 16/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9306 - cosine_similarity: -0.9307 - val_loss: -0.8610 - val_cosine_similarity: -0.8587\n",
            "Epoch 17/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9313 - cosine_similarity: -0.9312 - val_loss: -0.8615 - val_cosine_similarity: -0.8592\n",
            "Epoch 18/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9316 - cosine_similarity: -0.9316 - val_loss: -0.8616 - val_cosine_similarity: -0.8594\n",
            "Epoch 19/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9319 - cosine_similarity: -0.9319 - val_loss: -0.8621 - val_cosine_similarity: -0.8598\n",
            "Epoch 20/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9320 - cosine_similarity: -0.9319 - val_loss: -0.8625 - val_cosine_similarity: -0.8603\n",
            "Epoch 21/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9321 - cosine_similarity: -0.9322 - val_loss: -0.8622 - val_cosine_similarity: -0.8600\n",
            "Epoch 22/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9323 - cosine_similarity: -0.9322 - val_loss: -0.8627 - val_cosine_similarity: -0.8605\n",
            "Epoch 23/200\n",
            "94/94 [==============================] - 0s 3ms/step - loss: -0.9325 - cosine_similarity: -0.9325 - val_loss: -0.8624 - val_cosine_similarity: -0.8602\n",
            "Epoch 24/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9328 - cosine_similarity: -0.9329 - val_loss: -0.8625 - val_cosine_similarity: -0.8603\n",
            "Epoch 25/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9330 - cosine_similarity: -0.9330 - val_loss: -0.8624 - val_cosine_similarity: -0.8602\n",
            "Epoch 26/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9332 - cosine_similarity: -0.9332 - val_loss: -0.8625 - val_cosine_similarity: -0.8603\n",
            "Epoch 27/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9332 - cosine_similarity: -0.9332 - val_loss: -0.8625 - val_cosine_similarity: -0.8602\n",
            "Epoch 28/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9333 - cosine_similarity: -0.9334 - val_loss: -0.8626 - val_cosine_similarity: -0.8603\n",
            "Epoch 29/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9334 - cosine_similarity: -0.9334 - val_loss: -0.8627 - val_cosine_similarity: -0.8604\n",
            "Epoch 30/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9334 - cosine_similarity: -0.9334 - val_loss: -0.8631 - val_cosine_similarity: -0.8608\n",
            "Epoch 31/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9337 - cosine_similarity: -0.9336 - val_loss: -0.8629 - val_cosine_similarity: -0.8606\n",
            "Epoch 32/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9335 - cosine_similarity: -0.9336 - val_loss: -0.8627 - val_cosine_similarity: -0.8604\n",
            "Epoch 33/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9336 - cosine_similarity: -0.9336 - val_loss: -0.8631 - val_cosine_similarity: -0.8608\n",
            "Epoch 34/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9340 - cosine_similarity: -0.9340 - val_loss: -0.8631 - val_cosine_similarity: -0.8610\n",
            "Epoch 35/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9337 - cosine_similarity: -0.9338 - val_loss: -0.8629 - val_cosine_similarity: -0.8606\n",
            "Epoch 36/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9337 - cosine_similarity: -0.9336 - val_loss: -0.8626 - val_cosine_similarity: -0.8604\n",
            "Epoch 37/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9341 - cosine_similarity: -0.9341 - val_loss: -0.8632 - val_cosine_similarity: -0.8609\n",
            "Epoch 38/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9341 - cosine_similarity: -0.9341 - val_loss: -0.8632 - val_cosine_similarity: -0.8610\n",
            "Epoch 39/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9341 - cosine_similarity: -0.9341 - val_loss: -0.8628 - val_cosine_similarity: -0.8605\n",
            "Epoch 40/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9344 - cosine_similarity: -0.9344 - val_loss: -0.8630 - val_cosine_similarity: -0.8608\n",
            "Epoch 41/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9346 - cosine_similarity: -0.9345 - val_loss: -0.8628 - val_cosine_similarity: -0.8605\n",
            "Epoch 42/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9345 - cosine_similarity: -0.9345 - val_loss: -0.8633 - val_cosine_similarity: -0.8610\n",
            "Epoch 43/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9347 - cosine_similarity: -0.9347 - val_loss: -0.8635 - val_cosine_similarity: -0.8613\n",
            "Epoch 44/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9346 - cosine_similarity: -0.9346 - val_loss: -0.8634 - val_cosine_similarity: -0.8612\n",
            "Epoch 45/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9346 - cosine_similarity: -0.9346 - val_loss: -0.8636 - val_cosine_similarity: -0.8613\n",
            "Epoch 46/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9349 - cosine_similarity: -0.9348 - val_loss: -0.8630 - val_cosine_similarity: -0.8608\n",
            "Epoch 47/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9350 - cosine_similarity: -0.9350 - val_loss: -0.8631 - val_cosine_similarity: -0.8609\n",
            "Epoch 48/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9349 - cosine_similarity: -0.9349 - val_loss: -0.8629 - val_cosine_similarity: -0.8607\n",
            "Epoch 49/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9350 - cosine_similarity: -0.9350 - val_loss: -0.8634 - val_cosine_similarity: -0.8611\n",
            "Epoch 50/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9349 - cosine_similarity: -0.9349 - val_loss: -0.8631 - val_cosine_similarity: -0.8609\n",
            "Epoch 51/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9350 - cosine_similarity: -0.9351 - val_loss: -0.8635 - val_cosine_similarity: -0.8612\n",
            "Epoch 52/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9352 - cosine_similarity: -0.9352 - val_loss: -0.8632 - val_cosine_similarity: -0.8610\n",
            "Epoch 53/200\n",
            "94/94 [==============================] - 0s 3ms/step - loss: -0.9352 - cosine_similarity: -0.9352 - val_loss: -0.8637 - val_cosine_similarity: -0.8615\n",
            "Epoch 54/200\n",
            "94/94 [==============================] - 0s 3ms/step - loss: -0.9352 - cosine_similarity: -0.9351 - val_loss: -0.8629 - val_cosine_similarity: -0.8605\n",
            "Epoch 55/200\n",
            "94/94 [==============================] - 0s 3ms/step - loss: -0.9352 - cosine_similarity: -0.9352 - val_loss: -0.8628 - val_cosine_similarity: -0.8606\n",
            "Epoch 56/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9353 - cosine_similarity: -0.9353 - val_loss: -0.8634 - val_cosine_similarity: -0.8612\n",
            "Epoch 57/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9355 - cosine_similarity: -0.9354 - val_loss: -0.8635 - val_cosine_similarity: -0.8612\n",
            "Epoch 58/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9356 - cosine_similarity: -0.9356 - val_loss: -0.8632 - val_cosine_similarity: -0.8609\n",
            "Epoch 59/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9356 - cosine_similarity: -0.9356 - val_loss: -0.8632 - val_cosine_similarity: -0.8610\n",
            "Epoch 60/200\n",
            "94/94 [==============================] - 0s 3ms/step - loss: -0.9356 - cosine_similarity: -0.9355 - val_loss: -0.8630 - val_cosine_similarity: -0.8607\n",
            "Epoch 61/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9355 - cosine_similarity: -0.9354 - val_loss: -0.8630 - val_cosine_similarity: -0.8608\n",
            "Epoch 62/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9357 - cosine_similarity: -0.9357 - val_loss: -0.8629 - val_cosine_similarity: -0.8607\n",
            "Epoch 63/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9357 - cosine_similarity: -0.9356 - val_loss: -0.8631 - val_cosine_similarity: -0.8608\n",
            "Epoch 64/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9357 - cosine_similarity: -0.9357 - val_loss: -0.8632 - val_cosine_similarity: -0.8609\n",
            "Epoch 65/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9357 - cosine_similarity: -0.9357 - val_loss: -0.8628 - val_cosine_similarity: -0.8606\n",
            "Epoch 66/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9359 - cosine_similarity: -0.9359 - val_loss: -0.8630 - val_cosine_similarity: -0.8607\n",
            "Epoch 67/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9359 - cosine_similarity: -0.9359 - val_loss: -0.8634 - val_cosine_similarity: -0.8612\n",
            "Epoch 68/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9359 - cosine_similarity: -0.9359 - val_loss: -0.8626 - val_cosine_similarity: -0.8604\n",
            "Epoch 69/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9360 - cosine_similarity: -0.9360 - val_loss: -0.8631 - val_cosine_similarity: -0.8608\n",
            "Epoch 70/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9359 - cosine_similarity: -0.9359 - val_loss: -0.8633 - val_cosine_similarity: -0.8610\n",
            "Epoch 71/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9360 - cosine_similarity: -0.9360 - val_loss: -0.8630 - val_cosine_similarity: -0.8607\n",
            "Epoch 72/200\n",
            "94/94 [==============================] - 0s 3ms/step - loss: -0.9360 - cosine_similarity: -0.9361 - val_loss: -0.8631 - val_cosine_similarity: -0.8608\n",
            "Epoch 73/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9360 - cosine_similarity: -0.9360 - val_loss: -0.8633 - val_cosine_similarity: -0.8610\n",
            "Epoch 74/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9361 - cosine_similarity: -0.9362 - val_loss: -0.8624 - val_cosine_similarity: -0.8601\n",
            "Epoch 75/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9363 - cosine_similarity: -0.9363 - val_loss: -0.8633 - val_cosine_similarity: -0.8611\n",
            "Epoch 76/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9363 - cosine_similarity: -0.9363 - val_loss: -0.8631 - val_cosine_similarity: -0.8609\n",
            "Epoch 77/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9363 - cosine_similarity: -0.9363 - val_loss: -0.8630 - val_cosine_similarity: -0.8608\n",
            "Epoch 78/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9364 - cosine_similarity: -0.9364 - val_loss: -0.8632 - val_cosine_similarity: -0.8609\n",
            "Epoch 79/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9362 - cosine_similarity: -0.9361 - val_loss: -0.8631 - val_cosine_similarity: -0.8609\n",
            "Epoch 80/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9363 - cosine_similarity: -0.9363 - val_loss: -0.8629 - val_cosine_similarity: -0.8608\n",
            "Epoch 81/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9364 - cosine_similarity: -0.9365 - val_loss: -0.8630 - val_cosine_similarity: -0.8608\n",
            "Epoch 82/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9365 - cosine_similarity: -0.9365 - val_loss: -0.8632 - val_cosine_similarity: -0.8610\n",
            "Epoch 83/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9366 - cosine_similarity: -0.9366 - val_loss: -0.8631 - val_cosine_similarity: -0.8609\n",
            "Epoch 84/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9365 - cosine_similarity: -0.9365 - val_loss: -0.8632 - val_cosine_similarity: -0.8609\n",
            "Epoch 85/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9365 - cosine_similarity: -0.9365 - val_loss: -0.8628 - val_cosine_similarity: -0.8606\n",
            "Epoch 86/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9362 - cosine_similarity: -0.9362 - val_loss: -0.8629 - val_cosine_similarity: -0.8607\n",
            "Epoch 87/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9368 - cosine_similarity: -0.9368 - val_loss: -0.8631 - val_cosine_similarity: -0.8609\n",
            "Epoch 88/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9367 - cosine_similarity: -0.9367 - val_loss: -0.8630 - val_cosine_similarity: -0.8609\n",
            "Epoch 89/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9367 - cosine_similarity: -0.9367 - val_loss: -0.8629 - val_cosine_similarity: -0.8607\n",
            "Epoch 90/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9369 - cosine_similarity: -0.9367 - val_loss: -0.8632 - val_cosine_similarity: -0.8610\n",
            "Epoch 91/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9369 - cosine_similarity: -0.9368 - val_loss: -0.8631 - val_cosine_similarity: -0.8609\n",
            "Epoch 92/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9368 - cosine_similarity: -0.9368 - val_loss: -0.8628 - val_cosine_similarity: -0.8606\n",
            "Epoch 93/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9368 - cosine_similarity: -0.9368 - val_loss: -0.8630 - val_cosine_similarity: -0.8608\n",
            "Epoch 94/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9369 - cosine_similarity: -0.9369 - val_loss: -0.8631 - val_cosine_similarity: -0.8608\n",
            "Epoch 95/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9369 - cosine_similarity: -0.9369 - val_loss: -0.8631 - val_cosine_similarity: -0.8609\n",
            "Epoch 96/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9369 - cosine_similarity: -0.9369 - val_loss: -0.8630 - val_cosine_similarity: -0.8608\n",
            "Epoch 97/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9370 - cosine_similarity: -0.9369 - val_loss: -0.8630 - val_cosine_similarity: -0.8608\n",
            "Epoch 98/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9370 - cosine_similarity: -0.9370 - val_loss: -0.8630 - val_cosine_similarity: -0.8607\n",
            "Epoch 99/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9370 - cosine_similarity: -0.9370 - val_loss: -0.8627 - val_cosine_similarity: -0.8604\n",
            "Epoch 100/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9371 - cosine_similarity: -0.9371 - val_loss: -0.8630 - val_cosine_similarity: -0.8607\n",
            "Epoch 101/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9372 - cosine_similarity: -0.9372 - val_loss: -0.8630 - val_cosine_similarity: -0.8608\n",
            "Epoch 102/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9372 - cosine_similarity: -0.9372 - val_loss: -0.8631 - val_cosine_similarity: -0.8608\n",
            "Epoch 103/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9369 - cosine_similarity: -0.9370 - val_loss: -0.8632 - val_cosine_similarity: -0.8609\n",
            "Epoch 104/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9372 - cosine_similarity: -0.9372 - val_loss: -0.8630 - val_cosine_similarity: -0.8607\n",
            "Epoch 105/200\n",
            "94/94 [==============================] - 3s 29ms/step - loss: -0.9373 - cosine_similarity: -0.9373 - val_loss: -0.8632 - val_cosine_similarity: -0.8610\n",
            "Epoch 106/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9374 - cosine_similarity: -0.9374 - val_loss: -0.8630 - val_cosine_similarity: -0.8608\n",
            "Epoch 107/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9373 - cosine_similarity: -0.9372 - val_loss: -0.8632 - val_cosine_similarity: -0.8610\n",
            "Epoch 108/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9372 - cosine_similarity: -0.9371 - val_loss: -0.8630 - val_cosine_similarity: -0.8608\n",
            "Epoch 109/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9375 - cosine_similarity: -0.9375 - val_loss: -0.8629 - val_cosine_similarity: -0.8606\n",
            "Epoch 110/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9374 - cosine_similarity: -0.9374 - val_loss: -0.8629 - val_cosine_similarity: -0.8606\n",
            "Epoch 111/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9374 - cosine_similarity: -0.9374 - val_loss: -0.8629 - val_cosine_similarity: -0.8607\n",
            "Epoch 112/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9374 - cosine_similarity: -0.9374 - val_loss: -0.8631 - val_cosine_similarity: -0.8608\n",
            "Epoch 113/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9375 - cosine_similarity: -0.9374 - val_loss: -0.8632 - val_cosine_similarity: -0.8609\n",
            "Epoch 114/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9374 - cosine_similarity: -0.9373 - val_loss: -0.8629 - val_cosine_similarity: -0.8606\n",
            "Epoch 115/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9375 - cosine_similarity: -0.9374 - val_loss: -0.8628 - val_cosine_similarity: -0.8606\n",
            "Epoch 116/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9375 - cosine_similarity: -0.9375 - val_loss: -0.8631 - val_cosine_similarity: -0.8609\n",
            "Epoch 117/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9376 - cosine_similarity: -0.9377 - val_loss: -0.8629 - val_cosine_similarity: -0.8607\n",
            "Epoch 118/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9376 - cosine_similarity: -0.9377 - val_loss: -0.8631 - val_cosine_similarity: -0.8609\n",
            "Epoch 119/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9377 - cosine_similarity: -0.9377 - val_loss: -0.8632 - val_cosine_similarity: -0.8610\n",
            "Epoch 120/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9377 - cosine_similarity: -0.9377 - val_loss: -0.8630 - val_cosine_similarity: -0.8608\n",
            "Epoch 121/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9376 - cosine_similarity: -0.9377 - val_loss: -0.8628 - val_cosine_similarity: -0.8606\n",
            "Epoch 122/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9377 - cosine_similarity: -0.9376 - val_loss: -0.8629 - val_cosine_similarity: -0.8607\n",
            "Epoch 123/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9377 - cosine_similarity: -0.9377 - val_loss: -0.8629 - val_cosine_similarity: -0.8606\n",
            "Epoch 124/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9377 - cosine_similarity: -0.9377 - val_loss: -0.8630 - val_cosine_similarity: -0.8608\n",
            "Epoch 125/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9377 - cosine_similarity: -0.9377 - val_loss: -0.8629 - val_cosine_similarity: -0.8607\n",
            "Epoch 126/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9376 - cosine_similarity: -0.9375 - val_loss: -0.8633 - val_cosine_similarity: -0.8610\n",
            "Epoch 127/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9378 - cosine_similarity: -0.9378 - val_loss: -0.8628 - val_cosine_similarity: -0.8606\n",
            "Epoch 128/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9378 - cosine_similarity: -0.9378 - val_loss: -0.8630 - val_cosine_similarity: -0.8607\n",
            "Epoch 129/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9379 - cosine_similarity: -0.9379 - val_loss: -0.8626 - val_cosine_similarity: -0.8604\n",
            "Epoch 130/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9379 - cosine_similarity: -0.9378 - val_loss: -0.8629 - val_cosine_similarity: -0.8607\n",
            "Epoch 131/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9378 - cosine_similarity: -0.9377 - val_loss: -0.8633 - val_cosine_similarity: -0.8611\n",
            "Epoch 132/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9378 - cosine_similarity: -0.9378 - val_loss: -0.8630 - val_cosine_similarity: -0.8608\n",
            "Epoch 133/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9380 - cosine_similarity: -0.9379 - val_loss: -0.8631 - val_cosine_similarity: -0.8609\n",
            "Epoch 134/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9380 - cosine_similarity: -0.9379 - val_loss: -0.8631 - val_cosine_similarity: -0.8609\n",
            "Epoch 135/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9381 - cosine_similarity: -0.9380 - val_loss: -0.8628 - val_cosine_similarity: -0.8606\n",
            "Epoch 136/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9379 - cosine_similarity: -0.9379 - val_loss: -0.8632 - val_cosine_similarity: -0.8610\n",
            "Epoch 137/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9380 - cosine_similarity: -0.9380 - val_loss: -0.8630 - val_cosine_similarity: -0.8607\n",
            "Epoch 138/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9381 - cosine_similarity: -0.9382 - val_loss: -0.8633 - val_cosine_similarity: -0.8611\n",
            "Epoch 139/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9380 - cosine_similarity: -0.9381 - val_loss: -0.8632 - val_cosine_similarity: -0.8609\n",
            "Epoch 140/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9380 - cosine_similarity: -0.9380 - val_loss: -0.8628 - val_cosine_similarity: -0.8606\n",
            "Epoch 141/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9379 - cosine_similarity: -0.9379 - val_loss: -0.8631 - val_cosine_similarity: -0.8608\n",
            "Epoch 142/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9382 - cosine_similarity: -0.9382 - val_loss: -0.8632 - val_cosine_similarity: -0.8610\n",
            "Epoch 143/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9382 - cosine_similarity: -0.9381 - val_loss: -0.8631 - val_cosine_similarity: -0.8608\n",
            "Epoch 144/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9383 - cosine_similarity: -0.9383 - val_loss: -0.8633 - val_cosine_similarity: -0.8611\n",
            "Epoch 145/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9383 - cosine_similarity: -0.9383 - val_loss: -0.8629 - val_cosine_similarity: -0.8607\n",
            "Epoch 146/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9383 - cosine_similarity: -0.9382 - val_loss: -0.8629 - val_cosine_similarity: -0.8606\n",
            "Epoch 147/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9382 - cosine_similarity: -0.9382 - val_loss: -0.8630 - val_cosine_similarity: -0.8607\n",
            "Epoch 148/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9382 - cosine_similarity: -0.9383 - val_loss: -0.8632 - val_cosine_similarity: -0.8609\n",
            "Epoch 149/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9382 - cosine_similarity: -0.9381 - val_loss: -0.8632 - val_cosine_similarity: -0.8609\n",
            "Epoch 150/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9384 - cosine_similarity: -0.9384 - val_loss: -0.8628 - val_cosine_similarity: -0.8606\n",
            "Epoch 151/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9383 - cosine_similarity: -0.9383 - val_loss: -0.8627 - val_cosine_similarity: -0.8605\n",
            "Epoch 152/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9383 - cosine_similarity: -0.9383 - val_loss: -0.8631 - val_cosine_similarity: -0.8609\n",
            "Epoch 153/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9384 - cosine_similarity: -0.9383 - val_loss: -0.8628 - val_cosine_similarity: -0.8606\n",
            "Epoch 154/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9385 - cosine_similarity: -0.9385 - val_loss: -0.8632 - val_cosine_similarity: -0.8610\n",
            "Epoch 155/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9385 - cosine_similarity: -0.9385 - val_loss: -0.8629 - val_cosine_similarity: -0.8607\n",
            "Epoch 156/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9383 - cosine_similarity: -0.9383 - val_loss: -0.8629 - val_cosine_similarity: -0.8606\n",
            "Epoch 157/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9384 - cosine_similarity: -0.9383 - val_loss: -0.8629 - val_cosine_similarity: -0.8606\n",
            "Epoch 158/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9384 - cosine_similarity: -0.9384 - val_loss: -0.8630 - val_cosine_similarity: -0.8608\n",
            "Epoch 159/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9383 - cosine_similarity: -0.9382 - val_loss: -0.8633 - val_cosine_similarity: -0.8611\n",
            "Epoch 160/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9385 - cosine_similarity: -0.9384 - val_loss: -0.8633 - val_cosine_similarity: -0.8610\n",
            "Epoch 1/200\n",
            "94/94 [==============================] - 1s 4ms/step - loss: -0.5698 - cosine_similarity: -0.5701 - val_loss: -0.6075 - val_cosine_similarity: -0.6074\n",
            "Epoch 2/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.6967 - cosine_similarity: -0.6966 - val_loss: -0.6814 - val_cosine_similarity: -0.6804\n",
            "Epoch 3/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.7657 - cosine_similarity: -0.7656 - val_loss: -0.7283 - val_cosine_similarity: -0.7269\n",
            "Epoch 4/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.8114 - cosine_similarity: -0.8114 - val_loss: -0.7600 - val_cosine_similarity: -0.7584\n",
            "Epoch 5/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.8422 - cosine_similarity: -0.8422 - val_loss: -0.7816 - val_cosine_similarity: -0.7799\n",
            "Epoch 6/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.8635 - cosine_similarity: -0.8636 - val_loss: -0.7977 - val_cosine_similarity: -0.7959\n",
            "Epoch 7/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.8792 - cosine_similarity: -0.8792 - val_loss: -0.8096 - val_cosine_similarity: -0.8079\n",
            "Epoch 8/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.8909 - cosine_similarity: -0.8910 - val_loss: -0.8186 - val_cosine_similarity: -0.8170\n",
            "Epoch 9/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.8998 - cosine_similarity: -0.8998 - val_loss: -0.8260 - val_cosine_similarity: -0.8243\n",
            "Epoch 10/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9068 - cosine_similarity: -0.9068 - val_loss: -0.8320 - val_cosine_similarity: -0.8304\n",
            "Epoch 11/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9123 - cosine_similarity: -0.9124 - val_loss: -0.8367 - val_cosine_similarity: -0.8351\n",
            "Epoch 12/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9166 - cosine_similarity: -0.9166 - val_loss: -0.8406 - val_cosine_similarity: -0.8391\n",
            "Epoch 13/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9202 - cosine_similarity: -0.9202 - val_loss: -0.8441 - val_cosine_similarity: -0.8425\n",
            "Epoch 14/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9230 - cosine_similarity: -0.9231 - val_loss: -0.8465 - val_cosine_similarity: -0.8449\n",
            "Epoch 15/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9253 - cosine_similarity: -0.9252 - val_loss: -0.8491 - val_cosine_similarity: -0.8476\n",
            "Epoch 16/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9272 - cosine_similarity: -0.9272 - val_loss: -0.8509 - val_cosine_similarity: -0.8493\n",
            "Epoch 17/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9287 - cosine_similarity: -0.9288 - val_loss: -0.8523 - val_cosine_similarity: -0.8507\n",
            "Epoch 18/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9300 - cosine_similarity: -0.9300 - val_loss: -0.8537 - val_cosine_similarity: -0.8522\n",
            "Epoch 19/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9310 - cosine_similarity: -0.9309 - val_loss: -0.8552 - val_cosine_similarity: -0.8537\n",
            "Epoch 20/200\n",
            "94/94 [==============================] - 0s 3ms/step - loss: -0.9319 - cosine_similarity: -0.9318 - val_loss: -0.8561 - val_cosine_similarity: -0.8546\n",
            "Epoch 21/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9326 - cosine_similarity: -0.9325 - val_loss: -0.8568 - val_cosine_similarity: -0.8553\n",
            "Epoch 22/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9332 - cosine_similarity: -0.9331 - val_loss: -0.8576 - val_cosine_similarity: -0.8560\n",
            "Epoch 23/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9337 - cosine_similarity: -0.9337 - val_loss: -0.8581 - val_cosine_similarity: -0.8566\n",
            "Epoch 24/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9342 - cosine_similarity: -0.9341 - val_loss: -0.8588 - val_cosine_similarity: -0.8573\n",
            "Epoch 25/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9345 - cosine_similarity: -0.9345 - val_loss: -0.8594 - val_cosine_similarity: -0.8579\n",
            "Epoch 26/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9350 - cosine_similarity: -0.9350 - val_loss: -0.8596 - val_cosine_similarity: -0.8581\n",
            "Epoch 27/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9352 - cosine_similarity: -0.9352 - val_loss: -0.8599 - val_cosine_similarity: -0.8584\n",
            "Epoch 28/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9355 - cosine_similarity: -0.9355 - val_loss: -0.8601 - val_cosine_similarity: -0.8585\n",
            "Epoch 29/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9357 - cosine_similarity: -0.9358 - val_loss: -0.8604 - val_cosine_similarity: -0.8589\n",
            "Epoch 30/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9359 - cosine_similarity: -0.9359 - val_loss: -0.8604 - val_cosine_similarity: -0.8588\n",
            "Epoch 31/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9361 - cosine_similarity: -0.9360 - val_loss: -0.8611 - val_cosine_similarity: -0.8595\n",
            "Epoch 32/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9362 - cosine_similarity: -0.9362 - val_loss: -0.8610 - val_cosine_similarity: -0.8594\n",
            "Epoch 33/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9364 - cosine_similarity: -0.9364 - val_loss: -0.8611 - val_cosine_similarity: -0.8596\n",
            "Epoch 34/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9365 - cosine_similarity: -0.9364 - val_loss: -0.8615 - val_cosine_similarity: -0.8600\n",
            "Epoch 35/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9366 - cosine_similarity: -0.9365 - val_loss: -0.8616 - val_cosine_similarity: -0.8600\n",
            "Epoch 36/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9368 - cosine_similarity: -0.9368 - val_loss: -0.8615 - val_cosine_similarity: -0.8600\n",
            "Epoch 37/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9368 - cosine_similarity: -0.9368 - val_loss: -0.8618 - val_cosine_similarity: -0.8602\n",
            "Epoch 38/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9368 - cosine_similarity: -0.9369 - val_loss: -0.8618 - val_cosine_similarity: -0.8603\n",
            "Epoch 39/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9369 - cosine_similarity: -0.9369 - val_loss: -0.8621 - val_cosine_similarity: -0.8605\n",
            "Epoch 40/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9371 - cosine_similarity: -0.9371 - val_loss: -0.8619 - val_cosine_similarity: -0.8604\n",
            "Epoch 41/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9371 - cosine_similarity: -0.9371 - val_loss: -0.8620 - val_cosine_similarity: -0.8604\n",
            "Epoch 42/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9372 - cosine_similarity: -0.9372 - val_loss: -0.8624 - val_cosine_similarity: -0.8608\n",
            "Epoch 43/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9373 - cosine_similarity: -0.9372 - val_loss: -0.8621 - val_cosine_similarity: -0.8605\n",
            "Epoch 44/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9372 - cosine_similarity: -0.9373 - val_loss: -0.8623 - val_cosine_similarity: -0.8607\n",
            "Epoch 45/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9373 - cosine_similarity: -0.9373 - val_loss: -0.8627 - val_cosine_similarity: -0.8612\n",
            "Epoch 46/200\n",
            "94/94 [==============================] - 0s 3ms/step - loss: -0.9373 - cosine_similarity: -0.9373 - val_loss: -0.8625 - val_cosine_similarity: -0.8610\n",
            "Epoch 47/200\n",
            "94/94 [==============================] - 0s 3ms/step - loss: -0.9375 - cosine_similarity: -0.9375 - val_loss: -0.8625 - val_cosine_similarity: -0.8609\n",
            "Epoch 48/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9375 - cosine_similarity: -0.9374 - val_loss: -0.8623 - val_cosine_similarity: -0.8607\n",
            "Epoch 49/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9375 - cosine_similarity: -0.9375 - val_loss: -0.8624 - val_cosine_similarity: -0.8608\n",
            "Epoch 50/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9376 - cosine_similarity: -0.9377 - val_loss: -0.8624 - val_cosine_similarity: -0.8608\n",
            "Epoch 51/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9376 - cosine_similarity: -0.9376 - val_loss: -0.8625 - val_cosine_similarity: -0.8609\n",
            "Epoch 52/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9376 - cosine_similarity: -0.9376 - val_loss: -0.8628 - val_cosine_similarity: -0.8612\n",
            "Epoch 53/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9376 - cosine_similarity: -0.9377 - val_loss: -0.8625 - val_cosine_similarity: -0.8609\n",
            "Epoch 54/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9377 - cosine_similarity: -0.9377 - val_loss: -0.8625 - val_cosine_similarity: -0.8609\n",
            "Epoch 55/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9374 - cosine_similarity: -0.9374 - val_loss: -0.8623 - val_cosine_similarity: -0.8607\n",
            "Epoch 56/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9376 - cosine_similarity: -0.9377 - val_loss: -0.8626 - val_cosine_similarity: -0.8610\n",
            "Epoch 57/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9377 - cosine_similarity: -0.9377 - val_loss: -0.8627 - val_cosine_similarity: -0.8611\n",
            "Epoch 58/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9378 - cosine_similarity: -0.9379 - val_loss: -0.8628 - val_cosine_similarity: -0.8612\n",
            "Epoch 59/200\n",
            "94/94 [==============================] - 0s 3ms/step - loss: -0.9378 - cosine_similarity: -0.9378 - val_loss: -0.8627 - val_cosine_similarity: -0.8610\n",
            "Epoch 60/200\n",
            "94/94 [==============================] - 0s 3ms/step - loss: -0.9379 - cosine_similarity: -0.9379 - val_loss: -0.8629 - val_cosine_similarity: -0.8613\n",
            "Epoch 61/200\n",
            "94/94 [==============================] - 0s 3ms/step - loss: -0.9379 - cosine_similarity: -0.9380 - val_loss: -0.8626 - val_cosine_similarity: -0.8610\n",
            "Epoch 62/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9379 - cosine_similarity: -0.9379 - val_loss: -0.8626 - val_cosine_similarity: -0.8611\n",
            "Epoch 63/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9380 - cosine_similarity: -0.9379 - val_loss: -0.8628 - val_cosine_similarity: -0.8612\n",
            "Epoch 64/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9380 - cosine_similarity: -0.9380 - val_loss: -0.8627 - val_cosine_similarity: -0.8611\n",
            "Epoch 65/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9380 - cosine_similarity: -0.9379 - val_loss: -0.8629 - val_cosine_similarity: -0.8613\n",
            "Epoch 66/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9380 - cosine_similarity: -0.9380 - val_loss: -0.8629 - val_cosine_similarity: -0.8613\n",
            "Epoch 67/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9379 - cosine_similarity: -0.9379 - val_loss: -0.8628 - val_cosine_similarity: -0.8613\n",
            "Epoch 68/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9381 - cosine_similarity: -0.9381 - val_loss: -0.8627 - val_cosine_similarity: -0.8611\n",
            "Epoch 69/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9380 - cosine_similarity: -0.9380 - val_loss: -0.8628 - val_cosine_similarity: -0.8612\n",
            "Epoch 70/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9381 - cosine_similarity: -0.9380 - val_loss: -0.8631 - val_cosine_similarity: -0.8615\n",
            "Epoch 71/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9381 - cosine_similarity: -0.9381 - val_loss: -0.8631 - val_cosine_similarity: -0.8615\n",
            "Epoch 72/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9381 - cosine_similarity: -0.9380 - val_loss: -0.8627 - val_cosine_similarity: -0.8610\n",
            "Epoch 73/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9382 - cosine_similarity: -0.9382 - val_loss: -0.8628 - val_cosine_similarity: -0.8612\n",
            "Epoch 74/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9381 - cosine_similarity: -0.9381 - val_loss: -0.8629 - val_cosine_similarity: -0.8613\n",
            "Epoch 75/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9382 - cosine_similarity: -0.9383 - val_loss: -0.8628 - val_cosine_similarity: -0.8612\n",
            "Epoch 76/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9381 - cosine_similarity: -0.9382 - val_loss: -0.8626 - val_cosine_similarity: -0.8610\n",
            "Epoch 77/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9383 - cosine_similarity: -0.9382 - val_loss: -0.8631 - val_cosine_similarity: -0.8615\n",
            "Epoch 78/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9382 - cosine_similarity: -0.9382 - val_loss: -0.8628 - val_cosine_similarity: -0.8611\n",
            "Epoch 79/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9382 - cosine_similarity: -0.9383 - val_loss: -0.8628 - val_cosine_similarity: -0.8613\n",
            "Epoch 80/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9383 - cosine_similarity: -0.9382 - val_loss: -0.8628 - val_cosine_similarity: -0.8612\n",
            "Epoch 81/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9383 - cosine_similarity: -0.9383 - val_loss: -0.8627 - val_cosine_similarity: -0.8611\n",
            "Epoch 82/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9383 - cosine_similarity: -0.9383 - val_loss: -0.8626 - val_cosine_similarity: -0.8609\n",
            "Epoch 83/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9383 - cosine_similarity: -0.9384 - val_loss: -0.8627 - val_cosine_similarity: -0.8610\n",
            "Epoch 84/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9384 - cosine_similarity: -0.9383 - val_loss: -0.8630 - val_cosine_similarity: -0.8614\n",
            "Epoch 85/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9384 - cosine_similarity: -0.9384 - val_loss: -0.8629 - val_cosine_similarity: -0.8612\n",
            "Epoch 86/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9385 - cosine_similarity: -0.9385 - val_loss: -0.8627 - val_cosine_similarity: -0.8611\n",
            "Epoch 87/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9384 - cosine_similarity: -0.9384 - val_loss: -0.8626 - val_cosine_similarity: -0.8610\n",
            "Epoch 88/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9384 - cosine_similarity: -0.9384 - val_loss: -0.8626 - val_cosine_similarity: -0.8610\n",
            "Epoch 89/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9385 - cosine_similarity: -0.9385 - val_loss: -0.8626 - val_cosine_similarity: -0.8610\n",
            "Epoch 90/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9385 - cosine_similarity: -0.9384 - val_loss: -0.8627 - val_cosine_similarity: -0.8612\n",
            "Epoch 91/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9385 - cosine_similarity: -0.9384 - val_loss: -0.8627 - val_cosine_similarity: -0.8611\n",
            "Epoch 92/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9384 - cosine_similarity: -0.9384 - val_loss: -0.8627 - val_cosine_similarity: -0.8611\n",
            "Epoch 93/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9383 - cosine_similarity: -0.9382 - val_loss: -0.8628 - val_cosine_similarity: -0.8612\n",
            "Epoch 94/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9384 - cosine_similarity: -0.9384 - val_loss: -0.8626 - val_cosine_similarity: -0.8610\n",
            "{}\n",
            "Epoch 1/200\n",
            "94/94 [==============================] - 1s 4ms/step - loss: -0.5515 - cosine_similarity: -0.5520 - val_loss: -0.7109 - val_cosine_similarity: -0.7097\n",
            "Epoch 2/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.7981 - cosine_similarity: -0.7981 - val_loss: -0.7787 - val_cosine_similarity: -0.7771\n",
            "Epoch 3/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.8518 - cosine_similarity: -0.8518 - val_loss: -0.8065 - val_cosine_similarity: -0.8048\n",
            "Epoch 4/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.8762 - cosine_similarity: -0.8761 - val_loss: -0.8213 - val_cosine_similarity: -0.8196\n",
            "Epoch 5/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.8896 - cosine_similarity: -0.8897 - val_loss: -0.8298 - val_cosine_similarity: -0.8282\n",
            "Epoch 6/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.8977 - cosine_similarity: -0.8976 - val_loss: -0.8352 - val_cosine_similarity: -0.8334\n",
            "Epoch 7/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9027 - cosine_similarity: -0.9026 - val_loss: -0.8399 - val_cosine_similarity: -0.8383\n",
            "Epoch 8/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9064 - cosine_similarity: -0.9064 - val_loss: -0.8420 - val_cosine_similarity: -0.8404\n",
            "Epoch 9/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9086 - cosine_similarity: -0.9086 - val_loss: -0.8426 - val_cosine_similarity: -0.8408\n",
            "Epoch 10/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9108 - cosine_similarity: -0.9108 - val_loss: -0.8448 - val_cosine_similarity: -0.8432\n",
            "Epoch 11/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9122 - cosine_similarity: -0.9123 - val_loss: -0.8463 - val_cosine_similarity: -0.8446\n",
            "Epoch 12/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9133 - cosine_similarity: -0.9132 - val_loss: -0.8472 - val_cosine_similarity: -0.8456\n",
            "Epoch 13/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9141 - cosine_similarity: -0.9142 - val_loss: -0.8476 - val_cosine_similarity: -0.8459\n",
            "Epoch 14/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9149 - cosine_similarity: -0.9148 - val_loss: -0.8481 - val_cosine_similarity: -0.8464\n",
            "Epoch 15/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9158 - cosine_similarity: -0.9158 - val_loss: -0.8489 - val_cosine_similarity: -0.8472\n",
            "Epoch 16/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9158 - cosine_similarity: -0.9158 - val_loss: -0.8490 - val_cosine_similarity: -0.8474\n",
            "Epoch 17/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9163 - cosine_similarity: -0.9163 - val_loss: -0.8499 - val_cosine_similarity: -0.8482\n",
            "Epoch 18/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9170 - cosine_similarity: -0.9170 - val_loss: -0.8494 - val_cosine_similarity: -0.8477\n",
            "Epoch 19/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9170 - cosine_similarity: -0.9168 - val_loss: -0.8497 - val_cosine_similarity: -0.8480\n",
            "Epoch 20/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9172 - cosine_similarity: -0.9172 - val_loss: -0.8503 - val_cosine_similarity: -0.8486\n",
            "Epoch 21/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9177 - cosine_similarity: -0.9177 - val_loss: -0.8502 - val_cosine_similarity: -0.8484\n",
            "Epoch 22/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9180 - cosine_similarity: -0.9180 - val_loss: -0.8504 - val_cosine_similarity: -0.8487\n",
            "Epoch 23/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9180 - cosine_similarity: -0.9179 - val_loss: -0.8506 - val_cosine_similarity: -0.8489\n",
            "Epoch 24/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9182 - cosine_similarity: -0.9182 - val_loss: -0.8508 - val_cosine_similarity: -0.8491\n",
            "Epoch 25/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9183 - cosine_similarity: -0.9183 - val_loss: -0.8506 - val_cosine_similarity: -0.8490\n",
            "Epoch 26/200\n",
            "94/94 [==============================] - 0s 3ms/step - loss: -0.9183 - cosine_similarity: -0.9182 - val_loss: -0.8507 - val_cosine_similarity: -0.8491\n",
            "Epoch 27/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9183 - cosine_similarity: -0.9183 - val_loss: -0.8509 - val_cosine_similarity: -0.8492\n",
            "Epoch 28/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9186 - cosine_similarity: -0.9185 - val_loss: -0.8504 - val_cosine_similarity: -0.8487\n",
            "Epoch 29/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9189 - cosine_similarity: -0.9188 - val_loss: -0.8506 - val_cosine_similarity: -0.8488\n",
            "Epoch 30/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9188 - cosine_similarity: -0.9186 - val_loss: -0.8511 - val_cosine_similarity: -0.8493\n",
            "Epoch 31/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9190 - cosine_similarity: -0.9190 - val_loss: -0.8512 - val_cosine_similarity: -0.8495\n",
            "Epoch 32/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9193 - cosine_similarity: -0.9193 - val_loss: -0.8506 - val_cosine_similarity: -0.8489\n",
            "Epoch 33/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9194 - cosine_similarity: -0.9193 - val_loss: -0.8503 - val_cosine_similarity: -0.8486\n",
            "Epoch 34/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9193 - cosine_similarity: -0.9193 - val_loss: -0.8512 - val_cosine_similarity: -0.8494\n",
            "Epoch 35/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9195 - cosine_similarity: -0.9195 - val_loss: -0.8512 - val_cosine_similarity: -0.8495\n",
            "Epoch 36/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9196 - cosine_similarity: -0.9196 - val_loss: -0.8509 - val_cosine_similarity: -0.8493\n",
            "Epoch 37/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9195 - cosine_similarity: -0.9193 - val_loss: -0.8512 - val_cosine_similarity: -0.8495\n",
            "Epoch 38/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9196 - cosine_similarity: -0.9197 - val_loss: -0.8513 - val_cosine_similarity: -0.8496\n",
            "Epoch 39/200\n",
            "94/94 [==============================] - 0s 3ms/step - loss: -0.9198 - cosine_similarity: -0.9197 - val_loss: -0.8513 - val_cosine_similarity: -0.8496\n",
            "Epoch 40/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9200 - cosine_similarity: -0.9199 - val_loss: -0.8510 - val_cosine_similarity: -0.8493\n",
            "Epoch 41/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9200 - cosine_similarity: -0.9201 - val_loss: -0.8513 - val_cosine_similarity: -0.8496\n",
            "Epoch 42/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9199 - cosine_similarity: -0.9199 - val_loss: -0.8510 - val_cosine_similarity: -0.8493\n",
            "Epoch 43/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9201 - cosine_similarity: -0.9201 - val_loss: -0.8508 - val_cosine_similarity: -0.8491\n",
            "Epoch 44/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9201 - cosine_similarity: -0.9200 - val_loss: -0.8507 - val_cosine_similarity: -0.8490\n",
            "Epoch 45/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9204 - cosine_similarity: -0.9204 - val_loss: -0.8511 - val_cosine_similarity: -0.8493\n",
            "Epoch 46/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9202 - cosine_similarity: -0.9203 - val_loss: -0.8512 - val_cosine_similarity: -0.8495\n",
            "Epoch 47/200\n",
            "94/94 [==============================] - 0s 3ms/step - loss: -0.9202 - cosine_similarity: -0.9202 - val_loss: -0.8512 - val_cosine_similarity: -0.8494\n",
            "Epoch 48/200\n",
            "94/94 [==============================] - 0s 3ms/step - loss: -0.9205 - cosine_similarity: -0.9205 - val_loss: -0.8513 - val_cosine_similarity: -0.8496\n",
            "Epoch 49/200\n",
            "94/94 [==============================] - 0s 3ms/step - loss: -0.9204 - cosine_similarity: -0.9204 - val_loss: -0.8512 - val_cosine_similarity: -0.8495\n",
            "Epoch 50/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9206 - cosine_similarity: -0.9207 - val_loss: -0.8513 - val_cosine_similarity: -0.8496\n",
            "Epoch 51/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9206 - cosine_similarity: -0.9206 - val_loss: -0.8511 - val_cosine_similarity: -0.8494\n",
            "Epoch 52/200\n",
            "94/94 [==============================] - 0s 3ms/step - loss: -0.9206 - cosine_similarity: -0.9206 - val_loss: -0.8514 - val_cosine_similarity: -0.8496\n",
            "Epoch 53/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9207 - cosine_similarity: -0.9207 - val_loss: -0.8513 - val_cosine_similarity: -0.8496\n",
            "Epoch 54/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9208 - cosine_similarity: -0.9208 - val_loss: -0.8511 - val_cosine_similarity: -0.8494\n",
            "Epoch 55/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9208 - cosine_similarity: -0.9207 - val_loss: -0.8507 - val_cosine_similarity: -0.8490\n",
            "Epoch 56/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9207 - cosine_similarity: -0.9206 - val_loss: -0.8510 - val_cosine_similarity: -0.8493\n",
            "Epoch 57/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9209 - cosine_similarity: -0.9209 - val_loss: -0.8507 - val_cosine_similarity: -0.8489\n",
            "Epoch 58/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9211 - cosine_similarity: -0.9211 - val_loss: -0.8512 - val_cosine_similarity: -0.8495\n",
            "Epoch 59/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9210 - cosine_similarity: -0.9210 - val_loss: -0.8509 - val_cosine_similarity: -0.8491\n",
            "Epoch 60/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9212 - cosine_similarity: -0.9211 - val_loss: -0.8513 - val_cosine_similarity: -0.8496\n",
            "Epoch 61/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9211 - cosine_similarity: -0.9211 - val_loss: -0.8514 - val_cosine_similarity: -0.8497\n",
            "Epoch 62/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9211 - cosine_similarity: -0.9211 - val_loss: -0.8515 - val_cosine_similarity: -0.8498\n",
            "Epoch 63/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9212 - cosine_similarity: -0.9213 - val_loss: -0.8513 - val_cosine_similarity: -0.8496\n",
            "Epoch 64/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9213 - cosine_similarity: -0.9214 - val_loss: -0.8509 - val_cosine_similarity: -0.8492\n",
            "Epoch 65/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9213 - cosine_similarity: -0.9213 - val_loss: -0.8512 - val_cosine_similarity: -0.8494\n",
            "Epoch 66/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9214 - cosine_similarity: -0.9215 - val_loss: -0.8512 - val_cosine_similarity: -0.8495\n",
            "Epoch 67/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9213 - cosine_similarity: -0.9213 - val_loss: -0.8509 - val_cosine_similarity: -0.8491\n",
            "Epoch 68/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9214 - cosine_similarity: -0.9215 - val_loss: -0.8509 - val_cosine_similarity: -0.8492\n",
            "Epoch 69/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9216 - cosine_similarity: -0.9216 - val_loss: -0.8514 - val_cosine_similarity: -0.8497\n",
            "Epoch 70/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9215 - cosine_similarity: -0.9215 - val_loss: -0.8511 - val_cosine_similarity: -0.8493\n",
            "Epoch 71/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9216 - cosine_similarity: -0.9216 - val_loss: -0.8512 - val_cosine_similarity: -0.8494\n",
            "Epoch 72/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9217 - cosine_similarity: -0.9216 - val_loss: -0.8512 - val_cosine_similarity: -0.8495\n",
            "Epoch 73/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9218 - cosine_similarity: -0.9217 - val_loss: -0.8511 - val_cosine_similarity: -0.8493\n",
            "Epoch 74/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9217 - cosine_similarity: -0.9216 - val_loss: -0.8509 - val_cosine_similarity: -0.8492\n",
            "Epoch 75/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9217 - cosine_similarity: -0.9217 - val_loss: -0.8511 - val_cosine_similarity: -0.8493\n",
            "Epoch 76/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9218 - cosine_similarity: -0.9219 - val_loss: -0.8510 - val_cosine_similarity: -0.8493\n",
            "Epoch 77/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9219 - cosine_similarity: -0.9219 - val_loss: -0.8507 - val_cosine_similarity: -0.8490\n",
            "Epoch 78/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9218 - cosine_similarity: -0.9219 - val_loss: -0.8510 - val_cosine_similarity: -0.8493\n",
            "Epoch 79/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9218 - cosine_similarity: -0.9218 - val_loss: -0.8510 - val_cosine_similarity: -0.8493\n",
            "Epoch 80/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9219 - cosine_similarity: -0.9219 - val_loss: -0.8508 - val_cosine_similarity: -0.8491\n",
            "Epoch 81/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9220 - cosine_similarity: -0.9220 - val_loss: -0.8511 - val_cosine_similarity: -0.8494\n",
            "Epoch 82/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9222 - cosine_similarity: -0.9221 - val_loss: -0.8510 - val_cosine_similarity: -0.8493\n",
            "Epoch 83/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9220 - cosine_similarity: -0.9220 - val_loss: -0.8512 - val_cosine_similarity: -0.8494\n",
            "Epoch 84/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9221 - cosine_similarity: -0.9222 - val_loss: -0.8511 - val_cosine_similarity: -0.8494\n",
            "Epoch 85/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9221 - cosine_similarity: -0.9221 - val_loss: -0.8513 - val_cosine_similarity: -0.8496\n",
            "Epoch 86/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9221 - cosine_similarity: -0.9220 - val_loss: -0.8515 - val_cosine_similarity: -0.8498\n",
            "Epoch 87/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9221 - cosine_similarity: -0.9221 - val_loss: -0.8510 - val_cosine_similarity: -0.8493\n",
            "Epoch 1/200\n",
            "94/94 [==============================] - 1s 4ms/step - loss: -0.5284 - cosine_similarity: -0.5286 - val_loss: -0.6067 - val_cosine_similarity: -0.6067\n",
            "Epoch 2/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.7088 - cosine_similarity: -0.7089 - val_loss: -0.7010 - val_cosine_similarity: -0.7000\n",
            "Epoch 3/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.7918 - cosine_similarity: -0.7919 - val_loss: -0.7527 - val_cosine_similarity: -0.7511\n",
            "Epoch 4/200\n",
            "94/94 [==============================] - 0s 3ms/step - loss: -0.8389 - cosine_similarity: -0.8389 - val_loss: -0.7832 - val_cosine_similarity: -0.7815\n",
            "Epoch 5/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.8665 - cosine_similarity: -0.8666 - val_loss: -0.8028 - val_cosine_similarity: -0.8010\n",
            "Epoch 6/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.8843 - cosine_similarity: -0.8843 - val_loss: -0.8160 - val_cosine_similarity: -0.8142\n",
            "Epoch 7/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.8970 - cosine_similarity: -0.8970 - val_loss: -0.8262 - val_cosine_similarity: -0.8244\n",
            "Epoch 8/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9060 - cosine_similarity: -0.9060 - val_loss: -0.8335 - val_cosine_similarity: -0.8317\n",
            "Epoch 9/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9125 - cosine_similarity: -0.9124 - val_loss: -0.8394 - val_cosine_similarity: -0.8376\n",
            "Epoch 10/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9175 - cosine_similarity: -0.9176 - val_loss: -0.8437 - val_cosine_similarity: -0.8418\n",
            "Epoch 11/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9210 - cosine_similarity: -0.9210 - val_loss: -0.8471 - val_cosine_similarity: -0.8452\n",
            "Epoch 12/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9237 - cosine_similarity: -0.9238 - val_loss: -0.8498 - val_cosine_similarity: -0.8479\n",
            "Epoch 13/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9259 - cosine_similarity: -0.9259 - val_loss: -0.8519 - val_cosine_similarity: -0.8500\n",
            "Epoch 14/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9275 - cosine_similarity: -0.9275 - val_loss: -0.8531 - val_cosine_similarity: -0.8510\n",
            "Epoch 15/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9288 - cosine_similarity: -0.9288 - val_loss: -0.8550 - val_cosine_similarity: -0.8530\n",
            "Epoch 16/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9298 - cosine_similarity: -0.9298 - val_loss: -0.8561 - val_cosine_similarity: -0.8541\n",
            "Epoch 17/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9307 - cosine_similarity: -0.9308 - val_loss: -0.8569 - val_cosine_similarity: -0.8550\n",
            "Epoch 18/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9314 - cosine_similarity: -0.9313 - val_loss: -0.8575 - val_cosine_similarity: -0.8555\n",
            "Epoch 19/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9320 - cosine_similarity: -0.9321 - val_loss: -0.8583 - val_cosine_similarity: -0.8563\n",
            "Epoch 20/200\n",
            "94/94 [==============================] - 0s 3ms/step - loss: -0.9324 - cosine_similarity: -0.9323 - val_loss: -0.8591 - val_cosine_similarity: -0.8571\n",
            "Epoch 21/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9328 - cosine_similarity: -0.9328 - val_loss: -0.8595 - val_cosine_similarity: -0.8575\n",
            "Epoch 22/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9331 - cosine_similarity: -0.9331 - val_loss: -0.8599 - val_cosine_similarity: -0.8579\n",
            "Epoch 23/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9335 - cosine_similarity: -0.9335 - val_loss: -0.8601 - val_cosine_similarity: -0.8582\n",
            "Epoch 24/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9337 - cosine_similarity: -0.9337 - val_loss: -0.8604 - val_cosine_similarity: -0.8584\n",
            "Epoch 25/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9340 - cosine_similarity: -0.9340 - val_loss: -0.8605 - val_cosine_similarity: -0.8585\n",
            "Epoch 26/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9340 - cosine_similarity: -0.9340 - val_loss: -0.8611 - val_cosine_similarity: -0.8591\n",
            "Epoch 27/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9343 - cosine_similarity: -0.9343 - val_loss: -0.8607 - val_cosine_similarity: -0.8588\n",
            "Epoch 28/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9344 - cosine_similarity: -0.9344 - val_loss: -0.8610 - val_cosine_similarity: -0.8590\n",
            "Epoch 29/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9344 - cosine_similarity: -0.9344 - val_loss: -0.8613 - val_cosine_similarity: -0.8593\n",
            "Epoch 30/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9348 - cosine_similarity: -0.9347 - val_loss: -0.8617 - val_cosine_similarity: -0.8597\n",
            "Epoch 31/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9348 - cosine_similarity: -0.9347 - val_loss: -0.8615 - val_cosine_similarity: -0.8595\n",
            "Epoch 32/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9348 - cosine_similarity: -0.9348 - val_loss: -0.8615 - val_cosine_similarity: -0.8595\n",
            "Epoch 33/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9349 - cosine_similarity: -0.9350 - val_loss: -0.8619 - val_cosine_similarity: -0.8598\n",
            "Epoch 34/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9351 - cosine_similarity: -0.9351 - val_loss: -0.8619 - val_cosine_similarity: -0.8598\n",
            "Epoch 35/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9352 - cosine_similarity: -0.9353 - val_loss: -0.8618 - val_cosine_similarity: -0.8598\n",
            "Epoch 36/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9351 - cosine_similarity: -0.9351 - val_loss: -0.8620 - val_cosine_similarity: -0.8599\n",
            "Epoch 37/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9352 - cosine_similarity: -0.9352 - val_loss: -0.8616 - val_cosine_similarity: -0.8596\n",
            "Epoch 38/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9353 - cosine_similarity: -0.9353 - val_loss: -0.8616 - val_cosine_similarity: -0.8596\n",
            "Epoch 39/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9354 - cosine_similarity: -0.9353 - val_loss: -0.8622 - val_cosine_similarity: -0.8601\n",
            "Epoch 40/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9355 - cosine_similarity: -0.9356 - val_loss: -0.8617 - val_cosine_similarity: -0.8596\n",
            "Epoch 41/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9354 - cosine_similarity: -0.9355 - val_loss: -0.8623 - val_cosine_similarity: -0.8603\n",
            "Epoch 42/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9356 - cosine_similarity: -0.9356 - val_loss: -0.8621 - val_cosine_similarity: -0.8600\n",
            "Epoch 43/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9356 - cosine_similarity: -0.9356 - val_loss: -0.8621 - val_cosine_similarity: -0.8600\n",
            "Epoch 44/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9357 - cosine_similarity: -0.9357 - val_loss: -0.8622 - val_cosine_similarity: -0.8601\n",
            "Epoch 45/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9358 - cosine_similarity: -0.9359 - val_loss: -0.8621 - val_cosine_similarity: -0.8600\n",
            "Epoch 46/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9358 - cosine_similarity: -0.9358 - val_loss: -0.8621 - val_cosine_similarity: -0.8600\n",
            "Epoch 47/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9357 - cosine_similarity: -0.9357 - val_loss: -0.8625 - val_cosine_similarity: -0.8604\n",
            "Epoch 48/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9358 - cosine_similarity: -0.9358 - val_loss: -0.8622 - val_cosine_similarity: -0.8601\n",
            "Epoch 49/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9358 - cosine_similarity: -0.9358 - val_loss: -0.8620 - val_cosine_similarity: -0.8600\n",
            "Epoch 50/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9360 - cosine_similarity: -0.9359 - val_loss: -0.8620 - val_cosine_similarity: -0.8599\n",
            "Epoch 51/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9360 - cosine_similarity: -0.9360 - val_loss: -0.8622 - val_cosine_similarity: -0.8601\n",
            "Epoch 52/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9360 - cosine_similarity: -0.9359 - val_loss: -0.8623 - val_cosine_similarity: -0.8602\n",
            "Epoch 53/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9360 - cosine_similarity: -0.9360 - val_loss: -0.8623 - val_cosine_similarity: -0.8602\n",
            "Epoch 54/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9361 - cosine_similarity: -0.9360 - val_loss: -0.8626 - val_cosine_similarity: -0.8605\n",
            "Epoch 55/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9360 - cosine_similarity: -0.9360 - val_loss: -0.8623 - val_cosine_similarity: -0.8602\n",
            "Epoch 56/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9361 - cosine_similarity: -0.9362 - val_loss: -0.8621 - val_cosine_similarity: -0.8600\n",
            "Epoch 57/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9362 - cosine_similarity: -0.9362 - val_loss: -0.8619 - val_cosine_similarity: -0.8599\n",
            "Epoch 58/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9361 - cosine_similarity: -0.9360 - val_loss: -0.8622 - val_cosine_similarity: -0.8601\n",
            "Epoch 59/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9362 - cosine_similarity: -0.9363 - val_loss: -0.8622 - val_cosine_similarity: -0.8602\n",
            "Epoch 60/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9362 - cosine_similarity: -0.9362 - val_loss: -0.8625 - val_cosine_similarity: -0.8604\n",
            "Epoch 61/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9363 - cosine_similarity: -0.9363 - val_loss: -0.8624 - val_cosine_similarity: -0.8602\n",
            "Epoch 62/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9363 - cosine_similarity: -0.9364 - val_loss: -0.8620 - val_cosine_similarity: -0.8599\n",
            "Epoch 63/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9363 - cosine_similarity: -0.9363 - val_loss: -0.8625 - val_cosine_similarity: -0.8605\n",
            "Epoch 64/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9363 - cosine_similarity: -0.9363 - val_loss: -0.8623 - val_cosine_similarity: -0.8603\n",
            "Epoch 65/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9364 - cosine_similarity: -0.9364 - val_loss: -0.8619 - val_cosine_similarity: -0.8599\n",
            "Epoch 66/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9365 - cosine_similarity: -0.9363 - val_loss: -0.8622 - val_cosine_similarity: -0.8601\n",
            "Epoch 67/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9365 - cosine_similarity: -0.9365 - val_loss: -0.8623 - val_cosine_similarity: -0.8603\n",
            "Epoch 68/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9364 - cosine_similarity: -0.9365 - val_loss: -0.8624 - val_cosine_similarity: -0.8603\n",
            "Epoch 69/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9365 - cosine_similarity: -0.9365 - val_loss: -0.8625 - val_cosine_similarity: -0.8604\n",
            "Epoch 70/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9366 - cosine_similarity: -0.9367 - val_loss: -0.8623 - val_cosine_similarity: -0.8602\n",
            "Epoch 71/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9366 - cosine_similarity: -0.9366 - val_loss: -0.8625 - val_cosine_similarity: -0.8604\n",
            "Epoch 72/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9366 - cosine_similarity: -0.9366 - val_loss: -0.8623 - val_cosine_similarity: -0.8602\n",
            "Epoch 73/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9365 - cosine_similarity: -0.9364 - val_loss: -0.8622 - val_cosine_similarity: -0.8602\n",
            "Epoch 74/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9366 - cosine_similarity: -0.9367 - val_loss: -0.8624 - val_cosine_similarity: -0.8603\n",
            "Epoch 75/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9365 - cosine_similarity: -0.9366 - val_loss: -0.8623 - val_cosine_similarity: -0.8602\n",
            "Epoch 76/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9366 - cosine_similarity: -0.9366 - val_loss: -0.8625 - val_cosine_similarity: -0.8604\n",
            "Epoch 77/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9366 - cosine_similarity: -0.9365 - val_loss: -0.8622 - val_cosine_similarity: -0.8602\n",
            "Epoch 78/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9367 - cosine_similarity: -0.9368 - val_loss: -0.8619 - val_cosine_similarity: -0.8598\n",
            "Epoch 79/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9367 - cosine_similarity: -0.9367 - val_loss: -0.8621 - val_cosine_similarity: -0.8600\n",
            "Epoch 80/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9367 - cosine_similarity: -0.9366 - val_loss: -0.8626 - val_cosine_similarity: -0.8605\n",
            "Epoch 81/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9367 - cosine_similarity: -0.9366 - val_loss: -0.8622 - val_cosine_similarity: -0.8602\n",
            "Epoch 82/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9367 - cosine_similarity: -0.9367 - val_loss: -0.8621 - val_cosine_similarity: -0.8600\n",
            "Epoch 83/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9368 - cosine_similarity: -0.9368 - val_loss: -0.8620 - val_cosine_similarity: -0.8599\n",
            "Epoch 84/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9367 - cosine_similarity: -0.9368 - val_loss: -0.8623 - val_cosine_similarity: -0.8602\n",
            "Epoch 85/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9369 - cosine_similarity: -0.9369 - val_loss: -0.8620 - val_cosine_similarity: -0.8599\n",
            "Epoch 86/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9369 - cosine_similarity: -0.9368 - val_loss: -0.8622 - val_cosine_similarity: -0.8602\n",
            "Epoch 87/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9368 - cosine_similarity: -0.9368 - val_loss: -0.8621 - val_cosine_similarity: -0.8600\n",
            "Epoch 88/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9369 - cosine_similarity: -0.9369 - val_loss: -0.8619 - val_cosine_similarity: -0.8598\n",
            "Epoch 89/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9369 - cosine_similarity: -0.9369 - val_loss: -0.8621 - val_cosine_similarity: -0.8600\n",
            "Epoch 90/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9370 - cosine_similarity: -0.9369 - val_loss: -0.8621 - val_cosine_similarity: -0.8600\n",
            "Epoch 91/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9369 - cosine_similarity: -0.9369 - val_loss: -0.8622 - val_cosine_similarity: -0.8601\n",
            "Epoch 92/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9369 - cosine_similarity: -0.9369 - val_loss: -0.8621 - val_cosine_similarity: -0.8600\n",
            "Epoch 93/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9370 - cosine_similarity: -0.9371 - val_loss: -0.8622 - val_cosine_similarity: -0.8601\n",
            "Epoch 94/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9370 - cosine_similarity: -0.9370 - val_loss: -0.8620 - val_cosine_similarity: -0.8600\n",
            "Epoch 95/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9370 - cosine_similarity: -0.9370 - val_loss: -0.8622 - val_cosine_similarity: -0.8601\n",
            "Epoch 96/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9370 - cosine_similarity: -0.9369 - val_loss: -0.8623 - val_cosine_similarity: -0.8602\n",
            "Epoch 97/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9370 - cosine_similarity: -0.9369 - val_loss: -0.8619 - val_cosine_similarity: -0.8598\n",
            "Epoch 98/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9370 - cosine_similarity: -0.9370 - val_loss: -0.8623 - val_cosine_similarity: -0.8602\n",
            "Epoch 99/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9371 - cosine_similarity: -0.9370 - val_loss: -0.8622 - val_cosine_similarity: -0.8602\n",
            "Epoch 100/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9371 - cosine_similarity: -0.9370 - val_loss: -0.8625 - val_cosine_similarity: -0.8605\n",
            "Epoch 101/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9371 - cosine_similarity: -0.9369 - val_loss: -0.8624 - val_cosine_similarity: -0.8602\n",
            "Epoch 102/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9372 - cosine_similarity: -0.9372 - val_loss: -0.8622 - val_cosine_similarity: -0.8602\n",
            "Epoch 103/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9371 - cosine_similarity: -0.9371 - val_loss: -0.8623 - val_cosine_similarity: -0.8602\n",
            "Epoch 104/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9372 - cosine_similarity: -0.9371 - val_loss: -0.8625 - val_cosine_similarity: -0.8604\n",
            "Epoch 105/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9372 - cosine_similarity: -0.9371 - val_loss: -0.8622 - val_cosine_similarity: -0.8601\n",
            "Epoch 106/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9370 - cosine_similarity: -0.9369 - val_loss: -0.8624 - val_cosine_similarity: -0.8603\n",
            "Epoch 107/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9372 - cosine_similarity: -0.9372 - val_loss: -0.8623 - val_cosine_similarity: -0.8601\n",
            "Epoch 108/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9372 - cosine_similarity: -0.9372 - val_loss: -0.8620 - val_cosine_similarity: -0.8600\n",
            "Epoch 109/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9371 - cosine_similarity: -0.9372 - val_loss: -0.8621 - val_cosine_similarity: -0.8600\n",
            "Epoch 110/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9372 - cosine_similarity: -0.9372 - val_loss: -0.8620 - val_cosine_similarity: -0.8599\n",
            "Epoch 111/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9372 - cosine_similarity: -0.9373 - val_loss: -0.8621 - val_cosine_similarity: -0.8600\n",
            "Epoch 112/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9374 - cosine_similarity: -0.9374 - val_loss: -0.8624 - val_cosine_similarity: -0.8603\n",
            "Epoch 113/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9373 - cosine_similarity: -0.9374 - val_loss: -0.8619 - val_cosine_similarity: -0.8598\n",
            "Epoch 114/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9372 - cosine_similarity: -0.9371 - val_loss: -0.8623 - val_cosine_similarity: -0.8602\n",
            "Epoch 115/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9374 - cosine_similarity: -0.9373 - val_loss: -0.8623 - val_cosine_similarity: -0.8603\n",
            "Epoch 116/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9373 - cosine_similarity: -0.9374 - val_loss: -0.8620 - val_cosine_similarity: -0.8600\n",
            "Epoch 117/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9374 - cosine_similarity: -0.9373 - val_loss: -0.8620 - val_cosine_similarity: -0.8599\n",
            "Epoch 118/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9373 - cosine_similarity: -0.9373 - val_loss: -0.8622 - val_cosine_similarity: -0.8601\n",
            "Epoch 119/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9375 - cosine_similarity: -0.9375 - val_loss: -0.8622 - val_cosine_similarity: -0.8602\n",
            "Epoch 120/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9374 - cosine_similarity: -0.9374 - val_loss: -0.8621 - val_cosine_similarity: -0.8601\n",
            "Epoch 121/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9374 - cosine_similarity: -0.9374 - val_loss: -0.8619 - val_cosine_similarity: -0.8599\n",
            "Epoch 122/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9374 - cosine_similarity: -0.9374 - val_loss: -0.8622 - val_cosine_similarity: -0.8601\n",
            "Epoch 123/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9376 - cosine_similarity: -0.9376 - val_loss: -0.8623 - val_cosine_similarity: -0.8602\n",
            "Epoch 124/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9374 - cosine_similarity: -0.9374 - val_loss: -0.8623 - val_cosine_similarity: -0.8602\n",
            "Epoch 125/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9375 - cosine_similarity: -0.9374 - val_loss: -0.8620 - val_cosine_similarity: -0.8599\n",
            "Epoch 126/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9375 - cosine_similarity: -0.9374 - val_loss: -0.8619 - val_cosine_similarity: -0.8598\n",
            "Epoch 127/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9375 - cosine_similarity: -0.9375 - val_loss: -0.8621 - val_cosine_similarity: -0.8600\n",
            "Epoch 128/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9375 - cosine_similarity: -0.9375 - val_loss: -0.8624 - val_cosine_similarity: -0.8603\n",
            "{}\n",
            "Epoch 1/200\n",
            "94/94 [==============================] - 1s 4ms/step - loss: -0.5629 - cosine_similarity: -0.5632 - val_loss: -0.7138 - val_cosine_similarity: -0.7123\n",
            "Epoch 2/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.8104 - cosine_similarity: -0.8105 - val_loss: -0.7822 - val_cosine_similarity: -0.7804\n",
            "Epoch 3/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.8642 - cosine_similarity: -0.8643 - val_loss: -0.8087 - val_cosine_similarity: -0.8069\n",
            "Epoch 4/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.8886 - cosine_similarity: -0.8886 - val_loss: -0.8242 - val_cosine_similarity: -0.8224\n",
            "Epoch 5/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9017 - cosine_similarity: -0.9017 - val_loss: -0.8315 - val_cosine_similarity: -0.8298\n",
            "Epoch 6/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9092 - cosine_similarity: -0.9091 - val_loss: -0.8379 - val_cosine_similarity: -0.8363\n",
            "Epoch 7/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9148 - cosine_similarity: -0.9148 - val_loss: -0.8418 - val_cosine_similarity: -0.8400\n",
            "Epoch 8/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9185 - cosine_similarity: -0.9184 - val_loss: -0.8440 - val_cosine_similarity: -0.8424\n",
            "Epoch 9/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9210 - cosine_similarity: -0.9210 - val_loss: -0.8466 - val_cosine_similarity: -0.8449\n",
            "Epoch 10/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9228 - cosine_similarity: -0.9228 - val_loss: -0.8478 - val_cosine_similarity: -0.8460\n",
            "Epoch 11/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9244 - cosine_similarity: -0.9244 - val_loss: -0.8480 - val_cosine_similarity: -0.8462\n",
            "Epoch 12/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9255 - cosine_similarity: -0.9255 - val_loss: -0.8492 - val_cosine_similarity: -0.8476\n",
            "Epoch 13/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9264 - cosine_similarity: -0.9264 - val_loss: -0.8502 - val_cosine_similarity: -0.8487\n",
            "Epoch 14/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9269 - cosine_similarity: -0.9268 - val_loss: -0.8512 - val_cosine_similarity: -0.8495\n",
            "Epoch 15/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9278 - cosine_similarity: -0.9279 - val_loss: -0.8504 - val_cosine_similarity: -0.8490\n",
            "Epoch 16/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9281 - cosine_similarity: -0.9281 - val_loss: -0.8511 - val_cosine_similarity: -0.8495\n",
            "Epoch 17/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9285 - cosine_similarity: -0.9285 - val_loss: -0.8521 - val_cosine_similarity: -0.8503\n",
            "Epoch 18/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9287 - cosine_similarity: -0.9287 - val_loss: -0.8524 - val_cosine_similarity: -0.8508\n",
            "Epoch 19/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9292 - cosine_similarity: -0.9291 - val_loss: -0.8521 - val_cosine_similarity: -0.8504\n",
            "Epoch 20/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9295 - cosine_similarity: -0.9296 - val_loss: -0.8522 - val_cosine_similarity: -0.8507\n",
            "Epoch 21/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9297 - cosine_similarity: -0.9297 - val_loss: -0.8519 - val_cosine_similarity: -0.8504\n",
            "Epoch 22/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9295 - cosine_similarity: -0.9295 - val_loss: -0.8526 - val_cosine_similarity: -0.8510\n",
            "Epoch 23/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9302 - cosine_similarity: -0.9302 - val_loss: -0.8524 - val_cosine_similarity: -0.8510\n",
            "Epoch 24/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9303 - cosine_similarity: -0.9303 - val_loss: -0.8525 - val_cosine_similarity: -0.8511\n",
            "Epoch 25/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9306 - cosine_similarity: -0.9306 - val_loss: -0.8525 - val_cosine_similarity: -0.8510\n",
            "Epoch 26/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9307 - cosine_similarity: -0.9306 - val_loss: -0.8529 - val_cosine_similarity: -0.8515\n",
            "Epoch 27/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9309 - cosine_similarity: -0.9309 - val_loss: -0.8527 - val_cosine_similarity: -0.8513\n",
            "Epoch 28/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9306 - cosine_similarity: -0.9306 - val_loss: -0.8524 - val_cosine_similarity: -0.8510\n",
            "Epoch 29/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9311 - cosine_similarity: -0.9310 - val_loss: -0.8529 - val_cosine_similarity: -0.8514\n",
            "Epoch 30/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9307 - cosine_similarity: -0.9307 - val_loss: -0.8531 - val_cosine_similarity: -0.8515\n",
            "Epoch 31/200\n",
            "94/94 [==============================] - 0s 3ms/step - loss: -0.9311 - cosine_similarity: -0.9312 - val_loss: -0.8532 - val_cosine_similarity: -0.8517\n",
            "Epoch 32/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9311 - cosine_similarity: -0.9310 - val_loss: -0.8533 - val_cosine_similarity: -0.8516\n",
            "Epoch 33/200\n",
            "94/94 [==============================] - 0s 3ms/step - loss: -0.9312 - cosine_similarity: -0.9313 - val_loss: -0.8529 - val_cosine_similarity: -0.8514\n",
            "Epoch 34/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9316 - cosine_similarity: -0.9316 - val_loss: -0.8532 - val_cosine_similarity: -0.8517\n",
            "Epoch 35/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9317 - cosine_similarity: -0.9317 - val_loss: -0.8533 - val_cosine_similarity: -0.8518\n",
            "Epoch 36/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9318 - cosine_similarity: -0.9318 - val_loss: -0.8530 - val_cosine_similarity: -0.8515\n",
            "Epoch 37/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9320 - cosine_similarity: -0.9320 - val_loss: -0.8530 - val_cosine_similarity: -0.8517\n",
            "Epoch 38/200\n",
            "94/94 [==============================] - 0s 3ms/step - loss: -0.9321 - cosine_similarity: -0.9320 - val_loss: -0.8530 - val_cosine_similarity: -0.8516\n",
            "Epoch 39/200\n",
            "94/94 [==============================] - 0s 3ms/step - loss: -0.9318 - cosine_similarity: -0.9319 - val_loss: -0.8528 - val_cosine_similarity: -0.8514\n",
            "Epoch 40/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9321 - cosine_similarity: -0.9321 - val_loss: -0.8535 - val_cosine_similarity: -0.8518\n",
            "Epoch 41/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9321 - cosine_similarity: -0.9320 - val_loss: -0.8534 - val_cosine_similarity: -0.8519\n",
            "Epoch 42/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9323 - cosine_similarity: -0.9323 - val_loss: -0.8535 - val_cosine_similarity: -0.8521\n",
            "Epoch 43/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9320 - cosine_similarity: -0.9320 - val_loss: -0.8532 - val_cosine_similarity: -0.8517\n",
            "Epoch 44/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9326 - cosine_similarity: -0.9326 - val_loss: -0.8533 - val_cosine_similarity: -0.8518\n",
            "Epoch 45/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9325 - cosine_similarity: -0.9325 - val_loss: -0.8534 - val_cosine_similarity: -0.8518\n",
            "Epoch 46/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9327 - cosine_similarity: -0.9327 - val_loss: -0.8531 - val_cosine_similarity: -0.8516\n",
            "Epoch 47/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9324 - cosine_similarity: -0.9324 - val_loss: -0.8532 - val_cosine_similarity: -0.8518\n",
            "Epoch 48/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9324 - cosine_similarity: -0.9324 - val_loss: -0.8530 - val_cosine_similarity: -0.8514\n",
            "Epoch 49/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9326 - cosine_similarity: -0.9326 - val_loss: -0.8536 - val_cosine_similarity: -0.8521\n",
            "Epoch 50/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9326 - cosine_similarity: -0.9326 - val_loss: -0.8531 - val_cosine_similarity: -0.8516\n",
            "Epoch 51/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9329 - cosine_similarity: -0.9329 - val_loss: -0.8535 - val_cosine_similarity: -0.8520\n",
            "Epoch 52/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9326 - cosine_similarity: -0.9327 - val_loss: -0.8533 - val_cosine_similarity: -0.8519\n",
            "Epoch 53/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9329 - cosine_similarity: -0.9330 - val_loss: -0.8533 - val_cosine_similarity: -0.8518\n",
            "Epoch 54/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9332 - cosine_similarity: -0.9332 - val_loss: -0.8528 - val_cosine_similarity: -0.8514\n",
            "Epoch 55/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9329 - cosine_similarity: -0.9329 - val_loss: -0.8525 - val_cosine_similarity: -0.8510\n",
            "Epoch 56/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9330 - cosine_similarity: -0.9330 - val_loss: -0.8533 - val_cosine_similarity: -0.8519\n",
            "Epoch 57/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9334 - cosine_similarity: -0.9333 - val_loss: -0.8533 - val_cosine_similarity: -0.8517\n",
            "Epoch 58/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9333 - cosine_similarity: -0.9333 - val_loss: -0.8530 - val_cosine_similarity: -0.8515\n",
            "Epoch 59/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9335 - cosine_similarity: -0.9334 - val_loss: -0.8532 - val_cosine_similarity: -0.8517\n",
            "Epoch 60/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9333 - cosine_similarity: -0.9333 - val_loss: -0.8531 - val_cosine_similarity: -0.8517\n",
            "Epoch 61/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9336 - cosine_similarity: -0.9335 - val_loss: -0.8533 - val_cosine_similarity: -0.8517\n",
            "Epoch 62/200\n",
            "94/94 [==============================] - 0s 3ms/step - loss: -0.9331 - cosine_similarity: -0.9331 - val_loss: -0.8534 - val_cosine_similarity: -0.8519\n",
            "Epoch 63/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9335 - cosine_similarity: -0.9335 - val_loss: -0.8533 - val_cosine_similarity: -0.8518\n",
            "Epoch 64/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9336 - cosine_similarity: -0.9336 - val_loss: -0.8531 - val_cosine_similarity: -0.8517\n",
            "Epoch 65/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9333 - cosine_similarity: -0.9334 - val_loss: -0.8533 - val_cosine_similarity: -0.8518\n",
            "Epoch 66/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9335 - cosine_similarity: -0.9335 - val_loss: -0.8535 - val_cosine_similarity: -0.8521\n",
            "Epoch 67/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9336 - cosine_similarity: -0.9337 - val_loss: -0.8534 - val_cosine_similarity: -0.8518\n",
            "Epoch 68/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9337 - cosine_similarity: -0.9336 - val_loss: -0.8531 - val_cosine_similarity: -0.8517\n",
            "Epoch 69/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9335 - cosine_similarity: -0.9336 - val_loss: -0.8533 - val_cosine_similarity: -0.8518\n",
            "Epoch 70/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9335 - cosine_similarity: -0.9335 - val_loss: -0.8534 - val_cosine_similarity: -0.8518\n",
            "Epoch 71/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9340 - cosine_similarity: -0.9340 - val_loss: -0.8530 - val_cosine_similarity: -0.8515\n",
            "Epoch 72/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9339 - cosine_similarity: -0.9339 - val_loss: -0.8529 - val_cosine_similarity: -0.8515\n",
            "Epoch 73/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9337 - cosine_similarity: -0.9337 - val_loss: -0.8530 - val_cosine_similarity: -0.8516\n",
            "Epoch 74/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9340 - cosine_similarity: -0.9341 - val_loss: -0.8530 - val_cosine_similarity: -0.8516\n",
            "Epoch 75/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9339 - cosine_similarity: -0.9339 - val_loss: -0.8534 - val_cosine_similarity: -0.8519\n",
            "Epoch 76/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9339 - cosine_similarity: -0.9339 - val_loss: -0.8536 - val_cosine_similarity: -0.8521\n",
            "Epoch 77/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9341 - cosine_similarity: -0.9341 - val_loss: -0.8534 - val_cosine_similarity: -0.8518\n",
            "Epoch 78/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9339 - cosine_similarity: -0.9340 - val_loss: -0.8536 - val_cosine_similarity: -0.8521\n",
            "Epoch 79/200\n",
            "94/94 [==============================] - 0s 3ms/step - loss: -0.9336 - cosine_similarity: -0.9336 - val_loss: -0.8529 - val_cosine_similarity: -0.8515\n",
            "Epoch 80/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9342 - cosine_similarity: -0.9342 - val_loss: -0.8530 - val_cosine_similarity: -0.8515\n",
            "Epoch 81/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9344 - cosine_similarity: -0.9344 - val_loss: -0.8533 - val_cosine_similarity: -0.8518\n",
            "Epoch 82/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9344 - cosine_similarity: -0.9343 - val_loss: -0.8534 - val_cosine_similarity: -0.8518\n",
            "Epoch 83/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9342 - cosine_similarity: -0.9342 - val_loss: -0.8529 - val_cosine_similarity: -0.8514\n",
            "Epoch 84/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9345 - cosine_similarity: -0.9345 - val_loss: -0.8535 - val_cosine_similarity: -0.8521\n",
            "Epoch 85/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9345 - cosine_similarity: -0.9344 - val_loss: -0.8533 - val_cosine_similarity: -0.8518\n",
            "Epoch 86/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9344 - cosine_similarity: -0.9344 - val_loss: -0.8531 - val_cosine_similarity: -0.8516\n",
            "Epoch 87/200\n",
            "94/94 [==============================] - 0s 3ms/step - loss: -0.9345 - cosine_similarity: -0.9345 - val_loss: -0.8528 - val_cosine_similarity: -0.8513\n",
            "Epoch 88/200\n",
            "94/94 [==============================] - 0s 3ms/step - loss: -0.9346 - cosine_similarity: -0.9347 - val_loss: -0.8529 - val_cosine_similarity: -0.8513\n",
            "Epoch 89/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9347 - cosine_similarity: -0.9347 - val_loss: -0.8531 - val_cosine_similarity: -0.8517\n",
            "Epoch 90/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9345 - cosine_similarity: -0.9345 - val_loss: -0.8528 - val_cosine_similarity: -0.8513\n",
            "Epoch 91/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9348 - cosine_similarity: -0.9348 - val_loss: -0.8529 - val_cosine_similarity: -0.8515\n",
            "Epoch 92/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9343 - cosine_similarity: -0.9343 - val_loss: -0.8531 - val_cosine_similarity: -0.8515\n",
            "Epoch 93/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9346 - cosine_similarity: -0.9345 - val_loss: -0.8528 - val_cosine_similarity: -0.8514\n",
            "Epoch 94/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9346 - cosine_similarity: -0.9346 - val_loss: -0.8529 - val_cosine_similarity: -0.8514\n",
            "Epoch 95/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9349 - cosine_similarity: -0.9349 - val_loss: -0.8535 - val_cosine_similarity: -0.8520\n",
            "Epoch 96/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9347 - cosine_similarity: -0.9346 - val_loss: -0.8528 - val_cosine_similarity: -0.8512\n",
            "Epoch 97/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9348 - cosine_similarity: -0.9347 - val_loss: -0.8531 - val_cosine_similarity: -0.8516\n",
            "Epoch 98/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9347 - cosine_similarity: -0.9347 - val_loss: -0.8534 - val_cosine_similarity: -0.8518\n",
            "Epoch 99/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9350 - cosine_similarity: -0.9350 - val_loss: -0.8529 - val_cosine_similarity: -0.8515\n",
            "Epoch 100/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9350 - cosine_similarity: -0.9349 - val_loss: -0.8533 - val_cosine_similarity: -0.8517\n",
            "Epoch 101/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9349 - cosine_similarity: -0.9349 - val_loss: -0.8531 - val_cosine_similarity: -0.8517\n",
            "Epoch 102/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9349 - cosine_similarity: -0.9349 - val_loss: -0.8532 - val_cosine_similarity: -0.8518\n",
            "Epoch 103/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9351 - cosine_similarity: -0.9351 - val_loss: -0.8530 - val_cosine_similarity: -0.8515\n",
            "Epoch 104/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9351 - cosine_similarity: -0.9351 - val_loss: -0.8530 - val_cosine_similarity: -0.8514\n",
            "Epoch 105/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9350 - cosine_similarity: -0.9349 - val_loss: -0.8529 - val_cosine_similarity: -0.8514\n",
            "Epoch 106/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9352 - cosine_similarity: -0.9353 - val_loss: -0.8534 - val_cosine_similarity: -0.8519\n",
            "Epoch 107/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9352 - cosine_similarity: -0.9352 - val_loss: -0.8529 - val_cosine_similarity: -0.8515\n",
            "Epoch 108/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9351 - cosine_similarity: -0.9351 - val_loss: -0.8528 - val_cosine_similarity: -0.8513\n",
            "Epoch 109/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9349 - cosine_similarity: -0.9350 - val_loss: -0.8534 - val_cosine_similarity: -0.8518\n",
            "Epoch 110/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9350 - cosine_similarity: -0.9350 - val_loss: -0.8533 - val_cosine_similarity: -0.8518\n",
            "Epoch 111/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9353 - cosine_similarity: -0.9353 - val_loss: -0.8529 - val_cosine_similarity: -0.8515\n",
            "Epoch 112/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9352 - cosine_similarity: -0.9352 - val_loss: -0.8523 - val_cosine_similarity: -0.8507\n",
            "Epoch 113/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9352 - cosine_similarity: -0.9352 - val_loss: -0.8532 - val_cosine_similarity: -0.8517\n",
            "Epoch 114/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9355 - cosine_similarity: -0.9355 - val_loss: -0.8534 - val_cosine_similarity: -0.8518\n",
            "Epoch 115/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9355 - cosine_similarity: -0.9355 - val_loss: -0.8531 - val_cosine_similarity: -0.8516\n",
            "Epoch 116/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9354 - cosine_similarity: -0.9354 - val_loss: -0.8536 - val_cosine_similarity: -0.8520\n",
            "Epoch 117/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9354 - cosine_similarity: -0.9353 - val_loss: -0.8530 - val_cosine_similarity: -0.8514\n",
            "Epoch 118/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9354 - cosine_similarity: -0.9354 - val_loss: -0.8529 - val_cosine_similarity: -0.8516\n",
            "Epoch 119/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9354 - cosine_similarity: -0.9354 - val_loss: -0.8530 - val_cosine_similarity: -0.8515\n",
            "Epoch 1/200\n",
            "94/94 [==============================] - 1s 4ms/step - loss: -0.5132 - cosine_similarity: -0.5136 - val_loss: -0.5742 - val_cosine_similarity: -0.5747\n",
            "Epoch 2/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.6691 - cosine_similarity: -0.6692 - val_loss: -0.6638 - val_cosine_similarity: -0.6632\n",
            "Epoch 3/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.7513 - cosine_similarity: -0.7514 - val_loss: -0.7169 - val_cosine_similarity: -0.7157\n",
            "Epoch 4/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.8036 - cosine_similarity: -0.8037 - val_loss: -0.7521 - val_cosine_similarity: -0.7506\n",
            "Epoch 5/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.8370 - cosine_similarity: -0.8372 - val_loss: -0.7734 - val_cosine_similarity: -0.7719\n",
            "Epoch 6/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.8584 - cosine_similarity: -0.8584 - val_loss: -0.7888 - val_cosine_similarity: -0.7873\n",
            "Epoch 7/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.8735 - cosine_similarity: -0.8735 - val_loss: -0.8002 - val_cosine_similarity: -0.7988\n",
            "Epoch 8/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.8847 - cosine_similarity: -0.8847 - val_loss: -0.8087 - val_cosine_similarity: -0.8073\n",
            "Epoch 9/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.8932 - cosine_similarity: -0.8933 - val_loss: -0.8152 - val_cosine_similarity: -0.8139\n",
            "Epoch 10/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.8997 - cosine_similarity: -0.8997 - val_loss: -0.8205 - val_cosine_similarity: -0.8193\n",
            "Epoch 11/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9046 - cosine_similarity: -0.9046 - val_loss: -0.8245 - val_cosine_similarity: -0.8234\n",
            "Epoch 12/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9083 - cosine_similarity: -0.9083 - val_loss: -0.8277 - val_cosine_similarity: -0.8267\n",
            "Epoch 13/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9112 - cosine_similarity: -0.9112 - val_loss: -0.8306 - val_cosine_similarity: -0.8296\n",
            "Epoch 14/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9136 - cosine_similarity: -0.9135 - val_loss: -0.8329 - val_cosine_similarity: -0.8319\n",
            "Epoch 15/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9153 - cosine_similarity: -0.9154 - val_loss: -0.8343 - val_cosine_similarity: -0.8334\n",
            "Epoch 16/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9170 - cosine_similarity: -0.9170 - val_loss: -0.8357 - val_cosine_similarity: -0.8348\n",
            "Epoch 17/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9181 - cosine_similarity: -0.9180 - val_loss: -0.8372 - val_cosine_similarity: -0.8364\n",
            "Epoch 18/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9191 - cosine_similarity: -0.9191 - val_loss: -0.8380 - val_cosine_similarity: -0.8371\n",
            "Epoch 19/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9199 - cosine_similarity: -0.9199 - val_loss: -0.8392 - val_cosine_similarity: -0.8384\n",
            "Epoch 20/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9207 - cosine_similarity: -0.9206 - val_loss: -0.8396 - val_cosine_similarity: -0.8387\n",
            "Epoch 21/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9212 - cosine_similarity: -0.9212 - val_loss: -0.8404 - val_cosine_similarity: -0.8396\n",
            "Epoch 22/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9217 - cosine_similarity: -0.9217 - val_loss: -0.8412 - val_cosine_similarity: -0.8404\n",
            "Epoch 23/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9221 - cosine_similarity: -0.9221 - val_loss: -0.8413 - val_cosine_similarity: -0.8405\n",
            "Epoch 24/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9225 - cosine_similarity: -0.9225 - val_loss: -0.8417 - val_cosine_similarity: -0.8408\n",
            "Epoch 25/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9228 - cosine_similarity: -0.9228 - val_loss: -0.8424 - val_cosine_similarity: -0.8416\n",
            "Epoch 26/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9231 - cosine_similarity: -0.9230 - val_loss: -0.8424 - val_cosine_similarity: -0.8416\n",
            "Epoch 27/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9234 - cosine_similarity: -0.9234 - val_loss: -0.8427 - val_cosine_similarity: -0.8420\n",
            "Epoch 28/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9235 - cosine_similarity: -0.9235 - val_loss: -0.8427 - val_cosine_similarity: -0.8419\n",
            "Epoch 29/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9237 - cosine_similarity: -0.9236 - val_loss: -0.8433 - val_cosine_similarity: -0.8426\n",
            "Epoch 30/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9239 - cosine_similarity: -0.9240 - val_loss: -0.8433 - val_cosine_similarity: -0.8426\n",
            "Epoch 31/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9241 - cosine_similarity: -0.9241 - val_loss: -0.8433 - val_cosine_similarity: -0.8426\n",
            "Epoch 32/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9242 - cosine_similarity: -0.9242 - val_loss: -0.8435 - val_cosine_similarity: -0.8427\n",
            "Epoch 33/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9244 - cosine_similarity: -0.9244 - val_loss: -0.8439 - val_cosine_similarity: -0.8432\n",
            "Epoch 34/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9244 - cosine_similarity: -0.9244 - val_loss: -0.8439 - val_cosine_similarity: -0.8432\n",
            "Epoch 35/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9245 - cosine_similarity: -0.9244 - val_loss: -0.8436 - val_cosine_similarity: -0.8429\n",
            "Epoch 36/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9244 - cosine_similarity: -0.9244 - val_loss: -0.8436 - val_cosine_similarity: -0.8428\n",
            "Epoch 37/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9247 - cosine_similarity: -0.9246 - val_loss: -0.8440 - val_cosine_similarity: -0.8432\n",
            "Epoch 38/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9246 - cosine_similarity: -0.9246 - val_loss: -0.8439 - val_cosine_similarity: -0.8432\n",
            "Epoch 39/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9248 - cosine_similarity: -0.9248 - val_loss: -0.8438 - val_cosine_similarity: -0.8431\n",
            "Epoch 40/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9249 - cosine_similarity: -0.9249 - val_loss: -0.8444 - val_cosine_similarity: -0.8437\n",
            "Epoch 41/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9249 - cosine_similarity: -0.9249 - val_loss: -0.8442 - val_cosine_similarity: -0.8434\n",
            "Epoch 42/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9251 - cosine_similarity: -0.9251 - val_loss: -0.8443 - val_cosine_similarity: -0.8436\n",
            "Epoch 43/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9250 - cosine_similarity: -0.9250 - val_loss: -0.8446 - val_cosine_similarity: -0.8439\n",
            "Epoch 44/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9252 - cosine_similarity: -0.9252 - val_loss: -0.8441 - val_cosine_similarity: -0.8434\n",
            "Epoch 45/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9252 - cosine_similarity: -0.9252 - val_loss: -0.8445 - val_cosine_similarity: -0.8438\n",
            "Epoch 46/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9251 - cosine_similarity: -0.9251 - val_loss: -0.8445 - val_cosine_similarity: -0.8438\n",
            "Epoch 47/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9253 - cosine_similarity: -0.9253 - val_loss: -0.8447 - val_cosine_similarity: -0.8439\n",
            "Epoch 48/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9252 - cosine_similarity: -0.9253 - val_loss: -0.8443 - val_cosine_similarity: -0.8436\n",
            "Epoch 49/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9254 - cosine_similarity: -0.9254 - val_loss: -0.8447 - val_cosine_similarity: -0.8440\n",
            "Epoch 50/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9254 - cosine_similarity: -0.9254 - val_loss: -0.8446 - val_cosine_similarity: -0.8439\n",
            "Epoch 51/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9254 - cosine_similarity: -0.9253 - val_loss: -0.8447 - val_cosine_similarity: -0.8440\n",
            "Epoch 52/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9254 - cosine_similarity: -0.9254 - val_loss: -0.8448 - val_cosine_similarity: -0.8441\n",
            "Epoch 53/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9255 - cosine_similarity: -0.9255 - val_loss: -0.8444 - val_cosine_similarity: -0.8437\n",
            "Epoch 54/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9256 - cosine_similarity: -0.9256 - val_loss: -0.8449 - val_cosine_similarity: -0.8441\n",
            "Epoch 55/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9256 - cosine_similarity: -0.9255 - val_loss: -0.8447 - val_cosine_similarity: -0.8440\n",
            "Epoch 56/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9256 - cosine_similarity: -0.9254 - val_loss: -0.8444 - val_cosine_similarity: -0.8437\n",
            "Epoch 57/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9257 - cosine_similarity: -0.9258 - val_loss: -0.8443 - val_cosine_similarity: -0.8436\n",
            "Epoch 58/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9256 - cosine_similarity: -0.9257 - val_loss: -0.8450 - val_cosine_similarity: -0.8443\n",
            "Epoch 59/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9258 - cosine_similarity: -0.9258 - val_loss: -0.8450 - val_cosine_similarity: -0.8443\n",
            "Epoch 60/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9257 - cosine_similarity: -0.9257 - val_loss: -0.8444 - val_cosine_similarity: -0.8437\n",
            "Epoch 61/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9258 - cosine_similarity: -0.9257 - val_loss: -0.8448 - val_cosine_similarity: -0.8441\n",
            "Epoch 62/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9258 - cosine_similarity: -0.9259 - val_loss: -0.8449 - val_cosine_similarity: -0.8442\n",
            "Epoch 63/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9259 - cosine_similarity: -0.9259 - val_loss: -0.8448 - val_cosine_similarity: -0.8441\n",
            "Epoch 64/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9259 - cosine_similarity: -0.9260 - val_loss: -0.8451 - val_cosine_similarity: -0.8444\n",
            "Epoch 65/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9260 - cosine_similarity: -0.9259 - val_loss: -0.8444 - val_cosine_similarity: -0.8437\n",
            "Epoch 66/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9259 - cosine_similarity: -0.9259 - val_loss: -0.8448 - val_cosine_similarity: -0.8441\n",
            "Epoch 67/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9259 - cosine_similarity: -0.9259 - val_loss: -0.8447 - val_cosine_similarity: -0.8440\n",
            "Epoch 68/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9259 - cosine_similarity: -0.9259 - val_loss: -0.8449 - val_cosine_similarity: -0.8441\n",
            "Epoch 69/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9259 - cosine_similarity: -0.9259 - val_loss: -0.8444 - val_cosine_similarity: -0.8436\n",
            "Epoch 70/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9261 - cosine_similarity: -0.9260 - val_loss: -0.8445 - val_cosine_similarity: -0.8437\n",
            "Epoch 71/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9260 - cosine_similarity: -0.9259 - val_loss: -0.8445 - val_cosine_similarity: -0.8438\n",
            "Epoch 72/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9261 - cosine_similarity: -0.9260 - val_loss: -0.8444 - val_cosine_similarity: -0.8437\n",
            "Epoch 73/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9261 - cosine_similarity: -0.9261 - val_loss: -0.8448 - val_cosine_similarity: -0.8441\n",
            "Epoch 74/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9261 - cosine_similarity: -0.9261 - val_loss: -0.8449 - val_cosine_similarity: -0.8442\n",
            "Epoch 75/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9261 - cosine_similarity: -0.9261 - val_loss: -0.8446 - val_cosine_similarity: -0.8438\n",
            "Epoch 76/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9262 - cosine_similarity: -0.9261 - val_loss: -0.8445 - val_cosine_similarity: -0.8438\n",
            "Epoch 77/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9263 - cosine_similarity: -0.9263 - val_loss: -0.8448 - val_cosine_similarity: -0.8441\n",
            "Epoch 78/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9262 - cosine_similarity: -0.9261 - val_loss: -0.8448 - val_cosine_similarity: -0.8441\n",
            "Epoch 79/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9261 - cosine_similarity: -0.9262 - val_loss: -0.8446 - val_cosine_similarity: -0.8439\n",
            "Epoch 80/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9262 - cosine_similarity: -0.9261 - val_loss: -0.8449 - val_cosine_similarity: -0.8442\n",
            "Epoch 81/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9263 - cosine_similarity: -0.9264 - val_loss: -0.8446 - val_cosine_similarity: -0.8438\n",
            "Epoch 82/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9263 - cosine_similarity: -0.9262 - val_loss: -0.8447 - val_cosine_similarity: -0.8440\n",
            "Epoch 83/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9262 - cosine_similarity: -0.9261 - val_loss: -0.8449 - val_cosine_similarity: -0.8441\n",
            "Epoch 84/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9263 - cosine_similarity: -0.9263 - val_loss: -0.8449 - val_cosine_similarity: -0.8442\n",
            "Epoch 85/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9263 - cosine_similarity: -0.9264 - val_loss: -0.8445 - val_cosine_similarity: -0.8437\n",
            "Epoch 86/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9263 - cosine_similarity: -0.9264 - val_loss: -0.8450 - val_cosine_similarity: -0.8443\n",
            "Epoch 87/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9264 - cosine_similarity: -0.9263 - val_loss: -0.8446 - val_cosine_similarity: -0.8438\n",
            "Epoch 88/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9265 - cosine_similarity: -0.9265 - val_loss: -0.8448 - val_cosine_similarity: -0.8441\n",
            "Epoch 89/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9264 - cosine_similarity: -0.9263 - val_loss: -0.8445 - val_cosine_similarity: -0.8438\n",
            "Epoch 90/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9264 - cosine_similarity: -0.9263 - val_loss: -0.8446 - val_cosine_similarity: -0.8438\n",
            "Epoch 91/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9264 - cosine_similarity: -0.9263 - val_loss: -0.8444 - val_cosine_similarity: -0.8437\n",
            "Epoch 92/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9265 - cosine_similarity: -0.9264 - val_loss: -0.8448 - val_cosine_similarity: -0.8441\n",
            "Epoch 93/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9265 - cosine_similarity: -0.9265 - val_loss: -0.8444 - val_cosine_similarity: -0.8437\n",
            "Epoch 94/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9264 - cosine_similarity: -0.9264 - val_loss: -0.8445 - val_cosine_similarity: -0.8438\n",
            "Epoch 95/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9265 - cosine_similarity: -0.9264 - val_loss: -0.8448 - val_cosine_similarity: -0.8441\n",
            "Epoch 96/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9266 - cosine_similarity: -0.9265 - val_loss: -0.8447 - val_cosine_similarity: -0.8439\n",
            "Epoch 97/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9266 - cosine_similarity: -0.9266 - val_loss: -0.8448 - val_cosine_similarity: -0.8441\n",
            "Epoch 98/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9266 - cosine_similarity: -0.9265 - val_loss: -0.8444 - val_cosine_similarity: -0.8436\n",
            "Epoch 99/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9266 - cosine_similarity: -0.9266 - val_loss: -0.8445 - val_cosine_similarity: -0.8437\n",
            "Epoch 100/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9266 - cosine_similarity: -0.9265 - val_loss: -0.8446 - val_cosine_similarity: -0.8438\n",
            "Epoch 101/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9265 - cosine_similarity: -0.9264 - val_loss: -0.8446 - val_cosine_similarity: -0.8438\n",
            "Epoch 102/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9267 - cosine_similarity: -0.9267 - val_loss: -0.8443 - val_cosine_similarity: -0.8435\n",
            "Epoch 103/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9266 - cosine_similarity: -0.9266 - val_loss: -0.8445 - val_cosine_similarity: -0.8437\n",
            "Epoch 104/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9266 - cosine_similarity: -0.9266 - val_loss: -0.8447 - val_cosine_similarity: -0.8440\n",
            "Epoch 105/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9266 - cosine_similarity: -0.9266 - val_loss: -0.8444 - val_cosine_similarity: -0.8437\n",
            "Epoch 106/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9266 - cosine_similarity: -0.9266 - val_loss: -0.8446 - val_cosine_similarity: -0.8439\n",
            "Epoch 107/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9266 - cosine_similarity: -0.9265 - val_loss: -0.8444 - val_cosine_similarity: -0.8437\n",
            "{}\n",
            "Epoch 1/200\n",
            "94/94 [==============================] - 1s 4ms/step - loss: -0.5616 - cosine_similarity: -0.5621 - val_loss: -0.7182 - val_cosine_similarity: -0.7168\n",
            "Epoch 2/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.8109 - cosine_similarity: -0.8110 - val_loss: -0.7862 - val_cosine_similarity: -0.7846\n",
            "Epoch 3/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.8647 - cosine_similarity: -0.8647 - val_loss: -0.8155 - val_cosine_similarity: -0.8138\n",
            "Epoch 4/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.8891 - cosine_similarity: -0.8890 - val_loss: -0.8310 - val_cosine_similarity: -0.8293\n",
            "Epoch 5/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9025 - cosine_similarity: -0.9025 - val_loss: -0.8401 - val_cosine_similarity: -0.8383\n",
            "Epoch 6/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9104 - cosine_similarity: -0.9104 - val_loss: -0.8457 - val_cosine_similarity: -0.8439\n",
            "Epoch 7/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9158 - cosine_similarity: -0.9158 - val_loss: -0.8496 - val_cosine_similarity: -0.8478\n",
            "Epoch 8/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9191 - cosine_similarity: -0.9191 - val_loss: -0.8528 - val_cosine_similarity: -0.8509\n",
            "Epoch 9/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9221 - cosine_similarity: -0.9221 - val_loss: -0.8547 - val_cosine_similarity: -0.8528\n",
            "Epoch 10/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9237 - cosine_similarity: -0.9237 - val_loss: -0.8566 - val_cosine_similarity: -0.8547\n",
            "Epoch 11/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9250 - cosine_similarity: -0.9250 - val_loss: -0.8568 - val_cosine_similarity: -0.8550\n",
            "Epoch 12/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9263 - cosine_similarity: -0.9263 - val_loss: -0.8587 - val_cosine_similarity: -0.8567\n",
            "Epoch 13/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9271 - cosine_similarity: -0.9271 - val_loss: -0.8589 - val_cosine_similarity: -0.8570\n",
            "Epoch 14/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9279 - cosine_similarity: -0.9279 - val_loss: -0.8596 - val_cosine_similarity: -0.8577\n",
            "Epoch 15/200\n",
            "94/94 [==============================] - 0s 3ms/step - loss: -0.9284 - cosine_similarity: -0.9284 - val_loss: -0.8599 - val_cosine_similarity: -0.8580\n",
            "Epoch 16/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9291 - cosine_similarity: -0.9291 - val_loss: -0.8605 - val_cosine_similarity: -0.8586\n",
            "Epoch 17/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9293 - cosine_similarity: -0.9292 - val_loss: -0.8603 - val_cosine_similarity: -0.8583\n",
            "Epoch 18/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9299 - cosine_similarity: -0.9299 - val_loss: -0.8611 - val_cosine_similarity: -0.8591\n",
            "Epoch 19/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9297 - cosine_similarity: -0.9297 - val_loss: -0.8614 - val_cosine_similarity: -0.8594\n",
            "Epoch 20/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9302 - cosine_similarity: -0.9303 - val_loss: -0.8610 - val_cosine_similarity: -0.8591\n",
            "Epoch 21/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9306 - cosine_similarity: -0.9306 - val_loss: -0.8613 - val_cosine_similarity: -0.8593\n",
            "Epoch 22/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9306 - cosine_similarity: -0.9306 - val_loss: -0.8617 - val_cosine_similarity: -0.8597\n",
            "Epoch 23/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9309 - cosine_similarity: -0.9309 - val_loss: -0.8616 - val_cosine_similarity: -0.8597\n",
            "Epoch 24/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9310 - cosine_similarity: -0.9310 - val_loss: -0.8617 - val_cosine_similarity: -0.8597\n",
            "Epoch 25/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9311 - cosine_similarity: -0.9310 - val_loss: -0.8618 - val_cosine_similarity: -0.8598\n",
            "Epoch 26/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9313 - cosine_similarity: -0.9313 - val_loss: -0.8611 - val_cosine_similarity: -0.8590\n",
            "Epoch 27/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9316 - cosine_similarity: -0.9316 - val_loss: -0.8621 - val_cosine_similarity: -0.8601\n",
            "Epoch 28/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9315 - cosine_similarity: -0.9315 - val_loss: -0.8622 - val_cosine_similarity: -0.8602\n",
            "Epoch 29/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9318 - cosine_similarity: -0.9317 - val_loss: -0.8618 - val_cosine_similarity: -0.8597\n",
            "Epoch 30/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9319 - cosine_similarity: -0.9319 - val_loss: -0.8616 - val_cosine_similarity: -0.8596\n",
            "Epoch 31/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9320 - cosine_similarity: -0.9320 - val_loss: -0.8621 - val_cosine_similarity: -0.8601\n",
            "Epoch 32/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9320 - cosine_similarity: -0.9321 - val_loss: -0.8619 - val_cosine_similarity: -0.8600\n",
            "Epoch 33/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9321 - cosine_similarity: -0.9321 - val_loss: -0.8617 - val_cosine_similarity: -0.8597\n",
            "Epoch 34/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9321 - cosine_similarity: -0.9320 - val_loss: -0.8622 - val_cosine_similarity: -0.8602\n",
            "Epoch 35/200\n",
            "94/94 [==============================] - 0s 3ms/step - loss: -0.9324 - cosine_similarity: -0.9323 - val_loss: -0.8622 - val_cosine_similarity: -0.8601\n",
            "Epoch 36/200\n",
            "94/94 [==============================] - 0s 3ms/step - loss: -0.9323 - cosine_similarity: -0.9323 - val_loss: -0.8621 - val_cosine_similarity: -0.8601\n",
            "Epoch 37/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9325 - cosine_similarity: -0.9326 - val_loss: -0.8622 - val_cosine_similarity: -0.8602\n",
            "Epoch 38/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9324 - cosine_similarity: -0.9325 - val_loss: -0.8617 - val_cosine_similarity: -0.8597\n",
            "Epoch 39/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9327 - cosine_similarity: -0.9327 - val_loss: -0.8618 - val_cosine_similarity: -0.8599\n",
            "Epoch 40/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9326 - cosine_similarity: -0.9326 - val_loss: -0.8626 - val_cosine_similarity: -0.8606\n",
            "Epoch 41/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9329 - cosine_similarity: -0.9329 - val_loss: -0.8622 - val_cosine_similarity: -0.8603\n",
            "Epoch 42/200\n",
            "94/94 [==============================] - 0s 3ms/step - loss: -0.9328 - cosine_similarity: -0.9327 - val_loss: -0.8624 - val_cosine_similarity: -0.8604\n",
            "Epoch 43/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9329 - cosine_similarity: -0.9329 - val_loss: -0.8624 - val_cosine_similarity: -0.8604\n",
            "Epoch 44/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9331 - cosine_similarity: -0.9331 - val_loss: -0.8625 - val_cosine_similarity: -0.8605\n",
            "Epoch 45/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9330 - cosine_similarity: -0.9330 - val_loss: -0.8627 - val_cosine_similarity: -0.8606\n",
            "Epoch 46/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9330 - cosine_similarity: -0.9330 - val_loss: -0.8620 - val_cosine_similarity: -0.8600\n",
            "Epoch 47/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9331 - cosine_similarity: -0.9331 - val_loss: -0.8621 - val_cosine_similarity: -0.8600\n",
            "Epoch 48/200\n",
            "94/94 [==============================] - 0s 3ms/step - loss: -0.9333 - cosine_similarity: -0.9334 - val_loss: -0.8624 - val_cosine_similarity: -0.8604\n",
            "Epoch 49/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9333 - cosine_similarity: -0.9332 - val_loss: -0.8624 - val_cosine_similarity: -0.8603\n",
            "Epoch 50/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9332 - cosine_similarity: -0.9332 - val_loss: -0.8616 - val_cosine_similarity: -0.8596\n",
            "Epoch 51/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9333 - cosine_similarity: -0.9333 - val_loss: -0.8621 - val_cosine_similarity: -0.8601\n",
            "Epoch 52/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9336 - cosine_similarity: -0.9336 - val_loss: -0.8617 - val_cosine_similarity: -0.8597\n",
            "Epoch 53/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9334 - cosine_similarity: -0.9333 - val_loss: -0.8621 - val_cosine_similarity: -0.8600\n",
            "Epoch 54/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9336 - cosine_similarity: -0.9336 - val_loss: -0.8619 - val_cosine_similarity: -0.8599\n",
            "Epoch 55/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9336 - cosine_similarity: -0.9336 - val_loss: -0.8620 - val_cosine_similarity: -0.8600\n",
            "Epoch 56/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9337 - cosine_similarity: -0.9338 - val_loss: -0.8620 - val_cosine_similarity: -0.8600\n",
            "Epoch 57/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9337 - cosine_similarity: -0.9337 - val_loss: -0.8623 - val_cosine_similarity: -0.8603\n",
            "Epoch 58/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9338 - cosine_similarity: -0.9338 - val_loss: -0.8620 - val_cosine_similarity: -0.8599\n",
            "Epoch 59/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9337 - cosine_similarity: -0.9338 - val_loss: -0.8620 - val_cosine_similarity: -0.8600\n",
            "Epoch 60/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9339 - cosine_similarity: -0.9339 - val_loss: -0.8622 - val_cosine_similarity: -0.8602\n",
            "Epoch 61/200\n",
            "94/94 [==============================] - 0s 3ms/step - loss: -0.9339 - cosine_similarity: -0.9339 - val_loss: -0.8619 - val_cosine_similarity: -0.8599\n",
            "Epoch 62/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9340 - cosine_similarity: -0.9341 - val_loss: -0.8622 - val_cosine_similarity: -0.8602\n",
            "Epoch 63/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9339 - cosine_similarity: -0.9339 - val_loss: -0.8622 - val_cosine_similarity: -0.8601\n",
            "Epoch 64/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9341 - cosine_similarity: -0.9341 - val_loss: -0.8625 - val_cosine_similarity: -0.8605\n",
            "Epoch 65/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9340 - cosine_similarity: -0.9339 - val_loss: -0.8620 - val_cosine_similarity: -0.8599\n",
            "Epoch 66/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9341 - cosine_similarity: -0.9341 - val_loss: -0.8622 - val_cosine_similarity: -0.8601\n",
            "Epoch 67/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9341 - cosine_similarity: -0.9341 - val_loss: -0.8621 - val_cosine_similarity: -0.8600\n",
            "Epoch 68/200\n",
            "94/94 [==============================] - 0s 3ms/step - loss: -0.9343 - cosine_similarity: -0.9343 - val_loss: -0.8621 - val_cosine_similarity: -0.8600\n",
            "Epoch 69/200\n",
            "94/94 [==============================] - 0s 3ms/step - loss: -0.9343 - cosine_similarity: -0.9343 - val_loss: -0.8618 - val_cosine_similarity: -0.8597\n",
            "Epoch 70/200\n",
            "94/94 [==============================] - 0s 3ms/step - loss: -0.9343 - cosine_similarity: -0.9342 - val_loss: -0.8618 - val_cosine_similarity: -0.8598\n",
            "Epoch 71/200\n",
            "94/94 [==============================] - 0s 3ms/step - loss: -0.9344 - cosine_similarity: -0.9344 - val_loss: -0.8623 - val_cosine_similarity: -0.8602\n",
            "Epoch 72/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9343 - cosine_similarity: -0.9343 - val_loss: -0.8621 - val_cosine_similarity: -0.8600\n",
            "Epoch 73/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9343 - cosine_similarity: -0.9343 - val_loss: -0.8616 - val_cosine_similarity: -0.8596\n",
            "Epoch 74/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9344 - cosine_similarity: -0.9344 - val_loss: -0.8622 - val_cosine_similarity: -0.8602\n",
            "Epoch 75/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9345 - cosine_similarity: -0.9345 - val_loss: -0.8624 - val_cosine_similarity: -0.8603\n",
            "Epoch 76/200\n",
            "94/94 [==============================] - 0s 3ms/step - loss: -0.9345 - cosine_similarity: -0.9345 - val_loss: -0.8625 - val_cosine_similarity: -0.8604\n",
            "Epoch 77/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9347 - cosine_similarity: -0.9347 - val_loss: -0.8625 - val_cosine_similarity: -0.8604\n",
            "Epoch 78/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9346 - cosine_similarity: -0.9347 - val_loss: -0.8621 - val_cosine_similarity: -0.8601\n",
            "Epoch 79/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9346 - cosine_similarity: -0.9346 - val_loss: -0.8617 - val_cosine_similarity: -0.8596\n",
            "Epoch 80/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9348 - cosine_similarity: -0.9348 - val_loss: -0.8624 - val_cosine_similarity: -0.8604\n",
            "Epoch 81/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9348 - cosine_similarity: -0.9348 - val_loss: -0.8621 - val_cosine_similarity: -0.8601\n",
            "Epoch 82/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9348 - cosine_similarity: -0.9347 - val_loss: -0.8616 - val_cosine_similarity: -0.8595\n",
            "Epoch 83/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9349 - cosine_similarity: -0.9348 - val_loss: -0.8621 - val_cosine_similarity: -0.8600\n",
            "Epoch 84/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9348 - cosine_similarity: -0.9348 - val_loss: -0.8623 - val_cosine_similarity: -0.8603\n",
            "Epoch 85/200\n",
            "94/94 [==============================] - 0s 3ms/step - loss: -0.9349 - cosine_similarity: -0.9349 - val_loss: -0.8621 - val_cosine_similarity: -0.8600\n",
            "Epoch 86/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9349 - cosine_similarity: -0.9349 - val_loss: -0.8621 - val_cosine_similarity: -0.8600\n",
            "Epoch 87/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9348 - cosine_similarity: -0.9348 - val_loss: -0.8621 - val_cosine_similarity: -0.8600\n",
            "Epoch 88/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9350 - cosine_similarity: -0.9350 - val_loss: -0.8623 - val_cosine_similarity: -0.8602\n",
            "Epoch 89/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9350 - cosine_similarity: -0.9351 - val_loss: -0.8622 - val_cosine_similarity: -0.8601\n",
            "Epoch 90/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9351 - cosine_similarity: -0.9351 - val_loss: -0.8620 - val_cosine_similarity: -0.8600\n",
            "Epoch 91/200\n",
            "94/94 [==============================] - 0s 3ms/step - loss: -0.9351 - cosine_similarity: -0.9351 - val_loss: -0.8620 - val_cosine_similarity: -0.8599\n",
            "Epoch 92/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9351 - cosine_similarity: -0.9351 - val_loss: -0.8624 - val_cosine_similarity: -0.8604\n",
            "Epoch 93/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9352 - cosine_similarity: -0.9351 - val_loss: -0.8623 - val_cosine_similarity: -0.8603\n",
            "Epoch 94/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9353 - cosine_similarity: -0.9352 - val_loss: -0.8619 - val_cosine_similarity: -0.8599\n",
            "Epoch 95/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9353 - cosine_similarity: -0.9352 - val_loss: -0.8621 - val_cosine_similarity: -0.8601\n",
            "Epoch 96/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9353 - cosine_similarity: -0.9353 - val_loss: -0.8619 - val_cosine_similarity: -0.8599\n",
            "Epoch 97/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9352 - cosine_similarity: -0.9352 - val_loss: -0.8621 - val_cosine_similarity: -0.8601\n",
            "Epoch 98/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9353 - cosine_similarity: -0.9354 - val_loss: -0.8623 - val_cosine_similarity: -0.8602\n",
            "Epoch 99/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9354 - cosine_similarity: -0.9353 - val_loss: -0.8621 - val_cosine_similarity: -0.8600\n",
            "Epoch 100/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9354 - cosine_similarity: -0.9353 - val_loss: -0.8621 - val_cosine_similarity: -0.8600\n",
            "Epoch 101/200\n",
            "94/94 [==============================] - 0s 3ms/step - loss: -0.9354 - cosine_similarity: -0.9354 - val_loss: -0.8617 - val_cosine_similarity: -0.8596\n",
            "Epoch 102/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9355 - cosine_similarity: -0.9355 - val_loss: -0.8615 - val_cosine_similarity: -0.8594\n",
            "Epoch 103/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9355 - cosine_similarity: -0.9355 - val_loss: -0.8619 - val_cosine_similarity: -0.8598\n",
            "Epoch 104/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9355 - cosine_similarity: -0.9355 - val_loss: -0.8620 - val_cosine_similarity: -0.8600\n",
            "Epoch 105/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9355 - cosine_similarity: -0.9355 - val_loss: -0.8618 - val_cosine_similarity: -0.8598\n",
            "Epoch 106/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9356 - cosine_similarity: -0.9355 - val_loss: -0.8620 - val_cosine_similarity: -0.8599\n",
            "Epoch 107/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9355 - cosine_similarity: -0.9355 - val_loss: -0.8620 - val_cosine_similarity: -0.8599\n",
            "Epoch 108/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9356 - cosine_similarity: -0.9355 - val_loss: -0.8622 - val_cosine_similarity: -0.8602\n",
            "Epoch 109/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9355 - cosine_similarity: -0.9355 - val_loss: -0.8619 - val_cosine_similarity: -0.8599\n",
            "Epoch 110/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9357 - cosine_similarity: -0.9356 - val_loss: -0.8620 - val_cosine_similarity: -0.8599\n",
            "Epoch 111/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9358 - cosine_similarity: -0.9357 - val_loss: -0.8625 - val_cosine_similarity: -0.8605\n",
            "Epoch 112/200\n",
            "94/94 [==============================] - 0s 3ms/step - loss: -0.9358 - cosine_similarity: -0.9359 - val_loss: -0.8621 - val_cosine_similarity: -0.8601\n",
            "Epoch 113/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9358 - cosine_similarity: -0.9358 - val_loss: -0.8620 - val_cosine_similarity: -0.8600\n",
            "Epoch 114/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9357 - cosine_similarity: -0.9357 - val_loss: -0.8623 - val_cosine_similarity: -0.8602\n",
            "Epoch 115/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9358 - cosine_similarity: -0.9358 - val_loss: -0.8621 - val_cosine_similarity: -0.8600\n",
            "Epoch 116/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9358 - cosine_similarity: -0.9358 - val_loss: -0.8620 - val_cosine_similarity: -0.8599\n",
            "Epoch 117/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9358 - cosine_similarity: -0.9358 - val_loss: -0.8624 - val_cosine_similarity: -0.8603\n",
            "Epoch 118/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9359 - cosine_similarity: -0.9359 - val_loss: -0.8621 - val_cosine_similarity: -0.8600\n",
            "Epoch 119/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9358 - cosine_similarity: -0.9358 - val_loss: -0.8621 - val_cosine_similarity: -0.8601\n",
            "Epoch 120/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9360 - cosine_similarity: -0.9360 - val_loss: -0.8621 - val_cosine_similarity: -0.8600\n",
            "Epoch 121/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9360 - cosine_similarity: -0.9359 - val_loss: -0.8621 - val_cosine_similarity: -0.8600\n",
            "Epoch 122/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9360 - cosine_similarity: -0.9360 - val_loss: -0.8620 - val_cosine_similarity: -0.8600\n",
            "Epoch 123/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9360 - cosine_similarity: -0.9361 - val_loss: -0.8623 - val_cosine_similarity: -0.8603\n",
            "Epoch 124/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9361 - cosine_similarity: -0.9360 - val_loss: -0.8621 - val_cosine_similarity: -0.8600\n",
            "Epoch 125/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9361 - cosine_similarity: -0.9362 - val_loss: -0.8621 - val_cosine_similarity: -0.8600\n",
            "Epoch 126/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9361 - cosine_similarity: -0.9361 - val_loss: -0.8621 - val_cosine_similarity: -0.8600\n",
            "Epoch 127/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9362 - cosine_similarity: -0.9362 - val_loss: -0.8621 - val_cosine_similarity: -0.8601\n",
            "Epoch 128/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9361 - cosine_similarity: -0.9361 - val_loss: -0.8622 - val_cosine_similarity: -0.8602\n",
            "Epoch 129/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9362 - cosine_similarity: -0.9362 - val_loss: -0.8624 - val_cosine_similarity: -0.8603\n",
            "Epoch 130/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9362 - cosine_similarity: -0.9362 - val_loss: -0.8621 - val_cosine_similarity: -0.8600\n",
            "Epoch 131/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9362 - cosine_similarity: -0.9363 - val_loss: -0.8622 - val_cosine_similarity: -0.8601\n",
            "Epoch 132/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9362 - cosine_similarity: -0.9362 - val_loss: -0.8619 - val_cosine_similarity: -0.8599\n",
            "Epoch 133/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9363 - cosine_similarity: -0.9363 - val_loss: -0.8623 - val_cosine_similarity: -0.8602\n",
            "Epoch 134/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9363 - cosine_similarity: -0.9363 - val_loss: -0.8622 - val_cosine_similarity: -0.8601\n",
            "Epoch 135/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9364 - cosine_similarity: -0.9363 - val_loss: -0.8618 - val_cosine_similarity: -0.8598\n",
            "Epoch 136/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9362 - cosine_similarity: -0.9362 - val_loss: -0.8622 - val_cosine_similarity: -0.8601\n",
            "Epoch 137/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9364 - cosine_similarity: -0.9364 - val_loss: -0.8622 - val_cosine_similarity: -0.8602\n",
            "Epoch 138/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9363 - cosine_similarity: -0.9363 - val_loss: -0.8621 - val_cosine_similarity: -0.8600\n",
            "Epoch 139/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9364 - cosine_similarity: -0.9364 - val_loss: -0.8619 - val_cosine_similarity: -0.8599\n",
            "Epoch 140/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9364 - cosine_similarity: -0.9364 - val_loss: -0.8620 - val_cosine_similarity: -0.8599\n",
            "Epoch 141/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9365 - cosine_similarity: -0.9365 - val_loss: -0.8619 - val_cosine_similarity: -0.8598\n",
            "Epoch 142/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9365 - cosine_similarity: -0.9364 - val_loss: -0.8622 - val_cosine_similarity: -0.8601\n",
            "Epoch 143/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9363 - cosine_similarity: -0.9364 - val_loss: -0.8622 - val_cosine_similarity: -0.8601\n",
            "Epoch 144/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9365 - cosine_similarity: -0.9364 - val_loss: -0.8623 - val_cosine_similarity: -0.8603\n",
            "Epoch 145/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9365 - cosine_similarity: -0.9365 - val_loss: -0.8621 - val_cosine_similarity: -0.8600\n",
            "Epoch 146/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9365 - cosine_similarity: -0.9365 - val_loss: -0.8622 - val_cosine_similarity: -0.8601\n",
            "Epoch 147/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9366 - cosine_similarity: -0.9366 - val_loss: -0.8622 - val_cosine_similarity: -0.8602\n",
            "Epoch 148/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9365 - cosine_similarity: -0.9365 - val_loss: -0.8624 - val_cosine_similarity: -0.8604\n",
            "Epoch 149/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9366 - cosine_similarity: -0.9366 - val_loss: -0.8622 - val_cosine_similarity: -0.8601\n",
            "Epoch 150/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9367 - cosine_similarity: -0.9367 - val_loss: -0.8622 - val_cosine_similarity: -0.8601\n",
            "Epoch 151/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9366 - cosine_similarity: -0.9366 - val_loss: -0.8620 - val_cosine_similarity: -0.8599\n",
            "Epoch 152/200\n",
            "94/94 [==============================] - 0s 3ms/step - loss: -0.9366 - cosine_similarity: -0.9366 - val_loss: -0.8622 - val_cosine_similarity: -0.8602\n",
            "Epoch 153/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9367 - cosine_similarity: -0.9367 - val_loss: -0.8620 - val_cosine_similarity: -0.8600\n",
            "Epoch 154/200\n",
            "94/94 [==============================] - 0s 3ms/step - loss: -0.9367 - cosine_similarity: -0.9366 - val_loss: -0.8617 - val_cosine_similarity: -0.8596\n",
            "Epoch 155/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9368 - cosine_similarity: -0.9368 - val_loss: -0.8619 - val_cosine_similarity: -0.8598\n",
            "Epoch 156/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9367 - cosine_similarity: -0.9368 - val_loss: -0.8623 - val_cosine_similarity: -0.8602\n",
            "Epoch 157/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9367 - cosine_similarity: -0.9367 - val_loss: -0.8619 - val_cosine_similarity: -0.8599\n",
            "Epoch 158/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9367 - cosine_similarity: -0.9368 - val_loss: -0.8620 - val_cosine_similarity: -0.8599\n",
            "Epoch 159/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9366 - cosine_similarity: -0.9366 - val_loss: -0.8621 - val_cosine_similarity: -0.8600\n",
            "Epoch 160/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9368 - cosine_similarity: -0.9368 - val_loss: -0.8623 - val_cosine_similarity: -0.8602\n",
            "Epoch 1/200\n",
            "94/94 [==============================] - 1s 4ms/step - loss: -0.4960 - cosine_similarity: -0.4964 - val_loss: -0.5664 - val_cosine_similarity: -0.5665\n",
            "Epoch 2/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.6620 - cosine_similarity: -0.6621 - val_loss: -0.6604 - val_cosine_similarity: -0.6595\n",
            "Epoch 3/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.7447 - cosine_similarity: -0.7448 - val_loss: -0.7140 - val_cosine_similarity: -0.7125\n",
            "Epoch 4/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.7955 - cosine_similarity: -0.7954 - val_loss: -0.7479 - val_cosine_similarity: -0.7462\n",
            "Epoch 5/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.8282 - cosine_similarity: -0.8283 - val_loss: -0.7701 - val_cosine_similarity: -0.7683\n",
            "Epoch 6/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.8503 - cosine_similarity: -0.8503 - val_loss: -0.7865 - val_cosine_similarity: -0.7847\n",
            "Epoch 7/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.8664 - cosine_similarity: -0.8664 - val_loss: -0.7986 - val_cosine_similarity: -0.7967\n",
            "Epoch 8/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.8783 - cosine_similarity: -0.8783 - val_loss: -0.8083 - val_cosine_similarity: -0.8064\n",
            "Epoch 9/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.8872 - cosine_similarity: -0.8873 - val_loss: -0.8154 - val_cosine_similarity: -0.8135\n",
            "Epoch 10/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.8943 - cosine_similarity: -0.8943 - val_loss: -0.8215 - val_cosine_similarity: -0.8197\n",
            "Epoch 11/200\n",
            "94/94 [==============================] - 0s 3ms/step - loss: -0.8998 - cosine_similarity: -0.8997 - val_loss: -0.8264 - val_cosine_similarity: -0.8246\n",
            "Epoch 12/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9040 - cosine_similarity: -0.9040 - val_loss: -0.8300 - val_cosine_similarity: -0.8281\n",
            "Epoch 13/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9075 - cosine_similarity: -0.9075 - val_loss: -0.8330 - val_cosine_similarity: -0.8312\n",
            "Epoch 14/200\n",
            "94/94 [==============================] - 0s 3ms/step - loss: -0.9100 - cosine_similarity: -0.9101 - val_loss: -0.8360 - val_cosine_similarity: -0.8342\n",
            "Epoch 15/200\n",
            "94/94 [==============================] - 0s 3ms/step - loss: -0.9123 - cosine_similarity: -0.9122 - val_loss: -0.8379 - val_cosine_similarity: -0.8361\n",
            "Epoch 16/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9141 - cosine_similarity: -0.9141 - val_loss: -0.8398 - val_cosine_similarity: -0.8380\n",
            "Epoch 17/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9154 - cosine_similarity: -0.9154 - val_loss: -0.8412 - val_cosine_similarity: -0.8394\n",
            "Epoch 18/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9167 - cosine_similarity: -0.9167 - val_loss: -0.8427 - val_cosine_similarity: -0.8409\n",
            "Epoch 19/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9178 - cosine_similarity: -0.9178 - val_loss: -0.8435 - val_cosine_similarity: -0.8417\n",
            "Epoch 20/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9184 - cosine_similarity: -0.9184 - val_loss: -0.8446 - val_cosine_similarity: -0.8428\n",
            "Epoch 21/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9192 - cosine_similarity: -0.9192 - val_loss: -0.8452 - val_cosine_similarity: -0.8435\n",
            "Epoch 22/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9198 - cosine_similarity: -0.9198 - val_loss: -0.8459 - val_cosine_similarity: -0.8442\n",
            "Epoch 23/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9204 - cosine_similarity: -0.9204 - val_loss: -0.8462 - val_cosine_similarity: -0.8444\n",
            "Epoch 24/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9208 - cosine_similarity: -0.9207 - val_loss: -0.8474 - val_cosine_similarity: -0.8456\n",
            "Epoch 25/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9211 - cosine_similarity: -0.9211 - val_loss: -0.8475 - val_cosine_similarity: -0.8457\n",
            "Epoch 26/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9214 - cosine_similarity: -0.9214 - val_loss: -0.8481 - val_cosine_similarity: -0.8464\n",
            "Epoch 27/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9219 - cosine_similarity: -0.9219 - val_loss: -0.8477 - val_cosine_similarity: -0.8459\n",
            "Epoch 28/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9221 - cosine_similarity: -0.9221 - val_loss: -0.8485 - val_cosine_similarity: -0.8468\n",
            "Epoch 29/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9222 - cosine_similarity: -0.9222 - val_loss: -0.8488 - val_cosine_similarity: -0.8471\n",
            "Epoch 30/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9223 - cosine_similarity: -0.9223 - val_loss: -0.8487 - val_cosine_similarity: -0.8470\n",
            "Epoch 31/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9226 - cosine_similarity: -0.9226 - val_loss: -0.8490 - val_cosine_similarity: -0.8473\n",
            "Epoch 32/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9227 - cosine_similarity: -0.9227 - val_loss: -0.8490 - val_cosine_similarity: -0.8472\n",
            "Epoch 33/200\n",
            "94/94 [==============================] - 0s 3ms/step - loss: -0.9229 - cosine_similarity: -0.9229 - val_loss: -0.8495 - val_cosine_similarity: -0.8477\n",
            "Epoch 34/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9230 - cosine_similarity: -0.9231 - val_loss: -0.8497 - val_cosine_similarity: -0.8479\n",
            "Epoch 35/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9232 - cosine_similarity: -0.9232 - val_loss: -0.8494 - val_cosine_similarity: -0.8477\n",
            "Epoch 36/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9233 - cosine_similarity: -0.9233 - val_loss: -0.8503 - val_cosine_similarity: -0.8486\n",
            "Epoch 37/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9232 - cosine_similarity: -0.9232 - val_loss: -0.8496 - val_cosine_similarity: -0.8478\n",
            "Epoch 38/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9234 - cosine_similarity: -0.9234 - val_loss: -0.8501 - val_cosine_similarity: -0.8483\n",
            "Epoch 39/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9235 - cosine_similarity: -0.9234 - val_loss: -0.8503 - val_cosine_similarity: -0.8486\n",
            "Epoch 40/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9235 - cosine_similarity: -0.9234 - val_loss: -0.8501 - val_cosine_similarity: -0.8484\n",
            "Epoch 41/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9236 - cosine_similarity: -0.9237 - val_loss: -0.8503 - val_cosine_similarity: -0.8485\n",
            "Epoch 42/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9237 - cosine_similarity: -0.9236 - val_loss: -0.8503 - val_cosine_similarity: -0.8486\n",
            "Epoch 43/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9237 - cosine_similarity: -0.9237 - val_loss: -0.8505 - val_cosine_similarity: -0.8487\n",
            "Epoch 44/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9239 - cosine_similarity: -0.9238 - val_loss: -0.8504 - val_cosine_similarity: -0.8487\n",
            "Epoch 45/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9239 - cosine_similarity: -0.9240 - val_loss: -0.8506 - val_cosine_similarity: -0.8489\n",
            "Epoch 46/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9239 - cosine_similarity: -0.9239 - val_loss: -0.8506 - val_cosine_similarity: -0.8488\n",
            "Epoch 47/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9240 - cosine_similarity: -0.9238 - val_loss: -0.8507 - val_cosine_similarity: -0.8489\n",
            "Epoch 48/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9240 - cosine_similarity: -0.9240 - val_loss: -0.8508 - val_cosine_similarity: -0.8490\n",
            "Epoch 49/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9241 - cosine_similarity: -0.9241 - val_loss: -0.8510 - val_cosine_similarity: -0.8492\n",
            "Epoch 50/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9241 - cosine_similarity: -0.9241 - val_loss: -0.8509 - val_cosine_similarity: -0.8492\n",
            "Epoch 51/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9242 - cosine_similarity: -0.9242 - val_loss: -0.8506 - val_cosine_similarity: -0.8489\n",
            "Epoch 52/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9241 - cosine_similarity: -0.9241 - val_loss: -0.8506 - val_cosine_similarity: -0.8489\n",
            "Epoch 53/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9243 - cosine_similarity: -0.9242 - val_loss: -0.8508 - val_cosine_similarity: -0.8491\n",
            "Epoch 54/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9244 - cosine_similarity: -0.9243 - val_loss: -0.8511 - val_cosine_similarity: -0.8494\n",
            "Epoch 55/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9243 - cosine_similarity: -0.9243 - val_loss: -0.8508 - val_cosine_similarity: -0.8491\n",
            "Epoch 56/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9243 - cosine_similarity: -0.9244 - val_loss: -0.8510 - val_cosine_similarity: -0.8493\n",
            "Epoch 57/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9243 - cosine_similarity: -0.9244 - val_loss: -0.8511 - val_cosine_similarity: -0.8493\n",
            "Epoch 58/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9244 - cosine_similarity: -0.9244 - val_loss: -0.8512 - val_cosine_similarity: -0.8495\n",
            "Epoch 59/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9244 - cosine_similarity: -0.9244 - val_loss: -0.8515 - val_cosine_similarity: -0.8497\n",
            "Epoch 60/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9245 - cosine_similarity: -0.9245 - val_loss: -0.8513 - val_cosine_similarity: -0.8495\n",
            "Epoch 61/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9245 - cosine_similarity: -0.9244 - val_loss: -0.8511 - val_cosine_similarity: -0.8493\n",
            "Epoch 62/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9246 - cosine_similarity: -0.9246 - val_loss: -0.8512 - val_cosine_similarity: -0.8494\n",
            "Epoch 63/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9246 - cosine_similarity: -0.9246 - val_loss: -0.8513 - val_cosine_similarity: -0.8496\n",
            "Epoch 64/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9246 - cosine_similarity: -0.9246 - val_loss: -0.8513 - val_cosine_similarity: -0.8496\n",
            "Epoch 65/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9246 - cosine_similarity: -0.9245 - val_loss: -0.8514 - val_cosine_similarity: -0.8496\n",
            "Epoch 66/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9246 - cosine_similarity: -0.9246 - val_loss: -0.8509 - val_cosine_similarity: -0.8491\n",
            "Epoch 67/200\n",
            "94/94 [==============================] - 0s 3ms/step - loss: -0.9247 - cosine_similarity: -0.9247 - val_loss: -0.8514 - val_cosine_similarity: -0.8497\n",
            "Epoch 68/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9245 - cosine_similarity: -0.9245 - val_loss: -0.8509 - val_cosine_similarity: -0.8492\n",
            "Epoch 69/200\n",
            "94/94 [==============================] - 0s 3ms/step - loss: -0.9247 - cosine_similarity: -0.9248 - val_loss: -0.8511 - val_cosine_similarity: -0.8494\n",
            "Epoch 70/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9247 - cosine_similarity: -0.9247 - val_loss: -0.8512 - val_cosine_similarity: -0.8495\n",
            "Epoch 71/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9247 - cosine_similarity: -0.9247 - val_loss: -0.8515 - val_cosine_similarity: -0.8497\n",
            "Epoch 72/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9248 - cosine_similarity: -0.9248 - val_loss: -0.8512 - val_cosine_similarity: -0.8494\n",
            "Epoch 73/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9246 - cosine_similarity: -0.9246 - val_loss: -0.8511 - val_cosine_similarity: -0.8494\n",
            "Epoch 74/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9247 - cosine_similarity: -0.9247 - val_loss: -0.8513 - val_cosine_similarity: -0.8495\n",
            "Epoch 75/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9248 - cosine_similarity: -0.9247 - val_loss: -0.8511 - val_cosine_similarity: -0.8494\n",
            "Epoch 76/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9248 - cosine_similarity: -0.9247 - val_loss: -0.8511 - val_cosine_similarity: -0.8494\n",
            "Epoch 77/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9248 - cosine_similarity: -0.9248 - val_loss: -0.8512 - val_cosine_similarity: -0.8494\n",
            "Epoch 78/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9248 - cosine_similarity: -0.9248 - val_loss: -0.8512 - val_cosine_similarity: -0.8495\n",
            "Epoch 79/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9248 - cosine_similarity: -0.9248 - val_loss: -0.8514 - val_cosine_similarity: -0.8496\n",
            "Epoch 80/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9249 - cosine_similarity: -0.9248 - val_loss: -0.8509 - val_cosine_similarity: -0.8491\n",
            "Epoch 81/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9249 - cosine_similarity: -0.9248 - val_loss: -0.8511 - val_cosine_similarity: -0.8494\n",
            "Epoch 82/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9250 - cosine_similarity: -0.9250 - val_loss: -0.8511 - val_cosine_similarity: -0.8493\n",
            "Epoch 83/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9250 - cosine_similarity: -0.9251 - val_loss: -0.8512 - val_cosine_similarity: -0.8495\n",
            "Epoch 84/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9251 - cosine_similarity: -0.9250 - val_loss: -0.8511 - val_cosine_similarity: -0.8494\n",
            "Epoch 85/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9249 - cosine_similarity: -0.9249 - val_loss: -0.8511 - val_cosine_similarity: -0.8494\n",
            "Epoch 86/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9250 - cosine_similarity: -0.9250 - val_loss: -0.8512 - val_cosine_similarity: -0.8494\n",
            "Epoch 87/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9250 - cosine_similarity: -0.9251 - val_loss: -0.8512 - val_cosine_similarity: -0.8495\n",
            "Epoch 88/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9250 - cosine_similarity: -0.9250 - val_loss: -0.8508 - val_cosine_similarity: -0.8490\n",
            "Epoch 89/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: -0.9250 - cosine_similarity: -0.9250 - val_loss: -0.8512 - val_cosine_similarity: -0.8495\n",
            "{}\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}